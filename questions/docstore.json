{"docstore/metadata": {"237e5cd2-face-4c5b-98fe-6d3614aef161": {"doc_hash": "70855656d876b6115f2e42cf708cc88dba5de35d6fd7c5572ebfaae9ca678cac"}, "50b1cfb7-2331-459d-a905-e1740658bc20": {"doc_hash": "2378fc05910d66d3df707a08449be374c3cd1439d5217cc9d63cfea0aebc3e47"}, "60dcd420-d1cd-424b-a926-8ab307c70a51": {"doc_hash": "d78eb537b4c125ab152a5b46361f8ba890b8d6813b4f7413b0039f24cb7d0c59"}, "58d35c8b-fc64-4606-ae79-0bb7cde01948": {"doc_hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53"}, "991ebd60-0c73-48b0-a943-1685918f8576": {"doc_hash": "dca7c69ce8e04601325122df10ffb8b352783a64fe3f95c0e70add3dccb29fba", "ref_doc_id": "237e5cd2-face-4c5b-98fe-6d3614aef161"}, "ced036ed-02b5-4964-b952-d502476e1656": {"doc_hash": "321974dea242041d41c01dfdd70c077e69a2700ae914a164575cb14cdd8959c5", "ref_doc_id": "237e5cd2-face-4c5b-98fe-6d3614aef161"}, "e12bc1af-001e-4aff-ae2e-8ff2588909b4": {"doc_hash": "e3d7281de29da8d9a6a153cd1a1588a0c33061809b1bf286c5af4aa3733a454f", "ref_doc_id": "237e5cd2-face-4c5b-98fe-6d3614aef161"}, "0ca72028-e622-4002-8af8-939c10a19ff7": {"doc_hash": "5545ed186b2496f5fe25b51e16b2e60cd9a73401fe74e318f5814fb3f428aa4e", "ref_doc_id": "237e5cd2-face-4c5b-98fe-6d3614aef161"}, "235920a3-09c8-4e04-a9a4-71105e238589": {"doc_hash": "9232147643841d9fce3308c521db1882625a180ffc5122a102d252d672477217", "ref_doc_id": "237e5cd2-face-4c5b-98fe-6d3614aef161"}, "21141025-dabc-4695-b42c-d072f483f826": {"doc_hash": "1f8c9528012cced8a1f15c71f8f6da5d264c7cad69808aee22ab8aafecb76e73", "ref_doc_id": "237e5cd2-face-4c5b-98fe-6d3614aef161"}, "4345dc0a-f359-4348-bd8e-d2cb7a87d076": {"doc_hash": "e348a9e0553f904ceb482ae5d3c5be2d39115a36116d3cf355a3ff16c34c1f32", "ref_doc_id": "50b1cfb7-2331-459d-a905-e1740658bc20"}, "653ea791-6357-43f9-9b6f-a0756c58305e": {"doc_hash": "f3a72678f7c34e06f5c706596e2184f551e4289c9fd54320bcd22354a3f12c81", "ref_doc_id": "50b1cfb7-2331-459d-a905-e1740658bc20"}, "8e06ae75-cb32-45b0-a22b-6ad6ff16b001": {"doc_hash": "11faf6603dbdfdfe5afcd82fe115123f151aa9333b89e67f84eafd97e7e168c9", "ref_doc_id": "50b1cfb7-2331-459d-a905-e1740658bc20"}, "65f74eb4-4a88-4100-9acc-7cc0fe386957": {"doc_hash": "7e6a8e1273781dc6b198c506d168d470879c7f0d1a3d6e189d89b9abeb0e15aa", "ref_doc_id": "60dcd420-d1cd-424b-a926-8ab307c70a51"}, "08cb6190-31e7-4262-89e1-25a613ef29f4": {"doc_hash": "ef1d37ecb9b5c8ed44ebfce02f808519f298dbed46e4f69bfdf8c31067654dc0", "ref_doc_id": "60dcd420-d1cd-424b-a926-8ab307c70a51"}, "bf4e42de-7b8c-4daa-8ec5-f5c49e0a01ab": {"doc_hash": "6d585e8339cf2d95c0826b6ebd027c2c401cfde8d28fbff070d1dc75f896fdf3", "ref_doc_id": "60dcd420-d1cd-424b-a926-8ab307c70a51"}, "0e9f8e30-d860-4473-8344-0a0ae61600e4": {"doc_hash": "f6ea41d2fa334cfaeda116c7294eb74697c9736c560f419f747c8d21dd77417f", "ref_doc_id": "60dcd420-d1cd-424b-a926-8ab307c70a51"}, "c5bd60d7-69f9-4ae7-9fe4-dad4639b11c9": {"doc_hash": "03c2705c1eb8766978f52b8b32347e887a2c3727c37f135ca9df73f90f699011", "ref_doc_id": "60dcd420-d1cd-424b-a926-8ab307c70a51"}, "8b6e8797-b55b-498a-aad2-58baa790fc8b": {"doc_hash": "3982b88672fca54d124a98a2fb6afff1aac033c8464d3d1a2bb8b66e932e3804", "ref_doc_id": "60dcd420-d1cd-424b-a926-8ab307c70a51"}, "b94ec2a1-35f0-434a-998e-a02c3bd059be": {"doc_hash": "742c4fb5629b4eb09a03de45bc563dde5ab0233f62237b3a8d65ffa0a8cf298e", "ref_doc_id": "60dcd420-d1cd-424b-a926-8ab307c70a51"}, "fe2b9dc0-e3d8-4db7-b3f2-8e0ec249351f": {"doc_hash": "d22ab5440f78c51b05bcf47d6c4039971c2408822d86e24a96c9a943446dd756", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "afcd0ecc-c85b-47a9-a721-62c6bd5e35f0": {"doc_hash": "190d791d473d2d46c4d0ca325a089118e5d24d852104260f77e4b1950f6d7cc6", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "b41d4e23-791a-4643-ae55-1a8bb4e103f6": {"doc_hash": "46c61109247b9da4f48375b6221fb5e9d7f55b0f2cd0403a024e06deb8eb2af1", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "85e725a9-9f1b-4b24-9110-1b579841cd7a": {"doc_hash": "191742d2d75333f2fe6d09f3d6983a928a9ff59d4df4c9e885263436da9ff761", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "1510aabc-512a-4db7-ae2d-8d8042f1f93a": {"doc_hash": "1bb15985ca0d4d2c9c3776df74151a4154d9102e0d6ca16c7b2a193c199447d6", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "8296b97f-1310-4643-ab78-56f29dc57220": {"doc_hash": "e7b4ccfb850ab9a8da90de9f1f0717e304a2011a50cd6911717529a6ee09c542", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "5f582dbf-9095-4979-8abd-0e911bc0d0c7": {"doc_hash": "5bdd8ebeeb7aacab10dad1931a630922df7c66f1caad281165073c4221ab6835", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "5f021dc4-761c-42ac-bd6d-d166ede4bebc": {"doc_hash": "24f522dfcd562164fca010d7289ac92ff4879acaadae8ed97e998b4db6747aaa", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "af4a41ab-9cae-45d0-9659-da6859d826d5": {"doc_hash": "e58a3d9576ca711800a106f363f3eefab7da730da200f2ebe3a3e56a90575907", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "55a42822-3aea-478b-ab74-d03b28d72138": {"doc_hash": "53f217638a6db9a86d5829fc3863175ffe0e1e7d50b64069d9517bdbfae9df72", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}, "f1ca1cb9-54d8-4e17-80a5-fa06259f19b3": {"doc_hash": "fadb7a74b53ce2349459cc92cb8c1c265b60ec14ee7365899bdb6a6b932b251a", "ref_doc_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948"}}, "docstore/data": {"991ebd60-0c73-48b0-a943-1685918f8576": {"__data__": {"id_": "991ebd60-0c73-48b0-a943-1685918f8576", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "237e5cd2-face-4c5b-98fe-6d3614aef161", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "70855656d876b6115f2e42cf708cc88dba5de35d6fd7c5572ebfaae9ca678cac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ced036ed-02b5-4964-b952-d502476e1656", "node_type": "1", "metadata": {}, "hash": "d72ed841f111957ade750408da4699b14b71d49b724cbf80253d61bc0b160bcc", "class_name": "RelatedNodeInfo"}}, "text": "Thank you. Nice to see you. In call. Like right. Just can you me. I have a full of full your resume. So I'm calling from Bayer Drop Science. And we are looking for a text-based data scientist. And we found your resume. It's very interesting. So wanted to have a quick call with you. Nice. I am the hiring manager. So you should be able to be the introductions. And then it's a general. It keeps flowing. And you might have questions. I might have questions. Mostly, you know, any questions that you might have. And the last few minutes, you know, we can talk about whether typical next steps. And that's that. Right. That's good to me. Cool. So I can go first if you don't mind. And my gohy name is Baladasan. My name is Baladasan Giridharan. I grew up giri. I have been in Bayer for almost 10 years. I am right now leading a journey. I team. We are in the thousand fans sitting that goes with other than then all the media attention and the thing that goes with it. There's a lot of interest to base text-based models. And I am being assigned to, you know, ask to lead a team and then the team around this area. So that's why we have two recussions of pregnant for hiring people. And that's where we are right now. My background is in computer science. I have been leading an imaging team for the last four years, three years. And now I'm leading the text-based analytics team. So that's a background about me. I'll even simply disagree. That's it. Which part is it? Which part is it? Central ways. I'll send a voice. I'll send a city and then you know. Where are you going, Central ways? Yeah. Target of South. Oh, really? Yeah. I missed that. That's the family here. Oh, really? Interesting. Cool. Very nice. I like that. That's what I think. No. In my time. OK. If you don't mind, if you don't mind, can you do it? Totally. Sure. Sure. Of course. Yeah. So like you, my background is also in computer science. I was in bachelor degree. My master's, PhD, out in computer science. And for the last couple of years, I've been working with NLP as well. Like tech generation, some image process. But at the beginning of my data science career, I was work with statistical models, like linear regression, some time series analysis, and other kind of models to prediction. And maybe the last couple of months, I was work at the CHPT, the M2, Falcon B models in this MGM project. I on top of my mind, I think it's pretty similar what you would like to do. This is kind of the direction that's that bought and some data based behind it. But I have some experience of chat bots as well, even before the CHPT or any other large and expensive model, when you are using just decision trees or bird. And I can't say any question, Pat. I just need to talk about some project. I can answer. But basically, my background is. I'm interested. I'm interested. No, I'm simply for the start of a group of self. OK. Because the resume says just a few, because I didn't check. Although just a few, I was M docs. My I think it was my third project, the last one. I mean, I have MGM. Then in the Perina and the M docs, the telcom company. I don't know if you are familiar with this company. MGM, yes, I have heard about it when I was in Vegas. Perina, yes, M docs. No. Yeah, it's a telcom provider. They are from Israel, but they have a lot of sites. And here in the United States, one is just a field. The one you saw. And a couple of sites in Brazil, India, Europe. Yeah, the main client of M docs here in the United States are H&T and Timo Bay, Timo Bay.", "start_char_idx": 1, "end_char_idx": 3535, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ced036ed-02b5-4964-b952-d502476e1656": {"__data__": {"id_": "ced036ed-02b5-4964-b952-d502476e1656", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "237e5cd2-face-4c5b-98fe-6d3614aef161", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "70855656d876b6115f2e42cf708cc88dba5de35d6fd7c5572ebfaae9ca678cac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "991ebd60-0c73-48b0-a943-1685918f8576", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "dca7c69ce8e04601325122df10ffb8b352783a64fe3f95c0e70add3dccb29fba", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e12bc1af-001e-4aff-ae2e-8ff2588909b4", "node_type": "1", "metadata": {}, "hash": "2c6f60f8a57f2af0a17df5a2ac8549b0827d5599501e5873b5a4c0be6c08b61c", "class_name": "RelatedNodeInfo"}}, "text": "OK. Because the resume says just a few, because I didn't check. Although just a few, I was M docs. My I think it was my third project, the last one. I mean, I have MGM. Then in the Perina and the M docs, the telcom company. I don't know if you are familiar with this company. MGM, yes, I have heard about it when I was in Vegas. Perina, yes, M docs. No. Yeah, it's a telcom provider. They are from Israel, but they have a lot of sites. And here in the United States, one is just a field. The one you saw. And a couple of sites in Brazil, India, Europe. Yeah, the main client of M docs here in the United States are H&T and Timo Bay, Timo Bay. So the whole system from H&T and Timo Bay, it's from M docs, the CRM customer relationship management, the all data from customers and builds. Nice. What kind of thing for your next role, Leo? Well, I was very excited with large-length models. That's where I was working at MGM. But unfortunately, doing the low budget that they had, they had a cyber attack. I don't know if you saw that, but last year, they had a cyber attack. So they changed the priorities. Unfortunately, we could not keep it going with the same idea. So I'm going to look for the same thing. Now, they work with large-length models, maybe include some image on that. Exactly what they're doing, like with drag, with people, data. That's what I'm looking for now. I'm looking for your resume. So don't think I'm going to affect them. Of course. Your resume. It talked me about the biggest NLP project that here. The biggest one absolutely was the last one. Cause I was responsible to build, I end up to end applications like they have nothing in this context, nothing about no chatbot, no large-length model working on their site. And I had to grab all the data. We have like from the SQL data space, also doing some web scrappy in the MGM websites, cause some information in the website, they did not have in the SQL database. Also, the cloud transcripts, I need to like do a scrapping out cloud transcripts to, you know, push some relevant information about question and answer from the guests. And I think that was my biggest challenge in the large-length model or NLP context. See? What type of tools did they use to scrape text? Basically, I use Python, Python language, with some length chain libraries. What else? Some shell scripts? You went on mute, sorry. Oh, sorry. I press enter here, by mistake. I, I say shell script, I also code for that. But mainly was some Python code with length chain in shell script. Code. And how did you transfer documents after this? Prefeit, you know, I'm sure we have tried. Again, how did you go about chunking your documents? Well, I had to do change indeed. Mainly for PDF documents, basically I use the length chain library. They had a kind of, not wrong, they function is recursive, character, text cleared. I remember some recursive function they have to do the chunks and do the overlap in between the chunks as well. So basically I use length chain to do this recursive. And, okay. And what type of which platform did you develop? It was on my, at first, it was on my side. So I used doc and a container for that. But at the end, on production, they used Azure. The Azure pipeline. So it, you were an AI ML architect. So how much of the work did you do? How much other state for use? Will you be able to talk about it? Well, about the proof of constant, I did all of the work. Science, grab the data, build the APIs. You know, cause I had this lecture database. I also acknowledge graph. I need to connect with the large language model. So I was supposed to preview the API between the applications. Also, I designed out the pipeline from, you know, doing the commits, go to my branch and then deployment at the Azure using the Azure pipeline, of course. But at this personally, I was, I was the main responsible for make-to-work.", "start_char_idx": 2893, "end_char_idx": 6787, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e12bc1af-001e-4aff-ae2e-8ff2588909b4": {"__data__": {"id_": "e12bc1af-001e-4aff-ae2e-8ff2588909b4", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "237e5cd2-face-4c5b-98fe-6d3614aef161", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "70855656d876b6115f2e42cf708cc88dba5de35d6fd7c5572ebfaae9ca678cac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ced036ed-02b5-4964-b952-d502476e1656", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "321974dea242041d41c01dfdd70c077e69a2700ae914a164575cb14cdd8959c5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ca72028-e622-4002-8af8-939c10a19ff7", "node_type": "1", "metadata": {}, "hash": "d26ffd30d9bc97731fc4400ad2fcc56116530cca35d1b95ffad93cf5ce26f942", "class_name": "RelatedNodeInfo"}}, "text": "So I used doc and a container for that. But at the end, on production, they used Azure. The Azure pipeline. So it, you were an AI ML architect. So how much of the work did you do? How much other state for use? Will you be able to talk about it? Well, about the proof of constant, I did all of the work. Science, grab the data, build the APIs. You know, cause I had this lecture database. I also acknowledge graph. I need to connect with the large language model. So I was supposed to preview the API between the applications. Also, I designed out the pipeline from, you know, doing the commits, go to my branch and then deployment at the Azure using the Azure pipeline, of course. But at this personally, I was, I was the main responsible for make-to-work. Did you do fine-coming or reg? I was doing reg, in that case. It's a bit lazy. But I also did a fine-tuning in other contexts. Cause I was a total, I need to pull all the data from call transcripts. And that's pretty hard. So I had to do a fine-tuning like I had a couple of instance of call transcripts and a couple of instance of summarization, you know. Cause you need to summarize these call transcripts, you know, pull the information easily. And at that time, I used like a kind of fine-tuning using heavy-faced models. I probably, you are familiar with hand-faced pipeline. So I used to find a hand-faced pipeline to find the model for this specific test summarization. Okay. Perfect. How did you go about testing the models? How did you know that, you know, you're finally, your model is working. You mean about the hallucination measure, right? That's pretty hard. Yeah, that's pretty hard. We had a sample of data set, like I told you, I had the sample of transcripts in this suitcase, and then the call summarization. And I did a measure by similarity. I was using by myself mainly cause I was checking, that's a pretty hard test to do. Checking mainly the data. But I was, I tried to create similar data person as well, you know, doing the similar text, and see the cause in the scene, like between my output, the large-length model output, and then the real what I should get. What similarity did you use, do you? I don't know about the function, or about the... No, what type of similarity matrix? Oh, we got the cause in similarity, and we have some blue score at times, sorry. But I'll, yeah, it was cause in similarity the first and the main one, I just tried to do, you know, see the distance between, which is a simple, ugly distance, distance to see the distance between the words I got. Okay, it's working. I was also in fine cone at the time. Cool. So you looked like you got your degrees from San Paulo. So are you from Brazil? Yeah, I am Brazilian. Nice. Nice. Yeah, because I do, in my previous role, I did a lot of collaboration with teams in Brazil. They have been, which part? So, Uberlandia? Uberlandia? Minus? Yes, that's where our site is, so we did quite a bit of work there. Cool, very cool. They're here, very nice. Talking to you, very nice answers, what, they may be a... What are you looking for in the next role, ideally? What are you looking for in the next role, ideally? You know, ideally, I like to keep work with large-sized model files. You know, as a computer scientist, I believe the large-sized model was a big context-changer for humanity, basically. Now people are noticed, AI, they see, oh, it looks like a match-stuff, but not really. They are trying to do this for at least 50 years, no long time ago, they are research about it. And finally, with large-sized models, you can interact with computers with not a big technology. So, I think that's what a big context-changer for us, for all of us. So, I'd like to keep going with these field models and... Yeah, basically, that's it. Anything I can work with like, in models, human interaction in computer, I'd be very glad to work with them.", "start_char_idx": 6031, "end_char_idx": 9930, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ca72028-e622-4002-8af8-939c10a19ff7": {"__data__": {"id_": "0ca72028-e622-4002-8af8-939c10a19ff7", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "237e5cd2-face-4c5b-98fe-6d3614aef161", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "70855656d876b6115f2e42cf708cc88dba5de35d6fd7c5572ebfaae9ca678cac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e12bc1af-001e-4aff-ae2e-8ff2588909b4", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "e3d7281de29da8d9a6a153cd1a1588a0c33061809b1bf286c5af4aa3733a454f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "235920a3-09c8-4e04-a9a4-71105e238589", "node_type": "1", "metadata": {}, "hash": "1251b3406c9df88db6ff6e65397a4c387838790a69130e7e29b861e6fbaf76c8", "class_name": "RelatedNodeInfo"}}, "text": "What are you looking for in the next role, ideally? You know, ideally, I like to keep work with large-sized model files. You know, as a computer scientist, I believe the large-sized model was a big context-changer for humanity, basically. Now people are noticed, AI, they see, oh, it looks like a match-stuff, but not really. They are trying to do this for at least 50 years, no long time ago, they are research about it. And finally, with large-sized models, you can interact with computers with not a big technology. So, I think that's what a big context-changer for us, for all of us. So, I'd like to keep going with these field models and... Yeah, basically, that's it. Anything I can work with like, in models, human interaction in computer, I'd be very glad to work with them. What do you program in, Leo? Yes, I do. A lot of programming, actually. What language? What language? Well, my first language was C, and then the second on Java, and then I work with TypeScript, Lua for game, but my last one was Python. Cool. Those are the questions I had for you. What about you? Have any questions for me? I have a couple of questions, of course. I was wondering about the use case. I don't know if you were using it in this context. I'd like to know that. My first question. Yeah. Yeah, sure. I can share some information. So, as you said, when in the text I saw a hallucination, depression, hallucination, so, such GPT, LLM models are good at generating text, a lot of hallucinations. How do we get response of that useful and actionable? So, if someone asks, what should I do in this situation in the form? The recommendation should be, not a random thing, someone has to go and Google it again by actionable. That's what we wanted to get. So, it is a kind of chatbot for agriculture. Something like that, yeah. I was curious about me. It's not my resume, but I am also a agriculture technician. My high school, I was kind of an intern at, an intern at, an intern at school, where I were leaving this school and working this school. So, I was a agriculture technician the first start my major degree. Yeah, so that's very nice to know. So that's a nice background. But now, so that's what we are doing, and then document some other issues there. So quite a bit of a no-peer task for there that you think about it. So we have a bunch of them aligned, and then how do we make that actionable, right? Making sure no hallucinations are there, making sure how do we have a knowledge representation, how do we make sure we have full knowledge, because anyone can ask any questions, right? I agree. Because as you know, as we know, so you want to provide reliable books and reliable information. So that's what we are about, and that's what we are trying to do. Ah, that's super interesting, of course. Many friends here. So what I understand, the first goal here is like to make sure they like to make a model, stay like honest, so they context and so that's it. Right, and you see we're here, Missouri, Convoys, which the application should be deployed here, and used here. So that application will be deployed in cloud, but you know, our headquarters is here, right? So you would have seen that in our Linberg, Linberg and Lado, we have the big headquarters, so that's where we meet and you know, you have one. I saw some site on Grip Cur. Is it that? Grip Cur? Yes, that's the same. Yes. Interesting. Wow, brilliant. Mostly about the person who did that, see my questions, and you can't say about next steps, maybe. Yeah, so the next steps would be, so it's a two-step interview process. So today's the first one. You would have another one with a team. For that, we expect you to get possible present something. It could be a dissertation, but it could be not any confidential company things, but if you can give a 20 minute presentation of whatever you have done around the text, it would be ideal. If not, something is ongoing.", "start_char_idx": 9148, "end_char_idx": 13080, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "235920a3-09c8-4e04-a9a4-71105e238589": {"__data__": {"id_": "235920a3-09c8-4e04-a9a4-71105e238589", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "237e5cd2-face-4c5b-98fe-6d3614aef161", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "70855656d876b6115f2e42cf708cc88dba5de35d6fd7c5572ebfaae9ca678cac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ca72028-e622-4002-8af8-939c10a19ff7", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "5545ed186b2496f5fe25b51e16b2e60cd9a73401fe74e318f5814fb3f428aa4e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "21141025-dabc-4695-b42c-d072f483f826", "node_type": "1", "metadata": {}, "hash": "425ceb6484302bb425741edf321930248d1687e8c93a5beb6f4968dba75c67d0", "class_name": "RelatedNodeInfo"}}, "text": "So you would have seen that in our Linberg, Linberg and Lado, we have the big headquarters, so that's where we meet and you know, you have one. I saw some site on Grip Cur. Is it that? Grip Cur? Yes, that's the same. Yes. Interesting. Wow, brilliant. Mostly about the person who did that, see my questions, and you can't say about next steps, maybe. Yeah, so the next steps would be, so it's a two-step interview process. So today's the first one. You would have another one with a team. For that, we expect you to get possible present something. It could be a dissertation, but it could be not any confidential company things, but if you can give a 20 minute presentation of whatever you have done around the text, it would be ideal. If not, something is ongoing. So the question is whether you would have any slides or we are not testing it. But prepare something if you can reduce what you have. That would be great. So I wanted to check with you whether you might have something here. All nice. So is it this called Open, the subject? You had a specific subject for the presentation. Any old project that you have overcome would be ideal. And if it's NLP, that's even awesome. Or mission learning, that would be great. So yeah. Well, interesting. Yeah, I have something to build on this way. And I can present that totally. The same. Perfect. And then we would perfect. And then we would have a coding test. You have just to be five feet. You have a computer science background for a long time. It's to be a easy, easy thing. You should just knock it off. Yeah, hopefully. Yeah, that would be it for you. I would be surprised. And then they would make take about a few questions here and there. You can talk to the team Christian answer questions and then go from there. Nice. What's our next step? So for sure. Okay. Sounds good. The last question is how, you know, if things go well, you know, when is the earliest or when can you start? Yeah. Anytime. As soon like. Basically I can join now. I can't wait. Okay. Sounds good. Okay. Any other questions you might have from you? I think that's all for now. I'll save some questions for next step. Sounds good. Thank you for your time. Very nice talking to you. Okay. You should hear from us for the next round. So okay. Nice. Thank you very much. Appreciate it. Thank you. Take care. Very nice. Yeah. Vendor. Let's call. He's not a call. He's not a vendor. He is the chief data scientist. Looks like a vendor. Yeah. I know the very cool guy. Yeah. I will remind you. If you the last thing you should say is their name. Even if it's hard. I don't know how to spell that name. It's right in front of the chat. So. Yeah. Bala. Pass and. Yes. Balance. Yeah. Even if you just make an effort. It's very appreciated. I tried my best. I think that's what I'm going to say. I'm going to say. I'm going to say. I'm going to say. I'm going to say. I'm going to say. I'm going to say. I tried my best to split it for you. Yeah. I did not understand if you tried to put the name here. Or it was to me to try to read that. Bala. That's. Bala. That's. For. Bala. That's. That's. That's. So. So Leo, what we're going to do is. When we get this interview. Mauricio, I need to know in advance what I'm going to do is. I'm going to give you one of my toys. And this particular toy does something really cool, which is. You give it a book. And then it becomes an expert and you can you can, you know, query it and stuff like that.", "start_char_idx": 12316, "end_char_idx": 15780, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "21141025-dabc-4695-b42c-d072f483f826": {"__data__": {"id_": "21141025-dabc-4695-b42c-d072f483f826", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "237e5cd2-face-4c5b-98fe-6d3614aef161", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "70855656d876b6115f2e42cf708cc88dba5de35d6fd7c5572ebfaae9ca678cac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "235920a3-09c8-4e04-a9a4-71105e238589", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "9232147643841d9fce3308c521db1882625a180ffc5122a102d252d672477217", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4345dc0a-f359-4348-bd8e-d2cb7a87d076", "node_type": "1", "metadata": {}, "hash": "5941d624eb222ec42801650953d3975f183d0af91cd336bdca051b05443fe424", "class_name": "RelatedNodeInfo"}}, "text": "I'm going to say. I'm going to say. I'm going to say. I'm going to say. I tried my best to split it for you. Yeah. I did not understand if you tried to put the name here. Or it was to me to try to read that. Bala. That's. Bala. That's. For. Bala. That's. That's. That's. So. So Leo, what we're going to do is. When we get this interview. Mauricio, I need to know in advance what I'm going to do is. I'm going to give you one of my toys. And this particular toy does something really cool, which is. You give it a book. And then it becomes an expert and you can you can, you know, query it and stuff like that. So it's a simple, a simple program, but it goes through all the steps. It's my training video. And. And that will definitely do. Hello. I don't know. Somebody behind you saying hello. Who's that? He's my colleague. He's Ivan. Ivan. Ivan. Ivan. They're looking for you. Pueblo. Is a Jaime. How's that? Hi, Ivan. Bye. A quitos. A quitos. Entendemos espa\u00f1ol. En que algunos hablamos. Hablamos. Deberchief. Yeah. And some of us understand Portuguese. And when we're drunk enough, we speak it. Yeah. Indeed. Indeed. I feel that that that that especially when I drink too many guipinines. Mm hmm. Yeah. Almost. Or he comes. Yeah. It's all it's all everybody. If I have a friend Robert is not Robert is Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. iht a few people. For example, that we're only going to say Matt Does recessions or others and where it has- Brandy will get in the nose. Must be low. I was for serious changes in the countryside. Definitely not. Which is also never back in the RBG\u043c\u0435\u0440\u0438\u043ahet. regardless. We never think it's as a provisionary measure. But it's not over here. We all know it's the intention that we are gonna speculate. It's not easy to think about that. How does it seem to narrate their regard them? O. We're not necessarily trying to say the requirements. Man, I have no clue if it's a difference in modernization. Yeah, they know how to live a little of a samba, a little bit of steak, a little bit of kashasa. That's it. That's all you need. Maybe a beach. Definitely. Definitely. That's the best world. That's the best in the world actually. All right, gentlemen. It's 930. Thank you. Thank you, both of you. On a Friday. Have Friday. I only did this for you, Leo. Otherwise, I'm going to find it. I would have told them, hey, I'm sorry. It's Friday. Yeah, I really appreciate it. Okay. No worries. I know I'm glad. I appreciate it, Jan. Okay. I'm going to see you. Good job. Thank you, guys. This was great. This is this is for you. It seems to me. Yeah. I hope so. And you can go on. We've got moving. It's here at home without me now. Actually, you're doing great. You're doing great. Thank you, Jaime. We really appreciate it. Everything I'll keep you posted. As you may know, please stay safe. You guys. All right. See you in Monday.", "start_char_idx": 15171, "end_char_idx": 18098, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4345dc0a-f359-4348-bd8e-d2cb7a87d076": {"__data__": {"id_": "4345dc0a-f359-4348-bd8e-d2cb7a87d076", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "50b1cfb7-2331-459d-a905-e1740658bc20", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "2378fc05910d66d3df707a08449be374c3cd1439d5217cc9d63cfea0aebc3e47", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "21141025-dabc-4695-b42c-d072f483f826", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "1f8c9528012cced8a1f15c71f8f6da5d264c7cad69808aee22ab8aafecb76e73", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "653ea791-6357-43f9-9b6f-a0756c58305e", "node_type": "1", "metadata": {}, "hash": "7b4cbc7007450490ded83a795f3d88ad41445ca01aea5d61e41f875614f0feee", "class_name": "RelatedNodeInfo"}}, "text": "I will mute. I can see your message. Good luck. Thank you for having me. Thank you. Thank you. Thank you. Hi, Liu. Hello, Mike. I'm doing all right. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. Thank you. Thank you. I'm sorry. Thank you. Thank you. I'm sorry. Thank you. Thank you. Thank you. Thank you. Thank you. I think I'm a lot of say what it is. I'm Jodi. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I'm using my API key here. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I'm saying, if you don't know, you say, I don't know. I don't know. I don't know how I'm explaining. I don't know how I'm explaining. I don't know. I don't know how I'm explaining. I don't know how I'm explaining. I don't know how I'm explaining. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I can't get my text in the query. I have the key first chunks. I can't get my text in the query. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I was using catchPTAPI, but I was doing some experiments with Yamato model. I was doing some experiments with Yamato model. I was doing some experiments with Yamato model. I was doing some experiments with Yamato model. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park.", "start_char_idx": 1, "end_char_idx": 3011, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "653ea791-6357-43f9-9b6f-a0756c58305e": {"__data__": {"id_": "653ea791-6357-43f9-9b6f-a0756c58305e", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "50b1cfb7-2331-459d-a905-e1740658bc20", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "2378fc05910d66d3df707a08449be374c3cd1439d5217cc9d63cfea0aebc3e47", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4345dc0a-f359-4348-bd8e-d2cb7a87d076", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "e348a9e0553f904ceb482ae5d3c5be2d39115a36116d3cf355a3ff16c34c1f32", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8e06ae75-cb32-45b0-a22b-6ad6ff16b001", "node_type": "1", "metadata": {}, "hash": "246dedfe2f7af6a5dc67aa1aa7e8fc881f85c1457332be370afbc07470cfdc49", "class_name": "RelatedNodeInfo"}}, "text": "I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I was using catchPTAPI, but I was doing some experiments with Yamato model. I was doing some experiments with Yamato model. I was doing some experiments with Yamato model. I was doing some experiments with Yamato model. I have the key first chunks. I have the key first chunks. I have the key first chunks. I have the key first chunks. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park.", "start_char_idx": 2298, "end_char_idx": 5536, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8e06ae75-cb32-45b0-a22b-6ad6ff16b001": {"__data__": {"id_": "8e06ae75-cb32-45b0-a22b-6ad6ff16b001", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "50b1cfb7-2331-459d-a905-e1740658bc20", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "2378fc05910d66d3df707a08449be374c3cd1439d5217cc9d63cfea0aebc3e47", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "653ea791-6357-43f9-9b6f-a0756c58305e", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "f3a72678f7c34e06f5c706596e2184f551e4289c9fd54320bcd22354a3f12c81", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "65f74eb4-4a88-4100-9acc-7cc0fe386957", "node_type": "1", "metadata": {}, "hash": "4877f8d955a551a3ec4ed4980c423a88f79f27aa30c1b45ed143e4884737c2e4", "class_name": "RelatedNodeInfo"}}, "text": "I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. I should be at the park. Thank you all the best. I love the fact that the PhD in the information retrieval was so terrified of asking a question about it. Angela was terrified of asking you more. Yes. I love the Linux stuff. I think the one thing we have to be careful with in the future is the first time we spoke. We have to be careful with the policies. We have to be careful with the policies. We have to be careful with the policies. We are getting them. We are getting them. We are getting them. We are getting them. We are getting them. We are getting them. We are getting them. We are getting them. I wanted you to ask questions about the agriculture. I am very surprised if you don't get a call tonight. I wanted you to ask questions about the agriculture. I think this is a good question. I think this is a good question. I really like the way you work. I think this is a good question. I was having a word with Arturo.", "start_char_idx": 4912, "end_char_idx": 6816, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "65f74eb4-4a88-4100-9acc-7cc0fe386957": {"__data__": {"id_": "65f74eb4-4a88-4100-9acc-7cc0fe386957", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60dcd420-d1cd-424b-a926-8ab307c70a51", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "d78eb537b4c125ab152a5b46361f8ba890b8d6813b4f7413b0039f24cb7d0c59", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8e06ae75-cb32-45b0-a22b-6ad6ff16b001", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "11faf6603dbdfdfe5afcd82fe115123f151aa9333b89e67f84eafd97e7e168c9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "08cb6190-31e7-4262-89e1-25a613ef29f4", "node_type": "1", "metadata": {}, "hash": "0410fa7c4c0c6f5bb45618a115c5694ec8dd51fc3871bec31a81df97789fad60", "class_name": "RelatedNodeInfo"}}, "text": "1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5%, 02%. 1.5%, 02%. 1.5%, 02%. 0.5%, 02%. 2.5%, 02%. 4.6%, 02%. 5.5%, 02%. jod\u8a18\u5f97 incit Main ter Government on dir et intensise vieakardat emtill Switzerland et gu EBAD PASI Spirit Ja, me combinei\u0438\u043a s\u00f3kunpa, confident of the technology aromansed in your 10 studied Berlin veit hane in various projects. My most recent project, I was working with Abit Healthcare, healthcare company. We helped the company to move their data to the cloud, to AWS precisely. And we were using Snowflake and we also used SageMaker to be able to help the company to build a fixed summarization UI. So this project, overall objective of this project was to be able to increase the speed of solving the problems related to enormous clinical notes that were coming into the QA department. So they had to look for a faster method rather than doing it manually, which was done. I also worked with JFRIMANS Group, it's a finance company. I was working with the equity research department. We did some time series forecasting and stuff. So we used Arima, a cash model, stuff like that. And I've worked with the QA group of companies. I've been in several projects, ranges from traditional machine learning project, LLNs and the large language. And also MLOPS operations have been involved in those in my career. And also in some data engineering kind of jobs that have been. So I've got across a wide variety. And I think I would be of great help to this new project that I'm about to get into. Right. It looks like you have a lot of variety under your belt. Like I see that. So how long have you been in the field? In the field of data science specifically. And why it looks like. Yeah, I've been mainly focused as a data scientist in my career path to mostly involved with cleaning data, eds and building models and deploying models. Yeah. So let me ask you this question. So what was the most challenging. One of the most complicated clean data cleaning tasks that you have worked. Encounter because that's where it all begins. So what was the most tedious data cleaning that you've done. Among in your experience. I think one of the projects worked with Jeffery Finance, the one of the jobs we did for an end client. The job they had data coming from. Various sources. I mean, let me see the most tedious cleaning job I've done. Has been healthcare data to clean. So that has been the most tedious. But in terms of. Future engineering, future, and everything I had this project that I worked with Jeffery Finance. It was so difficult in terms of. Joining data from various sources and trying to leverage the different futures, create new futures because. It was so sketchy and stuff like that. That was also a challenging one that time because. Gotcha. Yeah. So it looks like you've worked in multiple fields too, right? So healthcare finance and. Which other demands have you worked with? Yeah, working mostly the both of them. Health care finance. I'll be. Okay, so let's come to the large language models, right? So that's the current trend right now. And that's where. Janai and large language models. So what's your experience in this domain? What have you worked on so far? This is I think. So far, this has been one of my. That my at domain is especially especially as a domain that is very pretty new. And everybody was learning when I go to. A big first to build a text from realization UI. We we use frameworks that we pretty new like. Lang chain. We use foundation models like. Flanck T5 and stuff like that. So which model? I heard yeah, we like. Yeah, we use flanck T5 from hooking face. Yes, okay, gosh.", "start_char_idx": 1, "end_char_idx": 3675, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08cb6190-31e7-4262-89e1-25a613ef29f4": {"__data__": {"id_": "08cb6190-31e7-4262-89e1-25a613ef29f4", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60dcd420-d1cd-424b-a926-8ab307c70a51", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "d78eb537b4c125ab152a5b46361f8ba890b8d6813b4f7413b0039f24cb7d0c59", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "65f74eb4-4a88-4100-9acc-7cc0fe386957", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "7e6a8e1273781dc6b198c506d168d470879c7f0d1a3d6e189d89b9abeb0e15aa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bf4e42de-7b8c-4daa-8ec5-f5c49e0a01ab", "node_type": "1", "metadata": {}, "hash": "b70c6f1f9ebb39e0876fb8c799678a8047ddd91fb0e31ac1d912e90b342e19ec", "class_name": "RelatedNodeInfo"}}, "text": "Health care finance. I'll be. Okay, so let's come to the large language models, right? So that's the current trend right now. And that's where. Janai and large language models. So what's your experience in this domain? What have you worked on so far? This is I think. So far, this has been one of my. That my at domain is especially especially as a domain that is very pretty new. And everybody was learning when I go to. A big first to build a text from realization UI. We we use frameworks that we pretty new like. Lang chain. We use foundation models like. Flanck T5 and stuff like that. So which model? I heard yeah, we like. Yeah, we use flanck T5 from hooking face. Yes, okay, gosh. Yeah, and all the computational challenges we had to select the right machines. See for machine failure machines and stuff like that and. The issues. Yeah, so our overall job and also working with the QA department to be able to collect. Label data set in this project because we needed. Data set that we humans labeled and that's what actually took us a lot of time because. This department had to be able to do it and save it for us and every time the Q8, a particular clinical note that came in like a nurse sense in their notes because. These guys have hundreds of clinical notes coming weekly and they have to kill the notes, and pay these clinicians and also build these notes that coming from nurses, doctors and other clinic clinicians. So we had to work with them try to work with them to get this. Label data set humanity labels like from their own perspective. And when they gave it to us, we had to clean it. We use. Sashmik and notebook and precisely they used the save this data on S3 using cloud formation. And they have a whole architecture that we could have access to it, pull it in our department. And we had to remove using beautiful soup. We had to remove some HTML if they were present and using rejects removed. Textured data that we present using NLP, NLTK library to remove all of these topways, non like data from it. The cleaning process was really very difficult putting it right. And then now we had to use the models that we used using Hogan face embedding. We use Hogan face embedding. It was pretty good not now that while we were doing some POCs using these new technologies like. Even open AI came in open and embedding was way better and faster. So when we did them embedding, then we then fine tune our model. And then we also had a lot of challenges. You know, he passed off like that security and everything we had to make sure everything was right. What kind of practice were you enforcing before hand to make ensure safety security things like this? Yeah, you know everything that works in Abik is in accordance to he put like right from the handling of the data, the level of the QA department, the respect or hyper regulation, the make sure personnel identifiable information were hitting from like diagnoses. We use codes ICD10 and stuff like that. And all of the most essential information we try to capture semantics of the most important information that we could get from the clinical notes that was submitted by the nurse. To make sure the nurse actually did the writing and to make sure the nurse actually went and saw the patient because sometimes nurses can bring notes that don't match up to the standards and stuff. So all of these ethics, even at the level of ethics and everything we respected and yeah. So when they push it down to S3, you know, there we only have access to a single key security logins that are going to be to our department. And so it's generated once when we want to assess it in terms of privacy. So the whole architecture was built using automated using cloud formation and stuff and then. So how is it compared to the so you I know you're working with the healthcare data right now with the nurse notes and out. But before that, when you are working with financial projects, a working of measures where you're taking. Yeah, we'd Jeffery finance one of the things that we do at the because it's a large department is the equity research department. We used to we work with derivatives that is we were modeling the volatility right so we stock data is available for the company. So we usually get the OHLC that is open high low and closing of the stock from which. These are these are pretty open source data like you can get it from your finance.", "start_char_idx": 2987, "end_char_idx": 7400, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bf4e42de-7b8c-4daa-8ec5-f5c49e0a01ab": {"__data__": {"id_": "bf4e42de-7b8c-4daa-8ec5-f5c49e0a01ab", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60dcd420-d1cd-424b-a926-8ab307c70a51", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "d78eb537b4c125ab152a5b46361f8ba890b8d6813b4f7413b0039f24cb7d0c59", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "08cb6190-31e7-4262-89e1-25a613ef29f4", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "ef1d37ecb9b5c8ed44ebfce02f808519f298dbed46e4f69bfdf8c31067654dc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0e9f8e30-d860-4473-8344-0a0ae61600e4", "node_type": "1", "metadata": {}, "hash": "5d300d5bbc105d8a9ba4beb6feb47353fdd8f3143b7bb8b307a6119bec5a3334", "class_name": "RelatedNodeInfo"}}, "text": "And so it's generated once when we want to assess it in terms of privacy. So the whole architecture was built using automated using cloud formation and stuff and then. So how is it compared to the so you I know you're working with the healthcare data right now with the nurse notes and out. But before that, when you are working with financial projects, a working of measures where you're taking. Yeah, we'd Jeffery finance one of the things that we do at the because it's a large department is the equity research department. We used to we work with derivatives that is we were modeling the volatility right so we stock data is available for the company. So we usually get the OHLC that is open high low and closing of the stock from which. These are these are pretty open source data like you can get it from your finance. You can get it from any stock data this and they were not too sensitive. But security is always very essential in terms of who has access to the data at what time and there were no buyers in terms of how we approached the data and they were finished. So when we have this data, we calculate what we call the realized volatility using gaming class volatility is a kind of function a magnetic function that takes us parameter the open high. Close and start of the of the stock. Yeah, so we calculate this volatility and we then model it is a time series data volatility and time because volatility is price changing over time so change of price with time. Then now we use a REMA we can now get what we call if forecasted volatility or predicted volatility which helps the company to mitigate risk whenever they want to make some kind of investment some kind of trades and stuff like that that has to be done at the level of the equity research department. So those were the kind of things we're doing the we were more than this kind of data and stuff like. Let's switch back to language models so you mentioned. Lama rate you said Lama not lama flanks or lunch. Oh yeah, lunch. So what do you what is lunch and what's it used for and how much how much are you from there with it? Lunch and Lama index. I mean lunch and very familiar with it right now because it's pretty what I've been working with so lunch is a framework that helps you to change. LLM with prompts and template so and it makes connections with several different LLM's like you can connect it with it has connectivity with different foundational models from different. So this is like you have bedrock like we just mentioned bedrock. Yes and API that you can connect with lunch and you have as your opponent you have a text AI in GCP you have a whole game phase you have a opponent itself so this framework you can get access to this different foundational models depending on the project you are working with. Now we were working with flanks if I is is the less a general purpose model and encoder decoder model so using this we connected it and we also use the hogging phase embedded in lunching because from lunching dot LLM's you can import these models from these frameworks and using lunching embeddings you can import hogging phase. We open AI embeddings and stuff like that so this framework also helps you to connect to different databases you can make your your LLM more intelligent like that's why they stop that we call on because there are two approaches to make a model more customized you can either use a supervised approach which is fine tuning or you can use what we call retrieval or minted. Generation that is rack so in the in the rack that we used because rack is mostly using in a big way we wanted to build something like a chat board and stuff like that that we have some proprietary documents we chop them down into chunks and then chunk size and then we embed them because you have to convert them to numerical values. So you mentioned the two are like model is what you are currently using right. The problem we have to we have two stuff that we are doing so the rack is mostly used when we want to have access to proprietary documents like a chat board right but the text memorization UI is super valid. This is supervised approach that was done there using label data set to fine tune the model so yeah. So what kind of benchmarks are you using are you planning to use that things like that to evaluate your models efficiency.", "start_char_idx": 6576, "end_char_idx": 10922, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0e9f8e30-d860-4473-8344-0a0ae61600e4": {"__data__": {"id_": "0e9f8e30-d860-4473-8344-0a0ae61600e4", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60dcd420-d1cd-424b-a926-8ab307c70a51", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "d78eb537b4c125ab152a5b46361f8ba890b8d6813b4f7413b0039f24cb7d0c59", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf4e42de-7b8c-4daa-8ec5-f5c49e0a01ab", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "6d585e8339cf2d95c0826b6ebd027c2c401cfde8d28fbff070d1dc75f896fdf3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c5bd60d7-69f9-4ae7-9fe4-dad4639b11c9", "node_type": "1", "metadata": {}, "hash": "b74ad5eea140479e9c5c3567bee1f3ff901b374243f6b9c629ee9c525679294d", "class_name": "RelatedNodeInfo"}}, "text": "Generation that is rack so in the in the rack that we used because rack is mostly using in a big way we wanted to build something like a chat board and stuff like that that we have some proprietary documents we chop them down into chunks and then chunk size and then we embed them because you have to convert them to numerical values. So you mentioned the two are like model is what you are currently using right. The problem we have to we have two stuff that we are doing so the rack is mostly used when we want to have access to proprietary documents like a chat board right but the text memorization UI is super valid. This is supervised approach that was done there using label data set to fine tune the model so yeah. So what kind of benchmarks are you using are you planning to use that things like that to evaluate your models efficiency. So the best benchmark that we used was human evaluation or human evaluators does the best I mean it's one of the most appreciated now in the market even though we used the stuff like blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue, blue Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Okay, another about, um, these, um, these , um, these, this, this, this, this, this, This, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, these, these, this, these, this, this, um, take to, and um, and one step down to them, the pressure, and uh, the pressure, and my, uh, the speed of the pressure of per business equals change with the, uh, retrieva of the bed, the pressure, the\u7c73 pressure, the office mode, machine updates, the editing rate of the pressure good, uh, the normal restrictions, the case value of them, what the A, the ground, the one that Dank continua for \u0411\u0443\u0434 Your500. Rick Hooking performance skills. It was a basic measure, plants, uh, rapid. kind of integrated Miller, uh, single submitted Moldel is or not, but sometimes the similarity or the same words that much is might not actually bring out the best sense in what we are looking for in the summary. So that's why human eye has to go there and try to see if the model is actually making sense. So we we used all of these metrics in terms of how you were trying. That's good. So you have pretty much familiar with Python then you since you're used language and so it's Python your main program language. Yeah, yeah, Python is my main language followed by. Scala. Yeah, Scala as well. Okay, gosh. And it comes to lambda implementation. So do you know what do you understand? Do you have any experience dealing with. AWS lambda yes, yeah, yeah, you want to explain what it is. Yeah, so lambda is used to orchestrate. Let's see. We are building a code so lambda you can it has. It's used for automation. You cannot to meet the whole process is it's a code it could as a service. So it's a fully managed code as service that AWS provides several. So we can code either in Python, either in. Different languages is supposed different languages. I think it's supposed to be a. But I'm more into Python that is the language that I use. So like I was working on one project that we were working on a POC that we had to use. We built a bottle client because lambda you would use.", "start_char_idx": 10077, "end_char_idx": 13907, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c5bd60d7-69f9-4ae7-9fe4-dad4639b11c9": {"__data__": {"id_": "c5bd60d7-69f9-4ae7-9fe4-dad4639b11c9", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60dcd420-d1cd-424b-a926-8ab307c70a51", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "d78eb537b4c125ab152a5b46361f8ba890b8d6813b4f7413b0039f24cb7d0c59", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0e9f8e30-d860-4473-8344-0a0ae61600e4", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "f6ea41d2fa334cfaeda116c7294eb74697c9736c560f419f747c8d21dd77417f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b6e8797-b55b-498a-aad2-58baa790fc8b", "node_type": "1", "metadata": {}, "hash": "5cce933910bae6f92a266591a726c92b7a4850be0882090eb6accdeb18fd8fca", "class_name": "RelatedNodeInfo"}}, "text": "Okay, gosh. And it comes to lambda implementation. So do you know what do you understand? Do you have any experience dealing with. AWS lambda yes, yeah, yeah, you want to explain what it is. Yeah, so lambda is used to orchestrate. Let's see. We are building a code so lambda you can it has. It's used for automation. You cannot to meet the whole process is it's a code it could as a service. So it's a fully managed code as service that AWS provides several. So we can code either in Python, either in. Different languages is supposed different languages. I think it's supposed to be a. But I'm more into Python that is the language that I use. So like I was working on one project that we were working on a POC that we had to use. We built a bottle client because lambda you would use. Boto three you import both to three and then when you use both to three you can view a bottle client with betwork for example betrock API if you have selected. The model so betrock run time to be precise. Maybe I might have you so we build a both betrock run time and from which. If we are using for example AWS gateway we can prompt it at the gateway and they are on lambda so lambda we can write all the function and from the client we can define the prompt that from the prompt using API gateway whenever the user has write something at the prompt when we customize the prompt. It would trigger the lambda function which would send a message to the LLM either in betrock we can use maybe AI 21 or maybe cohe depending on the task that we are working on or Titan. So it would trigger in an API call to the model and the model will perform the task. Let's say we are performing image so the lambda ought to miss the whole process for you and helps you to define the whole task and there is an extensive documentation in lambda in AWS that depending on the task the run time the client that you want to create maybe connecting with S3. You have to create another client connecting with betrock connecting with SageMaker all of them so lambda can give you a whole automated process that can trigger various tasks and make your work easy to do. That's it. So let's see. So what are the benefits and limitations to you see from the lambda AWS lambda point of view what kind of way do you feel like it's good and very fast. What do I see is good. I mean it's good in terms of the fact that you can make the process on real time seamless if I might use that term you can make it on. And the inconvenience that I can see lambda has. I think if let's say we are working out of AWS let's say we are working in we have a third party like snowflake. I don't know how compatible it is with all that party vendors I think it might be limited in terms of compatibility and also execution time lambda is not doesn't have some kind of distributed kind of computing that maybe can be that fast like because several less because several less and no minus forces are to issue. Yeah. Yeah. So for for a chart based application for another one fear using like a chart based interface and application do you think that's a good idea to utilize lambda or no. It depends on what extent yeah that's a good one to what extent yeah. Yeah. It depends on the amount of users that are assessing your your application that that would depend because at the level of API is less. Let's say we have an application that we have one the users or less we might go for it or if it's maybe a batch kind of process that we collect and whenever this body fees in the real time deploying deployment environment that the users are really hard. We might maybe go for something different depends on the workload. Yeah that's good. Let's close it as specifically with AWS lambda and things like that with one question. So how do you ensure the security in terms of especially when dealing with a lambda functions that are interacting with sensitive information for in ML use cases. So AWS is a fully managed platform as we said so the I am rules are very important it has policies and everything so when you are configuring the I am in lambda lambda when you go to configuration security you would put the policies and you would specify. The security the how you want who can access it in when can it be access and everything you can define the policy based on the rules so let's say I have a main role I can give it for access if you if you did because in in the typical production environment every.", "start_char_idx": 13121, "end_char_idx": 17564, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8b6e8797-b55b-498a-aad2-58baa790fc8b": {"__data__": {"id_": "8b6e8797-b55b-498a-aad2-58baa790fc8b", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60dcd420-d1cd-424b-a926-8ab307c70a51", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "d78eb537b4c125ab152a5b46361f8ba890b8d6813b4f7413b0039f24cb7d0c59", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c5bd60d7-69f9-4ae7-9fe4-dad4639b11c9", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "03c2705c1eb8766978f52b8b32347e887a2c3727c37f135ca9df73f90f699011", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b94ec2a1-35f0-434a-998e-a02c3bd059be", "node_type": "1", "metadata": {}, "hash": "bb93e8bf230d5d0a781b0001b6c7870375e90ae46e3b71e4150275e60fb47f4c", "class_name": "RelatedNodeInfo"}}, "text": "We might maybe go for something different depends on the workload. Yeah that's good. Let's close it as specifically with AWS lambda and things like that with one question. So how do you ensure the security in terms of especially when dealing with a lambda functions that are interacting with sensitive information for in ML use cases. So AWS is a fully managed platform as we said so the I am rules are very important it has policies and everything so when you are configuring the I am in lambda lambda when you go to configuration security you would put the policies and you would specify. The security the how you want who can access it in when can it be access and everything you can define the policy based on the rules so let's say I have a main role I can give it for access if you if you did because in in the typical production environment every. Department has their roles and so you can block access to data engineers and give us just to the lessons in the roles that you assigned on the lambda and whenever they make that call that so the I am is very important and also in terms of network security you can also do that you can maybe use eventual private cloud and stuff like that. And there is also possibility for encryption if it's in terms of data and other yeah. So do you have experience dealing with the AWS lambda for a lambda service in fine shooting models and all. And that is a different you do you are using that in your current scenario basically yeah we build a POC as I mentioned that we use AWS gateway lambda and bedrock this is pretty new stops especially bedrock pretty new yeah so it was a POC and based on it we were able to use it so that's why I did you got you. So you are familiar with GitHub or yeah that's not just a business. We live and breathe and forget I mean yeah well if you use it is you would have some some print knowledge for vision control as to if you commit you yeah so like that yeah but as much as we learn about gate we keep forgetting whatever we learn just really you got to keep on looking for it. So coming to the vector databases you guys using vector databases and knowledge drafts anything like that in your current POC had no you have any experience. Yeah I walk a vector database yeah we did as I mentioned before when we have to do with proprietary documents as I mentioned yeah we have to push it to a vector database after embedding after embedding. And then we index it vector database like pine cone stuff like that that's the one we use face chroma you have orders yeah so when you index it uses what we call similarity search or yeah you also use semantic search from the database that is index and then yeah it's good for building chat boards. I mean in this new age that we are everybody is looking forward to incorporate chat boards in their businesses because the cost of calls and everything why not just go for a chat board that you would just have one AI that is giving you all the results rather than recoding 50 people to be taking random calls from people yeah. Right that right that wave as it is going. Yeah so everyone wants to be part of it everyone wants to be the new technologies but we are keeping up with it because it's changing the world right now yeah. And the next so what kind of deep learning frame works at your family with what you have what what frames we have experienced dealing with in terms of the you have experience in deep more deep learning models and I do I do so I've worked with R&N and LSTN LSTN when I was working with Jeffries. As I mentioned that we're working with some time series data yeah right when when stores get too complicated so I'm familiar with Keras by touch and I mean TensorFlow now is also incorporated with the rest we Keras so yeah. One final question and you close that up what is the what does it mean bias and variance trade off to you and how do you handle that. By us can you repeat that please one more time bias and variance in machine learning general principles fundamentals of machine learning bias variance trade off and how do you think we handle that. Yeah so bias basically is measures how closely the average predictions the models matches to the true value so and variance we talk about variability of the model predictions across maybe different data sets we start talking about maybe the distribution of the model. So how will you handle that in practice when there is a when there is either too much bias too much variance how would you handle that. So I mean the overall objective in machine learning is to have it as low as possible like low but yeah but in an ideal scenario it's you can never achieve that. Especially since you're going to be fine tuning models you fine tuning models are all they want so how do you maintain that in the models that you're fine tuning.", "start_char_idx": 16710, "end_char_idx": 21536, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b94ec2a1-35f0-434a-998e-a02c3bd059be": {"__data__": {"id_": "b94ec2a1-35f0-434a-998e-a02c3bd059be", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60dcd420-d1cd-424b-a926-8ab307c70a51", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "d78eb537b4c125ab152a5b46361f8ba890b8d6813b4f7413b0039f24cb7d0c59", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b6e8797-b55b-498a-aad2-58baa790fc8b", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "3982b88672fca54d124a98a2fb6afff1aac033c8464d3d1a2bb8b66e932e3804", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fe2b9dc0-e3d8-4db7-b3f2-8e0ec249351f", "node_type": "1", "metadata": {}, "hash": "236531eff2facadc9536ad8420ed469b9f578f02aa514687f9ab3e2326e21770", "class_name": "RelatedNodeInfo"}}, "text": "By us can you repeat that please one more time bias and variance in machine learning general principles fundamentals of machine learning bias variance trade off and how do you think we handle that. Yeah so bias basically is measures how closely the average predictions the models matches to the true value so and variance we talk about variability of the model predictions across maybe different data sets we start talking about maybe the distribution of the model. So how will you handle that in practice when there is a when there is either too much bias too much variance how would you handle that. So I mean the overall objective in machine learning is to have it as low as possible like low but yeah but in an ideal scenario it's you can never achieve that. Especially since you're going to be fine tuning models you fine tuning models are all they want so how do you maintain that in the models that you're fine tuning. So several techniques have been used in tradition I'm a machine learning like we can use regular regularization technique yeah you can use your cross validation and stuff like that yeah I say modeling like. In models like decision tree that have high we can use some assemble models that are and don't for it is there or boosting models that can. Yeah I mean at the lower level we can use the future engineering kind of stores and yeah that's good yeah well that's all the questions that's all the time we have. Just like you have a lot of experience so I wish you good luck with the next steps if they decide to move forward yeah alright thank you for your time and you will hear from Suda thank you thank you good luck good luck thank you too yeah bye bye. Okay Lauren good job is it Suda he said we are in Suda okay I think he was good yeah that's what I feel yes let's ask Ignacio he was from the call I guess yeah I'm right here. Yeah so he said will near back from Suda I don't know when but yeah he's the one who take care of it yeah I mean at the beginning it was going to be a video screen call with the manager but they really they really like your profile so they decided to go for a technical call so it means that they're really into you and I believe they never went well so yeah let's move forward with the second position for second round hopefully it's going to be a final. But I'll ask before I'll let you know this is going to be a final anyway I'm going to send a thank you thank you email right now to those okay alright thanks thanks guys no good job Lauren yeah good job but yeah bye thank you.", "start_char_idx": 20611, "end_char_idx": 23154, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fe2b9dc0-e3d8-4db7-b3f2-8e0ec249351f": {"__data__": {"id_": "fe2b9dc0-e3d8-4db7-b3f2-8e0ec249351f", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b94ec2a1-35f0-434a-998e-a02c3bd059be", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "742c4fb5629b4eb09a03de45bc563dde5ab0233f62237b3a8d65ffa0a8cf298e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "afcd0ecc-c85b-47a9-a721-62c6bd5e35f0", "node_type": "1", "metadata": {}, "hash": "478ab0629cfddc7c073f484b9dd81f91a7b526e668b2c41a5553cc862ac8a5cb", "class_name": "RelatedNodeInfo"}}, "text": "Where are you based, Lauren? Right now, I'm in DC. DC? Oh, you're in DC, okay. That's where you live or you are there because of your work. That's where I live. Oh, okay. I guess it's nine o'clock, so let's get started. You know, so probably one or two persons may join in. I'm present at even Radoo, right? You know, I'm based in Dallas. I'm kind of interviewing on behalf of Cerebra for the contract position with Vanguard. Right? So I'm not associated with Vanguard, but I'm kind of helping screen the candidates and the position for Vanguard. Okay. Okay. So is this like the final round or is does it? No, there will be this is the initial round, if you will, right? You know, there will be interview from Vanguard. Okay. Okay. So I'm sure you would have seen the requirements. So, you know, this patient, yes, I so before we get started, I just wanted to hear from you about yourself. What are your interests? What motivates you? Yeah, my name is Louden. I'm a senior diversenities. Yeah, right now my area of interest is LLMs and Janie. I mean, it's taking over the world right now and everybody is really focused. So I'm really in active research in that area trying to dig more and try to get more. My most recent project with Abik, we're actually working on generative AI LLMs. We help them to build a text summarization UI. And this helped the company with the quality assurance department, which had manual jobs being done at the moment. They had to screen clinical notes manually. So we help them to facilitate this process using LLMs. So in my prior projects, I was working with Jeffrey Finans with the equity research department. We were mostly focused with time series and using some derivatives and stock data for the company. We were we used Arima, LSTM and some other manmatica functions to be able to capture market risk. I've also worked with supply chain management where we had to do some predictive analysis. I am using random forest models and its its tables here we use its tables and yeah. So globally, I've worked in both deployment ML ops and also some data engineering jobs. And I really have a wide experience cutting across various areas. And I think that looking at the current job description with which ties exactly with my area of research, I think I'm going to be of great value to this project and giving my best to make sure everything works well. Thank you. Nice to see you. You know, the specific requirement on pollution requires experiencing large language models. And you said you are currently doing research and helping advocate to do the text summarization and other things. So that's good. What kind of models that you have used are you using for a big? Yeah, in our big back, we use flank 35 from Hogan face is an encoder decoder model. So we part of the job which was really tedious. I was really tough was first to have label datasets from the company QA department, which was human level. That was what took us a lot of time because we had to fine tune the model, fine tuning that is customizing and now we have the concept of micro or small language models that you have to use some supervised approach. We did that and we deployed the model using stream lead for batch inferencing. So they can just put in the text and then get a summary. And yeah, so it was pretty difficult task, especially since the technology, the programmatic assets of the model and everything. Everybody was still in the face of developing and understanding everything with lime chain things were just happening. So we had to be able to integrate everything and use it for the advantage of the business and looking at what we were able to achieve using what we put in place. The company QA department had to invest less in terms of the difficulties they had with human resource and they could be able to do the job 10 times faster than what they were doing prior to all of those complications. And I mean, they are impressed and everything went well, but my contract just ended. So that's why I am now open in the market and try to look for the next opportunity still in this light of of Gen EI, which I saw this one and it's really interesting. So you picked up a plantify.", "start_char_idx": 1, "end_char_idx": 4202, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "afcd0ecc-c85b-47a9-a721-62c6bd5e35f0": {"__data__": {"id_": "afcd0ecc-c85b-47a9-a721-62c6bd5e35f0", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fe2b9dc0-e3d8-4db7-b3f2-8e0ec249351f", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "d22ab5440f78c51b05bcf47d6c4039971c2408822d86e24a96c9a943446dd756", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b41d4e23-791a-4643-ae55-1a8bb4e103f6", "node_type": "1", "metadata": {}, "hash": "bf8b04a1d8b7d11f77af73c671bc7ecbe2e33324b04e96b8701485d5657e45d0", "class_name": "RelatedNodeInfo"}}, "text": "And yeah, so it was pretty difficult task, especially since the technology, the programmatic assets of the model and everything. Everybody was still in the face of developing and understanding everything with lime chain things were just happening. So we had to be able to integrate everything and use it for the advantage of the business and looking at what we were able to achieve using what we put in place. The company QA department had to invest less in terms of the difficulties they had with human resource and they could be able to do the job 10 times faster than what they were doing prior to all of those complications. And I mean, they are impressed and everything went well, but my contract just ended. So that's why I am now open in the market and try to look for the next opportunity still in this light of of Gen EI, which I saw this one and it's really interesting. So you picked up a plantify. Okay, so what made through the process right from you know the problem definition right you this is what of manual effort goes into you know summarizing the clinical reports and other things that's the problem statement. So from there, how did you arrive at the solution? What kind of methodology that you use? How did you pick up a model? What kind of tools and frameworks that you picked up and how did you go about doing that and the process of from there to actually generating the solution, but me through the steps. Yeah, so when I got to a big what they were doing with that when the clinical notes because they have nurses, doctors and clinicians in the field would send clinical notes on daily basis. So when this notes coming, we have some clinicians in the office, we call them QA is in the QA department quality assurance department. They have to review these notes and then QA it validated it before the notes can be paid. That is the can be built and the clinicians can be paid. So now what we did was that this work was done manually they had to go through thousands of pages. So what we did first of all we use. We were working with the quality assurance department because that was the first part to get a level data set. Three trained models already exist in Hagen phase open AI. The reason why we choose Hagen phase is it's open source nature and it was really cost effective rather than using GPT 3.5 which existed at that time. Hagen phase also has Hagen phase embedded which is free. I mean even though it's a little bit slow than GPT that open AI embedded takes embedded embedded. So we choose Hagen phase which is flanked. I mean at that time you know beginning of 2022 like that time Hagen phase was released to very good not now that GPT has gave a programmatic access and it's really pretty more efficient and stuff. So that is why we choose flank C5 which was a very good general purpose model and code and it was really good for text summarization at that time. We had other options but that was the one that was really was really better and at that time also RAK was not yet a standard like retrieval of maintained generation. So it wasn't really a standard and many people had not come out so the most efficient approach at that time was fine tuning like model fine tuning that was what most of the research people published at that time we're talking about and it was what everybody was looking at at that time. So we choose the flank C5 model from Hagen phase we use Sashmaker in this project that was the cloud platform that we use because we could have access to a GPU machine that the T4 machine in Sashmaker and you know flank C5 is trained on about 11 billion parameters if I got it correct. So we were able to to to fine tune the model on Sashmaker and it was a little bit cost effective than other than we had other models that had more trainingable parameters than than flank C5 like we had farcon. Yeah we had farcon. Farcon is trained on more parameters than than so it was more difficult to to fine tune that one but the result if you look at flank C5 when we when we fine tuned it it was pretty good and based on all the research people that we published for text summarization we we either could use. On flank C5 or we could use palm there is this Google model palm Facebook has lama I think lama to lama had came out that time so no palm was not yet out at that time it was yeah it was lama it was farcon so but at the best bet was just bet at that time the.", "start_char_idx": 3293, "end_char_idx": 7708, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b41d4e23-791a-4643-ae55-1a8bb4e103f6": {"__data__": {"id_": "b41d4e23-791a-4643-ae55-1a8bb4e103f6", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "afcd0ecc-c85b-47a9-a721-62c6bd5e35f0", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "190d791d473d2d46c4d0ca325a089118e5d24d852104260f77e4b1950f6d7cc6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "85e725a9-9f1b-4b24-9110-1b579841cd7a", "node_type": "1", "metadata": {}, "hash": "e261dfdbc9adcb5b3bcae0ff160b36ac64cb444cffedf6667724ee96e6867937", "class_name": "RelatedNodeInfo"}}, "text": "So we were able to to to fine tune the model on Sashmaker and it was a little bit cost effective than other than we had other models that had more trainingable parameters than than flank C5 like we had farcon. Yeah we had farcon. Farcon is trained on more parameters than than so it was more difficult to to fine tune that one but the result if you look at flank C5 when we when we fine tuned it it was pretty good and based on all the research people that we published for text summarization we we either could use. On flank C5 or we could use palm there is this Google model palm Facebook has lama I think lama to lama had came out that time so no palm was not yet out at that time it was yeah it was lama it was farcon so but at the best bet was just bet at that time the. The bet was mostly for classification and this kind of problem because it was mostly an encoder based kind of model so that is why among all the models that we had at our disposal at that time flank C5 was one of the most ideal based on so many other parameters as I mentioned and so we went for it and then from Hogan face we imported the model and then we had to use. Months to have level did I said so we we're working in collaboration with the quality assurance department team and so they had to. Give us the data from a human perspective because whenever they get the text the summarized it manually based on what they needed the essential things they needed for them to validate that one. The clinician actually saw the patient that was very important to the notes that the clinician produce that is the diagnosis the procedures that the clinician used to take care of the patient and to see the patient were right and we they had something called plan of care so we had to see a good plan of care and everything was good so. The gave us the summaries based on what the way. Consent with in the the notes and from the roll notes so we had the roll note and the summary the roll note and the summary and then. We now loaded this data into session we cannot book we clean the data we removed non textual data using rejects we remove. If there were any HTML using beautiful so we removed using energy key library we cleaned the text we removed stop words remove everything and then tokenize it. And then perform all the NLP tax then we use the hogging face embedding and then we embedded it and then fine tune the model in all the framework we used was extremely and. And lunch and lunch in is the frame of use and from lunch in we could import all of these things and then make the API the API was done using the stream lead so we could design a kind of UI and then the UI was then. The symbol by the human evaluators because the method we use for evaluation was the QA team that is domain experts they had to put in a rod text and the results that were generated they validated it and then we also use. The rule and other evaluation methods in this project so when when we were done it was much appreciated the results were good and. The so the problem at that time so now is to improve the model and try to upgrade it and maybe yeah. One question there you said you at the time you didn't have drag so you decided to go fine tune it right so then varies the embedding coming into place and how is the language and fitting into this. Lunch in helps you to make your model more intelligent so when lunch in is a framework so when we are using stream lead and lunch in it helps us to add other intelligence in the model like. Because the overall objective of. Fintuning the model is to cost customize it so lunch in has a number of tools that can be incorporated like split us we you know some of these kind of things and. And load us and everything so these are frameworks that is the right right so you're splitting the text you're embedding it and you're loading it that is part of right pipeline yeah if you're not using. If you're just fine tuning yeah why would you use that yeah the process of fine tuning didn't that part the part of fine tuning where we had the level we loaded it using seismic we did everything didn't have. The right part the fine tuning itself was to it supervised approach that was done to make the model more intelligent but it's not just for rack the the lunch in is not just for for the right part it was to. It was to help us in the LL ops part of the model like incorporate other stores because in lunch in we also have what we call agents so we have other things that make the model more intelligent the prompt in prompt engineering change so it makes the model that we can write the right from because one of the most.", "start_char_idx": 6933, "end_char_idx": 11568, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "85e725a9-9f1b-4b24-9110-1b579841cd7a": {"__data__": {"id_": "85e725a9-9f1b-4b24-9110-1b579841cd7a", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b41d4e23-791a-4643-ae55-1a8bb4e103f6", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "46c61109247b9da4f48375b6221fb5e9d7f55b0f2cd0403a024e06deb8eb2af1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1510aabc-512a-4db7-ae2d-8d8042f1f93a", "node_type": "1", "metadata": {}, "hash": "5507a894faeb284e4e509c81350d5cbc340e82370179a0932225039773696541", "class_name": "RelatedNodeInfo"}}, "text": "And load us and everything so these are frameworks that is the right right so you're splitting the text you're embedding it and you're loading it that is part of right pipeline yeah if you're not using. If you're just fine tuning yeah why would you use that yeah the process of fine tuning didn't that part the part of fine tuning where we had the level we loaded it using seismic we did everything didn't have. The right part the fine tuning itself was to it supervised approach that was done to make the model more intelligent but it's not just for rack the the lunch in is not just for for the right part it was to. It was to help us in the LL ops part of the model like incorporate other stores because in lunch in we also have what we call agents so we have other things that make the model more intelligent the prompt in prompt engineering change so it makes the model that we can write the right from because one of the most. One of the most important part in this process is prompt engineering so prompting and getting it right was really better with this framework than just doing it like normally with without the framework so we had to. Make change and make it really right and the prompt passing the system from the user from and everything it was yeah. How big was the data set for fine tuning and how many days you took for fine tuning the data says was really big because we. We would in order for us to have that right it took so it took us a lot of time it took us months and it was like a hundred K and. Yeah it took us since the machine was good decision because we use a theft parameter efficient fine tuning so it was the number of trainable parameters were less so it took us to cause how many days. Like to be it's for the yeah something like that yeah so you said you used a L.T.K. for a lot of you know data cleansing light yeah yes we did so you're pretty good at an L.T.K. yeah I can say that. So natural language processing as well yeah natural language process what what is the difference between an L.P. and NLU NLP is natural language processing NLU natural language understanding yeah. What is the difference today we I mean understanding processing the what are the components of NLU NLP. So basically the components of NLP you have to when you have your data you have to clean the data the cleaning part of the data then which you remove stop words you remove non textual data you remove H.T.T.P. HTML links and stuff like that and then after that. You talk nice you talk nice to can I see on its vital and then after that you can perform limitization or stemming and then after that we do vectorization or embedding after the vectorization then we can now perform classification task or all the steps. And all the steps that you mentioned there are part of language processing right you know the three components of NLP or language understanding language generation and language processing what you said was part of language processing that is where NLP comes into play right. Language understanding is is nothing but that the energy part of it but all the three pieces are part of NLP language understanding generation and processing. Okay so you know you talk about stemming and limitation when do you use the stemming and when do you use limitation. Stemming you you capture the base word let's see we have root we talk about the root words which sometimes my nomics sense I mean even if it's not a dick a word that exists it will still just get the word example what can I use let's see. But the limitation finds a root word that has meaning a meaningful base word like running wrong running running wrong and maybe so it would have it would take wrong but stemming I'm trying to look for an example stemming. Stemming it can be a it can be three different whether the base word doesn't have a meaning but it will see ticket and then limitation also if you have some kind of way like good better best some different it would still give you a base word that is that takes care of all of these. Differenties like run run it will give you a base word like wrong but stemming will not stemming would stemming just try to capture it in a base word which even if it's not a meaningful word it captures it because it's a base word and so. Basically you're talking about cutting words versus cutting words with context right yeah perfect cutting word versus cutting word we call it. Yeah which one is more accurate. Limitization I prefer I mean it but but what is important what is important to note is that stemming is really easy and less compute and faster but limitation is more effective because it's so it depends on the project that you are doing if it's just like a simple project you would want to. Think about the competition and stuff yeah.", "start_char_idx": 10636, "end_char_idx": 15418, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1510aabc-512a-4db7-ae2d-8d8042f1f93a": {"__data__": {"id_": "1510aabc-512a-4db7-ae2d-8d8042f1f93a", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "85e725a9-9f1b-4b24-9110-1b579841cd7a", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "191742d2d75333f2fe6d09f3d6983a928a9ff59d4df4c9e885263436da9ff761", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8296b97f-1310-4643-ab78-56f29dc57220", "node_type": "1", "metadata": {}, "hash": "e1a9c247fbcaf8e8231f05eb8562d429f1f628e5291f0b45eb198679577f61cc", "class_name": "RelatedNodeInfo"}}, "text": "Differenties like run run it will give you a base word like wrong but stemming will not stemming would stemming just try to capture it in a base word which even if it's not a meaningful word it captures it because it's a base word and so. Basically you're talking about cutting words versus cutting words with context right yeah perfect cutting word versus cutting word we call it. Yeah which one is more accurate. Limitization I prefer I mean it but but what is important what is important to note is that stemming is really easy and less compute and faster but limitation is more effective because it's so it depends on the project that you are doing if it's just like a simple project you would want to. Think about the competition and stuff yeah. How many types of text summarizations are there and can you talk about those. How many types of text summarization so there are two types. We have the two types we have this charity we have extractive yeah we have extractive and abstractive yeah so extractive it just extracts from basically extractive. It's from the text and gives you a summary extractive is more generative it brings it takes it from the text and creates you something that is better and more presentable so yeah extract from yeah so that does the difference between the. So which one you used for your project yeah so we used abstractive that is where LLM's come into picture because that when when we do the prompting and everything that's why frameworks like I'm saying that important because you try to make it more generative that's why we call it generative AI extractive is not don't need to be in AI is what has been happening prior to. To to generate a but abstractive makes it more humanly if I may use that term because it it understands it and brings it in the form that irrespective of how you change the things is able to capture the semantics that is why the transformer architecture. It's captures what we talk about safe attention li captures the semantics of of the words the context one meaning not just not just the because to me two words can can be used in two different sentences but in different context so that that context while meaning of. That word in a sentence was vital and that's what brought the success of the transformer of the transformer architecture that we are using today and yeah. Have you used gun. No, I've generated an adverse in the network. Generative address on network. I think I've seen that like deep fake. Some things. I think I've seen. You're not used. Okay, that's all right. You have knowledge about it. Yeah, I've read an article on it but I've not implemented it so. I've talked about deep fake and the place images to networks something I can't really is being quite some time. Sometimes we just read research papers and try to capture some stuff. So I think at that time you were talking about two networks competing against each other. So I don't know if you can just give me a little bit of head so maybe I might I might refresh what I what I got in the gun. What is being quite some time that I read that paper. That's okay. So I want to be the neural network so. What is the drawback of LSTM and why is the transformer architecture better than that? LSTM still uses sequence sequence. So even though LSTM solves part of the problem of vanishing gradient but it's still so fast from it. Even though it's LSTM which transformer architecture doesn't and talking about the semantics that we just mentioned. And the contextual to capture the contextual meaning of of talking in a word in a sentence, the contextual meaning of of a word in a sentence. LSTM doesn't capture that which the transformer architecture due to the safe attention layer is able to capture that LSTM doesn't capture in terms of. So LSTM will just generate the text based on maybe they are if they occur in a sentence like how are you and if it's maybe supposed to translate it is going to attribute how and that based on the how they occur and how they so we will just know that if it's this is that if it's this is that based on how it is string. But transformer architecture doesn't only do that kind of capture the attention layer when we do the position encoding and everything that passes through the attention layer and it assigns attention scores and everything. And so based on that it would now generate representations during that phase which are probabilities and then based on that we would so it captures the context that's just the one of the great great difference and then transformer has both encoder and decoder.", "start_char_idx": 14668, "end_char_idx": 19250, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8296b97f-1310-4643-ab78-56f29dc57220": {"__data__": {"id_": "8296b97f-1310-4643-ab78-56f29dc57220", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1510aabc-512a-4db7-ae2d-8d8042f1f93a", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "1bb15985ca0d4d2c9c3776df74151a4154d9102e0d6ca16c7b2a193c199447d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5f582dbf-9095-4979-8abd-0e911bc0d0c7", "node_type": "1", "metadata": {}, "hash": "ca39cbc4fb068cc763bdb7a7a7e3c8c24c4264e3fe9b5645cc435192c219f484", "class_name": "RelatedNodeInfo"}}, "text": "LSTM doesn't capture that which the transformer architecture due to the safe attention layer is able to capture that LSTM doesn't capture in terms of. So LSTM will just generate the text based on maybe they are if they occur in a sentence like how are you and if it's maybe supposed to translate it is going to attribute how and that based on the how they occur and how they so we will just know that if it's this is that if it's this is that based on how it is string. But transformer architecture doesn't only do that kind of capture the attention layer when we do the position encoding and everything that passes through the attention layer and it assigns attention scores and everything. And so based on that it would now generate representations during that phase which are probabilities and then based on that we would so it captures the context that's just the one of the great great difference and then transformer has both encoder and decoder. So the LSTM for LSTM to really be like transformer is attention in is the attention layer like with the idea is is very difficult because you have to maybe forget get and all of those things are the recursive nature. It doesn't really solve everything. So are you heard about this egos models. Ego models. And I'm right you know but it is based on our and it doesn't use transformer architecture. Very recently the release it. It's as good as the amount to but it is based on our and. So what what did they use in. To capture the context of the. Based on the sequence to sequence nature of our NN and. I mean I will look into into it. You take a look at that right it's very interesting. So you don't necessarily need. You know transformer architecture but. They crack it with the order and so anyway. This is this is a fast changing domain that the list. They that you don't study something or you don't. You are you are you are you are you lost information like every day people are doing active research and. I mean it's really interesting but I would read I would read the paper on that and. You said ego right if I got it right. Yeah let me see if it is the eagle or. No not. I forgot I let you know you know before this call. The approach by County list made in, the support by Frankoff obviously. Very. Yeah. If about that. Loud and this is straight away and here so I just want to quickly ask you a couple of questions. I think you brought up a point about these micro LMS right. So can you talk about micro LMS why would you use micro LMS and what's the power of using a micro LMS versus a regular large scale? Yeah so there are several advantages one is that the micro LMS is customized so it's smaller than the large language model and so you benefit in terms of computation in terms of you get exactly the kind of response that you need because most big LMS are. General purpose like they were trained on large couples so they are prone to hallucination. There is a concept called hallucination where if the model was less a GPT 3 was trained to 2021 or 2022 2021. Yeah GPT 3.5. If you ask GPT 3.5 about Lama 2 or. Something concerning RAC it would say I don't know about that so it's limited so we need we need some kind of additional data to customize it to our context. So we have computational concerns with large language models which are solved with micro ones and they are more efficient than for specific task than the large language model. So and the micro the micro models can be can be trained faster and even locally than the large language models. So what do you say that micro LMS if trained properly would not hallucinate? The overall objective is that even if it does but it would do it less so that is why all these customized customizing LMS or micro LMS is because we want to reduce that hallucination. But to do that for a large one is more cost effective and it's more expensive it's more time consuming and all the lab for a smaller one is cheaper and faster. Yep. What are the applications of micro LMS where do you see them fitting in? Basically we see them in chat boards if you have an institution for example and you let's say a bank is different from a healthcare company so you would it would be more better if you use maybe a kind of bank kind of documents in a mine. So micro LMS in a chat board or rather than using a general purpose like charge FITI which is to use it in your so you so it's more proprietary kind of applications.", "start_char_idx": 18298, "end_char_idx": 22726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5f582dbf-9095-4979-8abd-0e911bc0d0c7": {"__data__": {"id_": "5f582dbf-9095-4979-8abd-0e911bc0d0c7", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8296b97f-1310-4643-ab78-56f29dc57220", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "e7b4ccfb850ab9a8da90de9f1f0717e304a2011a50cd6911717529a6ee09c542", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5f021dc4-761c-42ac-bd6d-d166ede4bebc", "node_type": "1", "metadata": {}, "hash": "452f3d80a6a858b1362dd47c864411a8a879b5caba7b3e1869be5294b07cf4f8", "class_name": "RelatedNodeInfo"}}, "text": "The overall objective is that even if it does but it would do it less so that is why all these customized customizing LMS or micro LMS is because we want to reduce that hallucination. But to do that for a large one is more cost effective and it's more expensive it's more time consuming and all the lab for a smaller one is cheaper and faster. Yep. What are the applications of micro LMS where do you see them fitting in? Basically we see them in chat boards if you have an institution for example and you let's say a bank is different from a healthcare company so you would it would be more better if you use maybe a kind of bank kind of documents in a mine. So micro LMS in a chat board or rather than using a general purpose like charge FITI which is to use it in your so you so it's more proprietary kind of applications. So micro services architecture? Yeah, micro service yes. So can you correlate the micro LMS and how they fit into overall schema? There will be some orchestrated wave. Yeah, I'm just giving you some hints you can tell now. Yeah, so micro service is in a typical DevOps environment is every micro service produce a given outcome but on the higher level each outcome joins together to give the final result. So let's say micro service one produces a bottle micro service to cleanse water and the higher level we put the water inside the bottle before we sell it. Let's just take as an example. So yeah, it's that's a similar scenario even on micro LMS like it's more reduced to a given task at a given time. Like for example, you can do something just for a chat board or maybe summarization or maybe just a specific task and it produces more better. It's easier for you to customize a model that was built just for text summarization for a summarization task than to build than to customize a general purpose model for a summarization task. So that and but now you can have various tasks in your company. Summarization, question and answering. Text generation and all other things image and everything so you would customize like for example, dali can be more used in a particular context and that is different from so choosing the right kind of model to. Model 2 is is very important depending on the task that you want to you want to do. So how so if I were to ask you so you talked about Lang chain before or other frameworks if you have to somehow correlate between using micro LMS in a Lang chain kind of framework. So what do you do there? Excuse me. So it's an interesting question. So basically if we have some proprietary documents right let's see they are. PDFs and other stuff so what we do is we make sure in Lang chain we have the right micro LLM that the first thing so when we have the right micro LLM we have other proprietary documents we would. Use a speeder Lang chain we can use a speeder like a recursive text speeder we speed them down into chunks. When we do that, Lang chain we also can use a vector store after we do the embedding we proceed to a vector store and then. But let's just stop here because if you're chunking there is a risk of losing context. How do you tie these different their phrases together? If I'm chunking there is a risk of losing context the overall context. The chunking is because every model has limitations in terms of talking. So in the chunk we specify both the chunk size and the overlap. So the overlap helps us to capture we need to specify the overlap. It helps us not to lose context. So did I did I respond to your question right? There is a balance right? There is a balance that you have to play around so that you don't lose the context. But I'll take the answer. Yeah, so we can also group by topics. Yeah, sure. Chomps by top. You do it by top. Just moving along. So have you worked with vector databases? Yes. I've worked with pine cone. So that was where I was heading to that when we embed we do index. So in Python we create an index and then based on that we can load the chunks in the vector store. So we create the vector store and we use what we call in the why creating the index we would specify the dimension and the. So we specify if we are going to use maybe dot product or cosine similarity. Yeah, so when all you can get distance and when we do that then when we finish the index in we use what we call similarity search.", "start_char_idx": 21901, "end_char_idx": 26228, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5f021dc4-761c-42ac-bd6d-d166ede4bebc": {"__data__": {"id_": "5f021dc4-761c-42ac-bd6d-d166ede4bebc", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f582dbf-9095-4979-8abd-0e911bc0d0c7", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "5bdd8ebeeb7aacab10dad1931a630922df7c66f1caad281165073c4221ab6835", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "af4a41ab-9cae-45d0-9659-da6859d826d5", "node_type": "1", "metadata": {}, "hash": "529670852c3cd8f6705291b55dfff57516bf2bdeb80fee6c990367b64c3dcbe2", "class_name": "RelatedNodeInfo"}}, "text": "There is a balance that you have to play around so that you don't lose the context. But I'll take the answer. Yeah, so we can also group by topics. Yeah, sure. Chomps by top. You do it by top. Just moving along. So have you worked with vector databases? Yes. I've worked with pine cone. So that was where I was heading to that when we embed we do index. So in Python we create an index and then based on that we can load the chunks in the vector store. So we create the vector store and we use what we call in the why creating the index we would specify the dimension and the. So we specify if we are going to use maybe dot product or cosine similarity. Yeah, so when all you can get distance and when we do that then when we finish the index in we use what we call similarity search. So whenever there is a query based on maybe when we are prompting also we pass the message if we in the rug we pass during the prompting we pass the message which can be system human and. AI, then AI message and based on the human message that is part of the query on the prompt that we would provide it will be able to do a cosine similarity and then using the micro LLM that we we choose will be able to generate the response to the user at the front end. Is there any other search mechanism that you are aware of other than Dr. Kereveys' yes we we have semantic stage yeah no in terms of not if we thought using vector database. So when we search again with the vector database anything other graph any other. Yes, not as grass yeah, not this graph yeah. So have you worked with any of the knowledge that tools or a bit of work a bit but not too much just to be. I've played around with new for you. What's the plate in knowledge graph. Can you repeat that plate? Treat let. Not to show that's okay that's all right. So you know any other way you can use micro LLM's leveraging language framework. Have you heard about agents. Again. Do you have you work with using agents. Yeah. Agent each agent and can be triggered and can be you know. Focus to do some particular task that can be done through the micro LLM so you have all these micro LLM's working as agents. And then they will be agent orchestrated on the top. But they have you what the agent. Yeah, I've worked with agents but not in the context that you are saying right now. But the agents were just to make the LLM more intelligent in terms of we needed something like a Python interpreter, a database and other things to be incorporated. So we use agents in lung chain but not like the high level that you are trying to be. But it's possible because the agents are yeah they are what makes it more more powerful. Basically the agent use the tools. Yeah, then you like to put around other things are the tools. Use the tool to perform some tasks in place of a tool you have a micro LL. Okay. That's where that's where I was going to. Okay. Yeah. Make sense. It makes sense. Make sense. So what are all the techniques that you would use to increase the accuracy of the error output. Techniques to increase well. First of all, prompt prompt engineering is is very important. We have to set the the gifts like one a few short inferences. During the prompt scene. The speeder. And there is a new technique that we are working on right now, which is. Ranked ranking. Retrived chunks, which is very important right now in a in a vector store. So those are those are stores that are improve, really improve and it can keep just the top. Maybe two or top two or top four or five chunks rather than just choosing it randomly instead of giving. It can select five out of maybe 15. Also. We we we already mentioned fine tuning fine tuning also makes it more customizable. So it's also very important. So the data set that we used to fine tune has to be good. We can use reinforcement learning that is feedbacks from maybe or a line in it with setting policies or human feedback and stuff like that model alignment. Yeah. So. Can you talk about our a little bit more detail how is that reinforcement learning that human feedback implemented? How do you implement that? Yeah. So basically we have we have rewards in real first-man learning.", "start_char_idx": 25444, "end_char_idx": 29620, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "af4a41ab-9cae-45d0-9659-da6859d826d5": {"__data__": {"id_": "af4a41ab-9cae-45d0-9659-da6859d826d5", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f021dc4-761c-42ac-bd6d-d166ede4bebc", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "24f522dfcd562164fca010d7289ac92ff4879acaadae8ed97e998b4db6747aaa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "55a42822-3aea-478b-ab74-d03b28d72138", "node_type": "1", "metadata": {}, "hash": "b695f37d1b78c9500674733ee669e6fb810b36503cb68a66f76f1938bb8fe992", "class_name": "RelatedNodeInfo"}}, "text": "Retrived chunks, which is very important right now in a in a vector store. So those are those are stores that are improve, really improve and it can keep just the top. Maybe two or top two or top four or five chunks rather than just choosing it randomly instead of giving. It can select five out of maybe 15. Also. We we we already mentioned fine tuning fine tuning also makes it more customizable. So it's also very important. So the data set that we used to fine tune has to be good. We can use reinforcement learning that is feedbacks from maybe or a line in it with setting policies or human feedback and stuff like that model alignment. Yeah. So. Can you talk about our a little bit more detail how is that reinforcement learning that human feedback implemented? How do you implement that? Yeah. So basically we have we have rewards in real first-man learning. We have a reward reward model and we have a reinforcement learning model like PPO. PPO is one of those that are mostly mostly use. So whenever the whenever we finish the fine tuning we we can make it to when it produce good results. Whenever it makes an inference let's say it does the job on the model and it produce good result. It gives rewards so we use the reward. The reward model they are several different. Do you train the the element that is producing the output of do you train a reward model? We train the reward model because so the reward model is based on human feedback. So when the feedback is positive it gives a reward when it's not it gives a penalty based on what the LLM has produced as result because the LLM is the one which generates the response. So the reward model uses this LLM model as a reward function to optimize the policy through reinforcement learning. So we train you train the model basically. Yeah, you're using two models. And the reward model is it usually a better model than the LLM that is producing output or is it of inferior to the LLM? I mean the reward model is the LLM is more intelligent than the um well the reward model would be better if I say so. So it means basically if I have to go around the RLHF, you have to do reinforcement learning it is much more costlier for me. Yeah. Right. It is more expensive for me to go up to use a RLHF because I have to use a better model and I have to use the two models to train the two models again. Yeah. How do we overcome this challenge? Is there any other way? So um. Oh, we could I think we could just fine tune maybe um if we have some regulations or some things that we want our model to align with, we could continue and correct the response and based on the feedbacks we find we. What's that you're right you're going on the right direction so what's that called so between the decision. So the DPO direct differential optimization right where you kind of take away the reward model and you. You know using the feedback you kind of you know put regulation as you said and try to train the LLM itself right you know so but then whether it is the RLHF whether it is DPO whether it is fine tuning what is that common thing that we need. We need um what is the common yeah what do we need we need feedback we need feedback we need lots of feedback we need lots of right you know so if we have to get to that point how much time we take to get the feedback depends on right you know yeah that is how. So if we if I'm able to generate the feedback and collect that enough data set where the question context answer and the feedback in terms of whether it is positive or not it takes months or years or a year for us to collect the feedback by then there's a new LLM. Yeah that's you. So. So why would I invest in that so how do I address this challenge you got to have a better way of doing things yeah so how do we do that and I think about this you don't have to answer out of now but I'm just putting your point yeah that's that's a good point to note I mean I'm going to walk on that we learn every day. I think we are almost at the top of the hour so I think we got a good conversation going on right you know by the way that model I said is EGLE 77 B 7.5 B. The RNN model. Oh was the name please. EGLE 7.5 B. Okay. Thank you so much. I learned a lot from you today.", "start_char_idx": 28755, "end_char_idx": 32988, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "55a42822-3aea-478b-ab74-d03b28d72138": {"__data__": {"id_": "55a42822-3aea-478b-ab74-d03b28d72138", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "af4a41ab-9cae-45d0-9659-da6859d826d5", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "e58a3d9576ca711800a106f363f3eefab7da730da200f2ebe3a3e56a90575907", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f1ca1cb9-54d8-4e17-80a5-fa06259f19b3", "node_type": "1", "metadata": {}, "hash": "1320b60930702f8231d4731d8d8f1c36c5d4b5399d299f7ffceedb22906d9a29", "class_name": "RelatedNodeInfo"}}, "text": "Yeah that's you. So. So why would I invest in that so how do I address this challenge you got to have a better way of doing things yeah so how do we do that and I think about this you don't have to answer out of now but I'm just putting your point yeah that's that's a good point to note I mean I'm going to walk on that we learn every day. I think we are almost at the top of the hour so I think we got a good conversation going on right you know by the way that model I said is EGLE 77 B 7.5 B. The RNN model. Oh was the name please. EGLE 7.5 B. Okay. Thank you so much. I learned a lot from you today. Same here every interaction with everyone we kind of learn something new. It's a good time spending time with you Lauren so probably we'll get back to you right you know in a day or two on the next steps or whether we are able to take you to the to the Van Gogh interview on out. Like you know so I'll keep you posted either to double post you or let you know or I'll I'll inform you either way. Alright thank you. Thank you. Thank you Lauren. Bye bye take care. Oh my goodness. These guys are good they know things. They know a lot of things. They are so powerful like yes. They have they have been working. They are not internal for what God there you just hear for screening process. Yeah this is just this is just the they are so. This is a very interesting field so so you know where you got yourself in trouble right. You know it right lynching. Wow yeah that's why I got my silly chance. Yeah you were doing great you were like you were like there was no no rag yet there was there was just this we were you were perfect and then it's like yeah and we you started throwing things. Yeah. Who knows we'll see. So what's interesting is again that there's not a lot of people using it. And I also noticed when you get nervous you speak a lot so so so it's okay to talk but it's also let me put it this way. Every time they ask a question when you answer correctly it's a hundred times more powerful than you you volunteering something. So so it's good to they were very nice to let you speak speak and and gave you rope to hang yourself you know they're like like keep on going. Yeah let's hear about this lynching in 2020. But I think I don't know I think I think I think you kind of work yourself out of the of the problem. They have to be aware that you know everything is new. Everything is new me and she hasn't we've been working on LLM's for years and years and years and everything we know is old. This is why this I mean we build this very nice bird classifiers like like two years ago there they're now obsolete. This question about NLU and NLP it's a semantic question it used to be very different and I'll tell you the main the big differences. NLU was more about understanding the language so for example clustering and stuff like that. Nowadays it doesn't matter we don't even need to limitize or stand or do any of that stuff. Basically the preprocessors for all the large language models do it by themselves in a better way than we could possibly do. So nowadays you don't stand you don't limitize you maybe the noise because there could be links that could be stuff like that. But even a basic and better like universal census encoder can handle anything you throw at it in a better way than you could. And the true face that the large language models the encoders of these large language models need to have capital letters they need to have a preposition because you're trying to capture the meaning. So just like a person you know a lot of language is things that make it easier for you to understand something and the old fashioned NLP models where you remove stop was remove everything. And you are just trying to classify these words you just trying to make a unique numerical identifier for this particular group of words and then kind of related but a large language model trained on billions of words and stuff like that. So it doesn't really care you don't need to stem you don't need to limitize you don't even need to tokenize they will have a preprocessing step that will limitize and tokenize everything. It used to be that for LLM for NLP you spent half of your of your time basically cleaning up your test.", "start_char_idx": 32384, "end_char_idx": 36631, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f1ca1cb9-54d8-4e17-80a5-fa06259f19b3": {"__data__": {"id_": "f1ca1cb9-54d8-4e17-80a5-fa06259f19b3", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58d35c8b-fc64-4606-ae79-0bb7cde01948", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "416426ba8bd206566157f552fe10fbd3fc5376dd57616c5fe9e5f1d32ccb1e53", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "55a42822-3aea-478b-ab74-d03b28d72138", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}, "hash": "53f217638a6db9a86d5829fc3863175ffe0e1e7d50b64069d9517bdbfae9df72", "class_name": "RelatedNodeInfo"}}, "text": "And the true face that the large language models the encoders of these large language models need to have capital letters they need to have a preposition because you're trying to capture the meaning. So just like a person you know a lot of language is things that make it easier for you to understand something and the old fashioned NLP models where you remove stop was remove everything. And you are just trying to classify these words you just trying to make a unique numerical identifier for this particular group of words and then kind of related but a large language model trained on billions of words and stuff like that. So it doesn't really care you don't need to stem you don't need to limitize you don't even need to tokenize they will have a preprocessing step that will limitize and tokenize everything. It used to be that for LLM for NLP you spent half of your of your time basically cleaning up your test. You don't care about that you mostly care about you know what he said is is this chunk. Does it contain enough context so for example if you if you write a recipe to give you an idea and the recipe is in a page with 20 I don't know let's say 200 words. Just because you need to split them into let's say 20 word chunks it doesn't mean that you will be able to know that that's a recipe for a souffle or whatever because you know add an egg right so you lose the whole thing so a lot of the work that is ahead of us as a as a discipline is to learn how to preserve that context. And it all happens in the splitting it all happens in the splitting it all happens at that moment where you don't do you do it. You know we had an idea for something called the hierarchical splitter where you try to preserve the the field or the topic. But this is all all like I said is all new and the interesting thing is that a lot of these rag systems are pretty good. But it's a combination of factors right all right Lohan we got to run. I don't know I don't know how it went but I what I can tell you is that it is it was a very challenging interview it was it was very good very interesting and we learned a lot of things and they gave you a lot of interesting information so you know. The idea that I had which which apparently is a thing you'll find out that any idea that you have in the interview is most likely already been written up by somebody else somewhere else. But it's is that whenever you have a proper response and the and the human gives you good feedback from that oh yeah you gave me good information you immediately trigger a retrain so. The cool thing about LLNs particularly for example the open AI stuff all that you need to do to retrain is you just give it a question answer pair. So you could have a situation where you can get you can generate a response to a question like what's that information useful to you. And and based on that response if it was yes it was very useful thank you you immediately retrain it so you what you would do be doing is almost like transfer learning where you're you're adding. Basically you're adding samples that you know are okay okay the more you talk so in theory the model will improve right in theory the model get better but he's absolutely right. It can take a year yeah yeah I mean they were very knowledgeable do two guys with very knowledgeable in this field like what's up. Yeah I'm thinking like you know every time I run them retraining it every time for this computationally expensive can we not set something like a threshold and I can say if we get this amount to actually peter or deeply retrain it with the correct response well so so the biggest. The biggest difference is and if you go to the open AI retraining or fine tuning page it's very easy. You just just like you do a completion you just give it a single observation. So the interesting thing about that is that you can be doing it all the time all the freaking time the other interesting thing about it's just seeing the observation it's yeah okay yeah so as long as the feedback is high enough so that would be the threshold I would put it's like if the feedback is high enough then you retrain the only problem is this people could be wrong. Just because I'm happy with this wrong response doesn't mean that it is useful for other users. Oh shoot okay I got to run I'll be right back. Thank you thank you loud and take care. Bye. Bye.", "start_char_idx": 35712, "end_char_idx": 40093, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"237e5cd2-face-4c5b-98fe-6d3614aef161": {"node_ids": ["991ebd60-0c73-48b0-a943-1685918f8576", "ced036ed-02b5-4964-b952-d502476e1656", "e12bc1af-001e-4aff-ae2e-8ff2588909b4", "0ca72028-e622-4002-8af8-939c10a19ff7", "235920a3-09c8-4e04-a9a4-71105e238589", "21141025-dabc-4695-b42c-d072f483f826"], "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}}, "50b1cfb7-2331-459d-a905-e1740658bc20": {"node_ids": ["4345dc0a-f359-4348-bd8e-d2cb7a87d076", "653ea791-6357-43f9-9b6f-a0756c58305e", "8e06ae75-cb32-45b0-a22b-6ad6ff16b001"], "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}}, "60dcd420-d1cd-424b-a926-8ab307c70a51": {"node_ids": ["65f74eb4-4a88-4100-9acc-7cc0fe386957", "08cb6190-31e7-4262-89e1-25a613ef29f4", "bf4e42de-7b8c-4daa-8ec5-f5c49e0a01ab", "0e9f8e30-d860-4473-8344-0a0ae61600e4", "c5bd60d7-69f9-4ae7-9fe4-dad4639b11c9", "8b6e8797-b55b-498a-aad2-58baa790fc8b", "b94ec2a1-35f0-434a-998e-a02c3bd059be"], "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}}, "58d35c8b-fc64-4606-ae79-0bb7cde01948": {"node_ids": ["fe2b9dc0-e3d8-4db7-b3f2-8e0ec249351f", "afcd0ecc-c85b-47a9-a721-62c6bd5e35f0", "b41d4e23-791a-4643-ae55-1a8bb4e103f6", "85e725a9-9f1b-4b24-9110-1b579841cd7a", "1510aabc-512a-4db7-ae2d-8d8042f1f93a", "8296b97f-1310-4643-ab78-56f29dc57220", "5f582dbf-9095-4979-8abd-0e911bc0d0c7", "5f021dc4-761c-42ac-bd6d-d166ede4bebc", "af4a41ab-9cae-45d0-9659-da6859d826d5", "55a42822-3aea-478b-ab74-d03b28d72138", "f1ca1cb9-54d8-4e17-80a5-fa06259f19b3"], "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-19", "last_modified_date": "2024-02-19", "last_accessed_date": "2024-02-20"}}}}