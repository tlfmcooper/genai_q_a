{"docstore/metadata": {"c433fffb-ab0b-4f64-afb2-b5f065255c4f": {"doc_hash": "eae19f89d11081b390d0f47d52ab1629ca7075bbc11a5cadb2a1df995990256e"}, "d3521eae-158d-4899-908d-b76c2e23d824": {"doc_hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3"}, "a0a11490-68e9-4b07-bef5-27c31af27966": {"doc_hash": "201eb0e77e152c65a2f5938f019514eb7a658ded7fd7816c4acc0b3f2f642324"}, "3f821ba1-e534-4918-ad05-b49a04e66534": {"doc_hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a"}, "05374a5a-b27a-4363-b1a1-a998366cba84": {"doc_hash": "847ae6225e106d7d86f29d1d9dbd723e4dda8df81f5e7a24767f2475ef04ae61", "ref_doc_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f"}, "fa9daee1-81cd-4f22-b73c-da31a58636d0": {"doc_hash": "78eaea1d4d4bba1dbfbd10a42b1b379e9fd769d76a6d0d6198fd74ce9c3b0519", "ref_doc_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f"}, "ba971bd8-7529-4bea-bcb9-e6102dd09fb0": {"doc_hash": "0d58be87c33748aaf0249d6db4d5f9073f70f1925fe6d90512da257c2399267b", "ref_doc_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f"}, "1d4ed061-3fe1-4e2b-9597-cb82ae4199f3": {"doc_hash": "1b5757b57192821ce439e94996a4b81d331f9628498bdfdab074cb0b6af632ec", "ref_doc_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f"}, "18ffbc8e-1924-4670-a809-2d4b430e7c1f": {"doc_hash": "93366da44db1fa6be934d23229ab41fa8325d4984733b7231219bed8c7a654c9", "ref_doc_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f"}, "59f2c73b-cb66-447f-9ba8-a11381e83fcb": {"doc_hash": "c62de141f0a050b25ffc55daf0930c3c24053bbd112e0edba9010ec60712b8ab", "ref_doc_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f"}, "4b93328c-f438-435b-b791-1a77d7474f9f": {"doc_hash": "141d1b14354216afbae01d082f9fc08fea0beae658dde14f25eeca81a1bc2934", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "140039e2-6389-4239-8c9a-a47e43509eeb": {"doc_hash": "a65e78856112819306c22da5f4047f7f2677d1ee27316280c97ac18f19bdc7a0", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "e76b746e-de81-4a0d-8055-288367541a6f": {"doc_hash": "45a494be68170270c16e344f51a1531ef7c37c2f17fecab94001e2dbab11f5ad", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "349bab13-3696-48e5-8eab-ede27cef7c8c": {"doc_hash": "51cd74e10bd2d9c5b219f44a5c0823118592d3794b47e45796c2efc2415513cb", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "ef945fdf-828d-4f48-8741-3fb64f8f5910": {"doc_hash": "370a4314db4fa314b6ca05a597ceafe4aaa82c5a3ae9cd72cd2709c9894b92fd", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "4a7806b1-85e8-4832-876f-05eb1d78f92d": {"doc_hash": "507db1be128be7b3e69b9d228722c1decc11ede81d0097c0b40deeabdfff7e9e", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "f828e89b-515e-43bc-beea-86204ebc775d": {"doc_hash": "797cae516614ce76445df195de23e2aa6e71c74aae1464d074b24448f8feb078", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "9d7450a4-6b0d-4238-a706-a8555c96e132": {"doc_hash": "390f5dfb2d2802011327f6182f70ad1900d5bf2691f0e660ccd7025a651e03d1", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "60cd25fe-1b89-42e6-9cbc-6559480f1a48": {"doc_hash": "b13ccb5320b4851c0178e7e4b4dda433909974e39d6ba168fbb55e629961bf0f", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "4e2c1416-b0c9-4383-aea6-df4854243788": {"doc_hash": "e67c65148904469e56da913c1ac1f324a147151b8a5b3c46351bc5693389f7fe", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "ee6278ee-5f6d-4b4b-8714-bb6bac19a186": {"doc_hash": "ee1c6041c9ba54a2e98e152e7335afd12f9b16bc8f38bb97e8f30dcbfa506783", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "d822043d-66a1-48d8-948f-c4d6938bce37": {"doc_hash": "0d1f8e495c8b92721882657590c045cc83398dedfe5200eafbb3d6d97c60b3f1", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "e510cb65-3a5d-40dd-b7a2-b42982e79b19": {"doc_hash": "1257bd5965a1e1ba16a1e0a4eacd67f9df8a17d075db78f4d3ca4b947212d84f", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "2319a23b-d482-4196-9f5e-624250ca0c8c": {"doc_hash": "49ae09c49aee4ef5a3d4eec3789268394574dab894c5287bb65c2186899e91d3", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "aaaaa1fa-96e5-420e-bba2-b393db5fb1e2": {"doc_hash": "172102b6dc14bc5478f16e54716a50f1f071cc3fde5e5e2919e48a2c9af86100", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "515f688d-285e-4c4f-8ebe-0101e4359e91": {"doc_hash": "8ea4d2036830eff56f784a6f0f766e3823fba7335c185470823ef78dca479482", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "6884e192-d11c-4083-9bb2-8197cec674c0": {"doc_hash": "5a23bcbcac5e7de52bc4c50af609c52b47e4cb7c1d8b7b6bf2673904a173a60a", "ref_doc_id": "d3521eae-158d-4899-908d-b76c2e23d824"}, "3b816b2d-c0e3-406d-aec4-1277060569d2": {"doc_hash": "8a5c78f4562d36e8420ea1819c23241abe5c85d5b02c4ca334f6e0d92be16669", "ref_doc_id": "a0a11490-68e9-4b07-bef5-27c31af27966"}, "30c0a70d-19b1-43cb-b9b0-441ae2ad8a25": {"doc_hash": "e763720621c48a82524c9c14426263aafe76a839dec60d53f8b4c479465cc8e5", "ref_doc_id": "a0a11490-68e9-4b07-bef5-27c31af27966"}, "a328c706-20f5-4c35-99e8-efef138fe040": {"doc_hash": "6513d7ae09b29a387682356f86eb7465f0a27dd482ae58054f47f4482a1f8ec4", "ref_doc_id": "a0a11490-68e9-4b07-bef5-27c31af27966"}, "c1f389d1-2523-4f14-ba4e-de2bbb19a7dd": {"doc_hash": "134403d9093335740011a98ae4608b47fea3e95c0577f26acced89ed49c19253", "ref_doc_id": "a0a11490-68e9-4b07-bef5-27c31af27966"}, "9c532364-1169-4cb1-95a0-250c43940657": {"doc_hash": "c30584d977571a57917741bd23c169dbecebc96b082ce50749b270e8aac54e53", "ref_doc_id": "a0a11490-68e9-4b07-bef5-27c31af27966"}, "f7d35226-315e-4002-bb1f-13dec45cc83c": {"doc_hash": "764727c41adbbdb6b85a801244f2ec25688d5114758fe35e1a5a6cbdcdc93a30", "ref_doc_id": "a0a11490-68e9-4b07-bef5-27c31af27966"}, "73520d45-75e0-4df5-99c8-978dac8f7c3d": {"doc_hash": "8ff1d2ef4620854c25f221e21881e753fde856ae4aa1243ce29c9330811e0440", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "b3465798-fdf5-453a-9ad7-59078f90ef24": {"doc_hash": "5df63e76d8df2574b143a290ee2888b6cc83a054646d89a70e7e230490d13742", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "0ed7e79d-79d2-4535-82c9-9c9d255c10f8": {"doc_hash": "21f73a7fa97590d62ef98b0620dca0b0bdc6b333a231b6c312e9d182d332308a", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "1d0e9dee-e671-4e2f-b85e-7532a209338e": {"doc_hash": "f62806f1d6329ffe7e4aaaf2fdcee9d22ecb5d87f634268a8f7492d24ec09e32", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "be2efb2e-a841-4f8b-8237-700c352b16cd": {"doc_hash": "854eb03f7640b502406b3f97ff5bad812ca50794618c85b9b988dad62a54bd84", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "cee31820-8605-471f-a1b3-753750992fd0": {"doc_hash": "dd870ac4b6cf5c4799523045b9c138abbfec0a79ca6e92d4ef43f93eaf2952d3", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "d1182f7f-3c0b-43fc-b277-bb303c2d8ed5": {"doc_hash": "14a626875557170b9e11386e96c7b8a57e19b59d197f42bdd0c95bbf1a36ffa8", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "bfcf4e11-d0bb-4da6-b073-73dc5c2531fc": {"doc_hash": "fab434848a39f21f8e3ffc6f4d8f367f6219c7151b1b554ae09e6cdf88f640d2", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "2807c55a-565f-477c-9d9b-833d0b3bdefb": {"doc_hash": "f6159a8f94470b98a705a4caac16bcb989df56233b60080ab801ff105d5f39d1", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "032f3e2d-60cf-40cc-b9f8-71668940c15a": {"doc_hash": "54d5ed20f16e2708874efec00236ec6c2c938ad421cb5bab51450a7fd6d6f64b", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "95703399-98e7-4c86-bac9-a7971b5ce475": {"doc_hash": "77211d774e50c80fb8a33b9452f67af030c92ab04e0f7472f1f9473747200eaa", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}, "cd622ea0-9589-454f-baea-b419c1d91ae1": {"doc_hash": "d28429e0e539841c5d7e75d4d364399bc4396ca7a04f89d2025e5cf732c2aaae", "ref_doc_id": "3f821ba1-e534-4918-ad05-b49a04e66534"}}, "docstore/data": {"05374a5a-b27a-4363-b1a1-a998366cba84": {"__data__": {"id_": "05374a5a-b27a-4363-b1a1-a998366cba84", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "eae19f89d11081b390d0f47d52ab1629ca7075bbc11a5cadb2a1df995990256e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fa9daee1-81cd-4f22-b73c-da31a58636d0", "node_type": "1", "metadata": {}, "hash": "d72ed841f111957ade750408da4699b14b71d49b724cbf80253d61bc0b160bcc", "class_name": "RelatedNodeInfo"}}, "text": "Thank you. Nice to see you. In call. Like right. Just can you me. I have a full of full your resume. So I'm calling from Bayer Drop Science. And we are looking for a text-based data scientist. And we found your resume. It's very interesting. So wanted to have a quick call with you. Nice. I am the hiring manager. So you should be able to be the introductions. And then it's a general. It keeps flowing. And you might have questions. I might have questions. Mostly, you know, any questions that you might have. And the last few minutes, you know, we can talk about whether typical next steps. And that's that. Right. That's good to me. Cool. So I can go first if you don't mind. And my gohy name is Baladasan. My name is Baladasan Giridharan. I grew up giri. I have been in Bayer for almost 10 years. I am right now leading a journey. I team. We are in the thousand fans sitting that goes with other than then all the media attention and the thing that goes with it. There's a lot of interest to base text-based models. And I am being assigned to, you know, ask to lead a team and then the team around this area. So that's why we have two recussions of pregnant for hiring people. And that's where we are right now. My background is in computer science. I have been leading an imaging team for the last four years, three years. And now I'm leading the text-based analytics team. So that's a background about me. I'll even simply disagree. That's it. Which part is it? Which part is it? Central ways. I'll send a voice. I'll send a city and then you know. Where are you going, Central ways? Yeah. Target of South. Oh, really? Yeah. I missed that. That's the family here. Oh, really? Interesting. Cool. Very nice. I like that. That's what I think. No. In my time. OK. If you don't mind, if you don't mind, can you do it? Totally. Sure. Sure. Of course. Yeah. So like you, my background is also in computer science. I was in bachelor degree. My master's, PhD, out in computer science. And for the last couple of years, I've been working with NLP as well. Like tech generation, some image process. But at the beginning of my data science career, I was work with statistical models, like linear regression, some time series analysis, and other kind of models to prediction. And maybe the last couple of months, I was work at the CHPT, the M2, Falcon B models in this MGM project. I on top of my mind, I think it's pretty similar what you would like to do. This is kind of the direction that's that bought and some data based behind it. But I have some experience of chat bots as well, even before the CHPT or any other large and expensive model, when you are using just decision trees or bird. And I can't say any question, Pat. I just need to talk about some project. I can answer. But basically, my background is. I'm interested. I'm interested. No, I'm simply for the start of a group of self. OK. Because the resume says just a few, because I didn't check. Although just a few, I was M docs. My I think it was my third project, the last one. I mean, I have MGM. Then in the Perina and the M docs, the telcom company. I don't know if you are familiar with this company. MGM, yes, I have heard about it when I was in Vegas. Perina, yes, M docs. No. Yeah, it's a telcom provider. They are from Israel, but they have a lot of sites. And here in the United States, one is just a field. The one you saw. And a couple of sites in Brazil, India, Europe. Yeah, the main client of M docs here in the United States are H&T and Timo Bay, Timo Bay.", "start_char_idx": 1, "end_char_idx": 3535, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fa9daee1-81cd-4f22-b73c-da31a58636d0": {"__data__": {"id_": "fa9daee1-81cd-4f22-b73c-da31a58636d0", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "eae19f89d11081b390d0f47d52ab1629ca7075bbc11a5cadb2a1df995990256e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "05374a5a-b27a-4363-b1a1-a998366cba84", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "847ae6225e106d7d86f29d1d9dbd723e4dda8df81f5e7a24767f2475ef04ae61", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba971bd8-7529-4bea-bcb9-e6102dd09fb0", "node_type": "1", "metadata": {}, "hash": "2c6f60f8a57f2af0a17df5a2ac8549b0827d5599501e5873b5a4c0be6c08b61c", "class_name": "RelatedNodeInfo"}}, "text": "OK. Because the resume says just a few, because I didn't check. Although just a few, I was M docs. My I think it was my third project, the last one. I mean, I have MGM. Then in the Perina and the M docs, the telcom company. I don't know if you are familiar with this company. MGM, yes, I have heard about it when I was in Vegas. Perina, yes, M docs. No. Yeah, it's a telcom provider. They are from Israel, but they have a lot of sites. And here in the United States, one is just a field. The one you saw. And a couple of sites in Brazil, India, Europe. Yeah, the main client of M docs here in the United States are H&T and Timo Bay, Timo Bay. So the whole system from H&T and Timo Bay, it's from M docs, the CRM customer relationship management, the all data from customers and builds. Nice. What kind of thing for your next role, Leo? Well, I was very excited with large-length models. That's where I was working at MGM. But unfortunately, doing the low budget that they had, they had a cyber attack. I don't know if you saw that, but last year, they had a cyber attack. So they changed the priorities. Unfortunately, we could not keep it going with the same idea. So I'm going to look for the same thing. Now, they work with large-length models, maybe include some image on that. Exactly what they're doing, like with drag, with people, data. That's what I'm looking for now. I'm looking for your resume. So don't think I'm going to affect them. Of course. Your resume. It talked me about the biggest NLP project that here. The biggest one absolutely was the last one. Cause I was responsible to build, I end up to end applications like they have nothing in this context, nothing about no chatbot, no large-length model working on their site. And I had to grab all the data. We have like from the SQL data space, also doing some web scrappy in the MGM websites, cause some information in the website, they did not have in the SQL database. Also, the cloud transcripts, I need to like do a scrapping out cloud transcripts to, you know, push some relevant information about question and answer from the guests. And I think that was my biggest challenge in the large-length model or NLP context. See? What type of tools did they use to scrape text? Basically, I use Python, Python language, with some length chain libraries. What else? Some shell scripts? You went on mute, sorry. Oh, sorry. I press enter here, by mistake. I, I say shell script, I also code for that. But mainly was some Python code with length chain in shell script. Code. And how did you transfer documents after this? Prefeit, you know, I'm sure we have tried. Again, how did you go about chunking your documents? Well, I had to do change indeed. Mainly for PDF documents, basically I use the length chain library. They had a kind of, not wrong, they function is recursive, character, text cleared. I remember some recursive function they have to do the chunks and do the overlap in between the chunks as well. So basically I use length chain to do this recursive. And, okay. And what type of which platform did you develop? It was on my, at first, it was on my side. So I used doc and a container for that. But at the end, on production, they used Azure. The Azure pipeline. So it, you were an AI ML architect. So how much of the work did you do? How much other state for use? Will you be able to talk about it? Well, about the proof of constant, I did all of the work. Science, grab the data, build the APIs. You know, cause I had this lecture database. I also acknowledge graph. I need to connect with the large language model. So I was supposed to preview the API between the applications. Also, I designed out the pipeline from, you know, doing the commits, go to my branch and then deployment at the Azure using the Azure pipeline, of course. But at this personally, I was, I was the main responsible for make-to-work.", "start_char_idx": 2893, "end_char_idx": 6787, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba971bd8-7529-4bea-bcb9-e6102dd09fb0": {"__data__": {"id_": "ba971bd8-7529-4bea-bcb9-e6102dd09fb0", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "eae19f89d11081b390d0f47d52ab1629ca7075bbc11a5cadb2a1df995990256e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fa9daee1-81cd-4f22-b73c-da31a58636d0", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "78eaea1d4d4bba1dbfbd10a42b1b379e9fd769d76a6d0d6198fd74ce9c3b0519", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1d4ed061-3fe1-4e2b-9597-cb82ae4199f3", "node_type": "1", "metadata": {}, "hash": "d26ffd30d9bc97731fc4400ad2fcc56116530cca35d1b95ffad93cf5ce26f942", "class_name": "RelatedNodeInfo"}}, "text": "So I used doc and a container for that. But at the end, on production, they used Azure. The Azure pipeline. So it, you were an AI ML architect. So how much of the work did you do? How much other state for use? Will you be able to talk about it? Well, about the proof of constant, I did all of the work. Science, grab the data, build the APIs. You know, cause I had this lecture database. I also acknowledge graph. I need to connect with the large language model. So I was supposed to preview the API between the applications. Also, I designed out the pipeline from, you know, doing the commits, go to my branch and then deployment at the Azure using the Azure pipeline, of course. But at this personally, I was, I was the main responsible for make-to-work. Did you do fine-coming or reg? I was doing reg, in that case. It's a bit lazy. But I also did a fine-tuning in other contexts. Cause I was a total, I need to pull all the data from call transcripts. And that's pretty hard. So I had to do a fine-tuning like I had a couple of instance of call transcripts and a couple of instance of summarization, you know. Cause you need to summarize these call transcripts, you know, pull the information easily. And at that time, I used like a kind of fine-tuning using heavy-faced models. I probably, you are familiar with hand-faced pipeline. So I used to find a hand-faced pipeline to find the model for this specific test summarization. Okay. Perfect. How did you go about testing the models? How did you know that, you know, you're finally, your model is working. You mean about the hallucination measure, right? That's pretty hard. Yeah, that's pretty hard. We had a sample of data set, like I told you, I had the sample of transcripts in this suitcase, and then the call summarization. And I did a measure by similarity. I was using by myself mainly cause I was checking, that's a pretty hard test to do. Checking mainly the data. But I was, I tried to create similar data person as well, you know, doing the similar text, and see the cause in the scene, like between my output, the large-length model output, and then the real what I should get. What similarity did you use, do you? I don't know about the function, or about the... No, what type of similarity matrix? Oh, we got the cause in similarity, and we have some blue score at times, sorry. But I'll, yeah, it was cause in similarity the first and the main one, I just tried to do, you know, see the distance between, which is a simple, ugly distance, distance to see the distance between the words I got. Okay, it's working. I was also in fine cone at the time. Cool. So you looked like you got your degrees from San Paulo. So are you from Brazil? Yeah, I am Brazilian. Nice. Nice. Yeah, because I do, in my previous role, I did a lot of collaboration with teams in Brazil. They have been, which part? So, Uberlandia? Uberlandia? Minus? Yes, that's where our site is, so we did quite a bit of work there. Cool, very cool. They're here, very nice. Talking to you, very nice answers, what, they may be a... What are you looking for in the next role, ideally? What are you looking for in the next role, ideally? You know, ideally, I like to keep work with large-sized model files. You know, as a computer scientist, I believe the large-sized model was a big context-changer for humanity, basically. Now people are noticed, AI, they see, oh, it looks like a match-stuff, but not really. They are trying to do this for at least 50 years, no long time ago, they are research about it. And finally, with large-sized models, you can interact with computers with not a big technology. So, I think that's what a big context-changer for us, for all of us. So, I'd like to keep going with these field models and... Yeah, basically, that's it. Anything I can work with like, in models, human interaction in computer, I'd be very glad to work with them.", "start_char_idx": 6031, "end_char_idx": 9930, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1d4ed061-3fe1-4e2b-9597-cb82ae4199f3": {"__data__": {"id_": "1d4ed061-3fe1-4e2b-9597-cb82ae4199f3", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "eae19f89d11081b390d0f47d52ab1629ca7075bbc11a5cadb2a1df995990256e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba971bd8-7529-4bea-bcb9-e6102dd09fb0", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "0d58be87c33748aaf0249d6db4d5f9073f70f1925fe6d90512da257c2399267b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "18ffbc8e-1924-4670-a809-2d4b430e7c1f", "node_type": "1", "metadata": {}, "hash": "1251b3406c9df88db6ff6e65397a4c387838790a69130e7e29b861e6fbaf76c8", "class_name": "RelatedNodeInfo"}}, "text": "What are you looking for in the next role, ideally? You know, ideally, I like to keep work with large-sized model files. You know, as a computer scientist, I believe the large-sized model was a big context-changer for humanity, basically. Now people are noticed, AI, they see, oh, it looks like a match-stuff, but not really. They are trying to do this for at least 50 years, no long time ago, they are research about it. And finally, with large-sized models, you can interact with computers with not a big technology. So, I think that's what a big context-changer for us, for all of us. So, I'd like to keep going with these field models and... Yeah, basically, that's it. Anything I can work with like, in models, human interaction in computer, I'd be very glad to work with them. What do you program in, Leo? Yes, I do. A lot of programming, actually. What language? What language? Well, my first language was C, and then the second on Java, and then I work with TypeScript, Lua for game, but my last one was Python. Cool. Those are the questions I had for you. What about you? Have any questions for me? I have a couple of questions, of course. I was wondering about the use case. I don't know if you were using it in this context. I'd like to know that. My first question. Yeah. Yeah, sure. I can share some information. So, as you said, when in the text I saw a hallucination, depression, hallucination, so, such GPT, LLM models are good at generating text, a lot of hallucinations. How do we get response of that useful and actionable? So, if someone asks, what should I do in this situation in the form? The recommendation should be, not a random thing, someone has to go and Google it again by actionable. That's what we wanted to get. So, it is a kind of chatbot for agriculture. Something like that, yeah. I was curious about me. It's not my resume, but I am also a agriculture technician. My high school, I was kind of an intern at, an intern at, an intern at school, where I were leaving this school and working this school. So, I was a agriculture technician the first start my major degree. Yeah, so that's very nice to know. So that's a nice background. But now, so that's what we are doing, and then document some other issues there. So quite a bit of a no-peer task for there that you think about it. So we have a bunch of them aligned, and then how do we make that actionable, right? Making sure no hallucinations are there, making sure how do we have a knowledge representation, how do we make sure we have full knowledge, because anyone can ask any questions, right? I agree. Because as you know, as we know, so you want to provide reliable books and reliable information. So that's what we are about, and that's what we are trying to do. Ah, that's super interesting, of course. Many friends here. So what I understand, the first goal here is like to make sure they like to make a model, stay like honest, so they context and so that's it. Right, and you see we're here, Missouri, Convoys, which the application should be deployed here, and used here. So that application will be deployed in cloud, but you know, our headquarters is here, right? So you would have seen that in our Linberg, Linberg and Lado, we have the big headquarters, so that's where we meet and you know, you have one. I saw some site on Grip Cur. Is it that? Grip Cur? Yes, that's the same. Yes. Interesting. Wow, brilliant. Mostly about the person who did that, see my questions, and you can't say about next steps, maybe. Yeah, so the next steps would be, so it's a two-step interview process. So today's the first one. You would have another one with a team. For that, we expect you to get possible present something. It could be a dissertation, but it could be not any confidential company things, but if you can give a 20 minute presentation of whatever you have done around the text, it would be ideal. If not, something is ongoing.", "start_char_idx": 9148, "end_char_idx": 13080, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "18ffbc8e-1924-4670-a809-2d4b430e7c1f": {"__data__": {"id_": "18ffbc8e-1924-4670-a809-2d4b430e7c1f", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "eae19f89d11081b390d0f47d52ab1629ca7075bbc11a5cadb2a1df995990256e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1d4ed061-3fe1-4e2b-9597-cb82ae4199f3", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "1b5757b57192821ce439e94996a4b81d331f9628498bdfdab074cb0b6af632ec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "59f2c73b-cb66-447f-9ba8-a11381e83fcb", "node_type": "1", "metadata": {}, "hash": "9077e213c9328022c3c63ed71f8f8d4b374eb6ea891e243e64e1d0d138b99a1a", "class_name": "RelatedNodeInfo"}}, "text": "So you would have seen that in our Linberg, Linberg and Lado, we have the big headquarters, so that's where we meet and you know, you have one. I saw some site on Grip Cur. Is it that? Grip Cur? Yes, that's the same. Yes. Interesting. Wow, brilliant. Mostly about the person who did that, see my questions, and you can't say about next steps, maybe. Yeah, so the next steps would be, so it's a two-step interview process. So today's the first one. You would have another one with a team. For that, we expect you to get possible present something. It could be a dissertation, but it could be not any confidential company things, but if you can give a 20 minute presentation of whatever you have done around the text, it would be ideal. If not, something is ongoing. So the question is whether you would have any slides or we are not testing it. But prepare something if you can reduce what you have. That would be great. So I wanted to check with you whether you might have something here. All nice. So is it this called Open, the subject? You had a specific subject for the presentation. Any old project that you have overcome would be ideal. And if it's NLP, that's even awesome. Or mission learning, that would be great. So yeah. Well, interesting. Yeah, I have something to build on this way. And I can present that totally. The same. Perfect. And then we would perfect. And then we would have a coding test. You have just to be five feet. You have a computer science background for a long time. It's to be a easy, easy thing. You should just knock it off. Yeah, hopefully. Yeah, that would be it for you. I would be surprised. And then they would make take about a few questions here and there. You can talk to the team Christian answer questions and then go from there. Nice. What's our next step? So for sure. Okay. Sounds good. The last question is how, you know, if things go well, you know, when is the earliest or when can you start? Yeah. Anytime. As soon like. Basically I can join now. I can't wait. Okay. Sounds good. Okay. Any other questions you might have from you? I think that's all for now. I'll save some questions for next step. Sounds good. Thank you for your time. Very nice talking to you. Okay. You should hear from us for the next round. So okay. Nice. Thank you very much. Appreciate it. Thank you. Take care. Very nice. Yeah. Vendor. Let's call. He's not a call. He's not a vendor. He is the chief data scientist. Looks like a vendor. Yeah. I know the very cool guy. Yeah. I will remind you. If you the last thing you should say is their name. Even if it's hard. I don't know how to spell that name. It's right in front of the chat. So. Yeah. Bala. Pass and. Yes. Balance. Yeah. Even if you just make an effort. It's very appreciated. I tried my best. I think that's what I'm going to say. I'm going to say. I'm going to say. I'm going to say. I'm going to say. I'm going to say. I'm going to say. I tried my best to split it for you. Yeah. I did not understand if you tried to put the name here. Or it was to me to try to read that. Bala. That's. Bala. That's. For. Bala. That's. That's. That's. So. So Leo, what we're going to do is. When we get this interview. Mauricio, I need to know in advance what I'm going to do is. I'm going to give you one of my toys. And this particular toy does something really cool, which is. You give it a book. And then it becomes an expert and you can you can, you know, query it and stuff like that.", "start_char_idx": 12316, "end_char_idx": 15780, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "59f2c73b-cb66-447f-9ba8-a11381e83fcb": {"__data__": {"id_": "59f2c73b-cb66-447f-9ba8-a11381e83fcb", "embedding": null, "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c433fffb-ab0b-4f64-afb2-b5f065255c4f", "node_type": "4", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "eae19f89d11081b390d0f47d52ab1629ca7075bbc11a5cadb2a1df995990256e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "18ffbc8e-1924-4670-a809-2d4b430e7c1f", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "93366da44db1fa6be934d23229ab41fa8325d4984733b7231219bed8c7a654c9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b93328c-f438-435b-b791-1a77d7474f9f", "node_type": "1", "metadata": {}, "hash": "b2e650b768bec4df78b37df6ff66d31891fb9610e414fb02bbe8493e57f63815", "class_name": "RelatedNodeInfo"}}, "text": "I'm going to say. I'm going to say. I'm going to say. I'm going to say. I tried my best to split it for you. Yeah. I did not understand if you tried to put the name here. Or it was to me to try to read that. Bala. That's. Bala. That's. For. Bala. That's. That's. That's. So. So Leo, what we're going to do is. When we get this interview. Mauricio, I need to know in advance what I'm going to do is. I'm going to give you one of my toys. And this particular toy does something really cool, which is. You give it a book. And then it becomes an expert and you can you can, you know, query it and stuff like that. So it's a simple, a simple program, but it goes through all the steps. It's my training video. And. And that will definitely do. Hello. I don't know. Somebody behind you saying hello. Who's that? He's my colleague. He's Ivan. Ivan. Ivan. Ivan. They're looking for you. Pueblo. Is a Jaime. How's that? Hi, Ivan. Bye. A quitos. A quitos. Entendemos espa\u00f1ol. En que algunos hablamos. Hablamos. Deberchief. Yeah. And some of us understand Portuguese. And when we're drunk enough, we speak it. Yeah. Indeed. Indeed. I feel that that that that especially when I drink too many guipinines. Mm hmm. Yeah. Almost. Or he comes. Yeah. It's all it's all everybody. If I have a friend Robert is not Robert is Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. Robert. I was going to question some question that doesn't seem to be. So there are a lot of people here who have lose tele Matthews. They sound the Portuguese, especially this Brazilian. Yeah, they know how to live a little bit of sambal, a little bit of steak, a little bit of kashasa. That's it. That's all you need. Maybe a beach. Definitely. Definitely. That's the best in the world actually. All right, gentlemen. It's 9.30. Thank you. Thank you both of you. On a Friday. I only did this for you, Leo. Otherwise I would have thought I would have told them, hey, I'm sorry it's Friday. Yeah, I really appreciate it. Okay, no worries. I know I'm glad. I appreciate it, Jan. Okay, I'm going to see you. Good job. Thank you, guys. This was great. This is this is for you. It seems to me. Yeah, and you can go on. We got moving. It's here at home without me. Yeah, actually. You're doing great. You're doing great. Thank you, Jaime. We really appreciate it. Everything I'll keep you posted as you may know. Please stay safe. You guys. All right. See you Monday.", "start_char_idx": 15171, "end_char_idx": 17627, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4b93328c-f438-435b-b791-1a77d7474f9f": {"__data__": {"id_": "4b93328c-f438-435b-b791-1a77d7474f9f", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "59f2c73b-cb66-447f-9ba8-a11381e83fcb", "node_type": "1", "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}, "hash": "c62de141f0a050b25ffc55daf0930c3c24053bbd112e0edba9010ec60712b8ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "140039e2-6389-4239-8c9a-a47e43509eeb", "node_type": "1", "metadata": {}, "hash": "02391fc1150035a6e33281600bef9221471128e78aec46877efc781db3aad72e", "class_name": "RelatedNodeInfo"}}, "text": "I will mute. It's good. It's really surprising here. Can you see the message? Can you see the message? It looks like you were hiding there. Yes. So it's my turn. I'm going to mute. I'm going to mute. I'm going to mute. I'm going to mute. I'm going to mute. I'm going to mute. I'm going to mute. Hi, Leo. Hi, Angela. Hi, Leo. Hi, Josh. Hi, Leo. Hello, Mike. Hello, Leo. Hi, Mike. How are you? So first I grew it, and you? I'm doing all right. I'm taking over the world. I see you have the big, you have big plans. Yeah, yeah. Somebody's got to do it, right? Yeah. Why not, Mike? I like the way you think, Johnny. Hey, Leo, I wondered before, like, I think we are, we are afraid, right? Are more people going to show up, Mike? I think so. I hope you show up. You want to say that she declined some, yeah? Some of you in your group now? No, not in the. Okay, so this, this may be the, uh, she says accepted, but I don't see her here yet. Angela, hi, Angela. I'm sorry. So we're good, I think. Unless you want to wait for, for Gary, but I, I don't know. Okay, let's, let's give, uh, Somia one more minute, while we do some technical kind of double checks. So we want to make sure. Leo can share his screen and, and, and, and like that, so for this presentation. And then while we wait for rest of the folk. Sure, the sure my screen now or. Yeah, just check check if you can share your screen. If there is something needed to be done. Yeah, you can try sharing your screen. So that while we're introducing ourselves, you have time to fix any of these issues. Never know. Let me know it. Perfect. Perfect. See it's perfect. The hot abs. Yeah. Yeah, everything is perfect. Okay, that's good. It's good. So Mike, see yours. Go ahead. You're the. Oh, you will. I've, okay. My name is Mike Martinez. Um, my work. Uh, I work in smart operations within field operations. And I'm doing environmental modeling. I do a lot of clustering. So in actually right now, we're putting together some clustering. We're clustering Brazil at 30 meters. So that's a lot of data. And we've actually done it previously, but we're doing it again, because we're putting it in a different cloud ecosystem. And so this is a test case for that. So that's that's pretty. I think that's a very interesting kind of work. Uh, and we have our own internal algorithm for doing that. My background is in electrical engineering. And I trained, transferred over into the science side around five years ago now. And I've been leading the. The environmental modeling team here for. I've been doing it for almost two years. And during the same thing, but there's a lot of different pieces that I look at. Um, I don't want to dive into details on that. I do have a lot of experience with. Going in the building. Some deep learning. I have done some. I think that's a lot of work. You know, the, the, the gated architectures. I haven't actually played with transformers yet. Um, other than, you know, at an API level. But I have an actual gun and gun. Any of that, but I do have some deep learning background. So that's. And that I think is why you guys bring me in, journey. Here he keeps bringing me under these. I think we're all from together. The similar amount of. Kind of. Yeah. Okay. So anyway, that's, that's me in a nutshell. I'm more than happy to talk about myself, but more than here we talk about me. Yes. Well, you guys speak. Okay. Go ahead, Angela. Can you introduce yourself?", "start_char_idx": 1, "end_char_idx": 3446, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "140039e2-6389-4239-8c9a-a47e43509eeb": {"__data__": {"id_": "140039e2-6389-4239-8c9a-a47e43509eeb", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b93328c-f438-435b-b791-1a77d7474f9f", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "141d1b14354216afbae01d082f9fc08fea0beae658dde14f25eeca81a1bc2934", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e76b746e-de81-4a0d-8055-288367541a6f", "node_type": "1", "metadata": {}, "hash": "a0c6230944f36072e9eb22fc0f704a55751acc4cce63a8b621525201f25f8e25", "class_name": "RelatedNodeInfo"}}, "text": "Going in the building. Some deep learning. I have done some. I think that's a lot of work. You know, the, the, the gated architectures. I haven't actually played with transformers yet. Um, other than, you know, at an API level. But I have an actual gun and gun. Any of that, but I do have some deep learning background. So that's. And that I think is why you guys bring me in, journey. Here he keeps bringing me under these. I think we're all from together. The similar amount of. Kind of. Yeah. Okay. So anyway, that's, that's me in a nutshell. I'm more than happy to talk about myself, but more than here we talk about me. Yes. Well, you guys speak. Okay. Go ahead, Angela. Can you introduce yourself? And then we. Good. Yes. I'm Angela. I started at Bayer on January 2nd. So a very recent addition. Um, but before that, I had just completed my. PhD in data science at NYU. And my work there was focusing on. Using natural language processing methods to study. Social media data. And here I've been working on. I think I'm a lot to say what it is, right? It's like a. Um, basically, you know, generative AI question answering system. Specific to agriculture. Cool. So it's my turn now. So I'm Jodi for my goal. People call me Jodi. And. I've been working in Bayer for more than three years. And I primarily work with remote sensing data. Applications, remote sensing data for mapping monitoring. And. Crops across. And my background is primarily remote sensing. I've been working in this field for. Close to two decades. During my PhD postdoc. I was a professor at a university. The university at Madeleine. It was also worked. At NASA for a short period before I jumped into the. The private sector. And I have. I'm part of DSO. And the. This is not operations also. But my focus has always been. Sensors and insights working in. Figuring out what sensors work. What is that like, especially space around sensors. So that's my background. Now to you, you. Nice. Very much. And while Mike was talking, I got a lot of flashbacks because my first contact with buyer was in Brazil. You know, Councilman, Brazilian. And. Maybe you don't know. Yeah, it's not my. My resume, but I did that with the technician. It was a high school intern. School, you know, when you live in school, you work. So in there, I met the buyer with some boot camps. About the seeds about. And. And. And. And. And. I talked about myself. So yeah, I am a. Data scientist. At the beginning, I was working on a time series and math models. By the way, my PhDs focus on computer science and math. My. My thesis focus was in IoT and. Answering. Probably. It's more related to draw. You know. But also using some geoscience techniques and machine learning, you know, to make sure the quality of data. But in the industry, at the last two years, I've been working with large language models and some fun to me for other times series model as well. But yeah, my whole background is based on machine learning and statistics and also some research models. Basically, that's the big picture about me. Okay. I was going to hear it. The interlude quite quite interesting. So the way this interviews are normally structured is that you have a presentation. You take us through. You walk us through one of the projects and we kind of have a question answer session where you. Like we discussed back and forth and then we have a kind of quick coding test kind of thing where we ask you to solve a very simple problem. Something you'd have encountered in high school. And it's it's and it's normally quite quite quite easy to deal with. How do you know that? Norris. Or does it turn myself on of? So, so let's start with your. With your presentation and then we move from there.", "start_char_idx": 2743, "end_char_idx": 6477, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e76b746e-de81-4a0d-8055-288367541a6f": {"__data__": {"id_": "e76b746e-de81-4a0d-8055-288367541a6f", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "140039e2-6389-4239-8c9a-a47e43509eeb", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "a65e78856112819306c22da5f4047f7f2677d1ee27316280c97ac18f19bdc7a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "349bab13-3696-48e5-8eab-ede27cef7c8c", "node_type": "1", "metadata": {}, "hash": "8b9243dbdba27fb2d9c43011a4a035e2c1636dfeb73cfcd3149eed8104a6737a", "class_name": "RelatedNodeInfo"}}, "text": "But yeah, my whole background is based on machine learning and statistics and also some research models. Basically, that's the big picture about me. Okay. I was going to hear it. The interlude quite quite interesting. So the way this interviews are normally structured is that you have a presentation. You take us through. You walk us through one of the projects and we kind of have a question answer session where you. Like we discussed back and forth and then we have a kind of quick coding test kind of thing where we ask you to solve a very simple problem. Something you'd have encountered in high school. And it's it's and it's normally quite quite quite easy to deal with. How do you know that? Norris. Or does it turn myself on of? So, so let's start with your. With your presentation and then we move from there. Does that does that make sense? Mike and Angela, if you have anything to add, we'll go for it. Yeah. Oh, sorry. Oh, go ahead. Sorry about that. No, just saying yeah, that sounds that sounds good. I don't care if they are. Do we know if Gary can join or. I don't think he's joined. He tries to make it to these. And I'll I'll go question again, but he's a very busy guy these days. Yeah, let me see. Yeah, and yes, so normally after five minutes, you just once we have like three people. So yeah, it sounds like a good plan. I usually anticipate seeing what we have to show us. All right, then to the rated sorry. So. I guess go ahead. Yeah, yeah, yeah. So the last me, the last interview, I was talking with. I remember the second name, sorry, but I guess a lot of us and we were talking about machinery and large models. And that's what I'm applying for this position. So I'm going to be the main product now is to work with large models and so doing. Math as well. But I prepared here for you a presentation about large length of models and red. Because that was the name popped in our last meeting, our last interview. Right. So doing your background and my background, I believe everyone here agrees that large length of model was a big. Context changer in the last year, the last couple of years. And that's what I'm talking about the large models and red. But on we live in the Missouri, the show estate, I'm going to show some use case. Right. With this first I had worked my last project at the MGM resorts. The main focus was to build some agent assistant. Cause they had a lot of problems with the agent. You know, guys, how to request some system. I don't know about this room. I don't know if they are friends. I don't know if this restaurant is child friendly and a lot of times they do not know the answer. So they spend a lot of time asking some co workers or who the colonel hold. So that was a big. I say that bad experience, you know, bad customer experience. So my main task in this first was to develop some chat box was system. So they have a knowledge centers of knowledge data database. Where they can query these database to a large length of model. So that was the big feature here. To the chat box to assist agents and some calls, the call center basically. All right. So as you know, there is no perfect model. There is no such thing as a perfect model, but only the useful ones. So what I'm showing you here is how to make large length models the most useful possible. Or something like that. So for that, I've prepared some two ways to do red. The first one is using a knowledge grad. And it is an important information for you. This is a pretty simple way to do red. If not any complex stuff, cause doing some sensitive information. I could not show you the whole application like the production application. And I'm just showing here some box, some initial research I'm doing. So that's it. You just cut expectations not at so advanced. This advanced techniques to do red, but it's just the base. And you can dig around here and go deep in advanced questions and how to improve the model. All right. So the first one, the first way to do red is using vector database. So how does it work first?", "start_char_idx": 5657, "end_char_idx": 9703, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "349bab13-3696-48e5-8eab-ede27cef7c8c": {"__data__": {"id_": "349bab13-3696-48e5-8eab-ede27cef7c8c", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e76b746e-de81-4a0d-8055-288367541a6f", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "45a494be68170270c16e344f51a1531ef7c37c2f17fecab94001e2dbab11f5ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef945fdf-828d-4f48-8741-3fb64f8f5910", "node_type": "1", "metadata": {}, "hash": "dbe9579e6f0caa66a5f351b534ccd216357a8f03522bb8c1169ebb029338f40a", "class_name": "RelatedNodeInfo"}}, "text": "So what I'm showing you here is how to make large length models the most useful possible. Or something like that. So for that, I've prepared some two ways to do red. The first one is using a knowledge grad. And it is an important information for you. This is a pretty simple way to do red. If not any complex stuff, cause doing some sensitive information. I could not show you the whole application like the production application. And I'm just showing here some box, some initial research I'm doing. So that's it. You just cut expectations not at so advanced. This advanced techniques to do red, but it's just the base. And you can dig around here and go deep in advanced questions and how to improve the model. All right. So the first one, the first way to do red is using vector database. So how does it work first? I mean, here using rag with large length models, not just red. Red is something that came to us. See large models are we can use just red for other purpose. All right. So the first thing that suppose various and large length model on top of a vector database. To do red, you know, which way of information. So the first step is like the user is doing questions or thanks on thing to the chat box. The second step, we do a query search here into the database, the vector database. And after that, we got to put the chunks, the retrieved information. Right. From this database. And with the question, plus the chunks, the these retrieved information we can then formulate or return to the user. More created answer. Basically, that's it. So let's see how does it work. I prepared this notebook. I just show how it works and there is process step by step. Again, pretty basic stuff, not so advanced. There's many ways to do red. So this is the simplest one. So the first way. So first thing first, we should make sure we have all the libraries and then we'll have some access to the opening I API. Right. In this case, I'm used judge pity. I'm used judge pity for the subject 3.5 and also have some cases for just a different between models and how they answer and how I create the answers. Right. In the second case, I'm going to show you using another technique with knowledge graph or data graph database. A bit different, but you see let's focus on this one first. The right with the vector database. Right. For this vector database, I'm used findcon here, the free version. And you can see I already have something here, some embedding words, some embedding information, the chance out here. And let's see. First and first. So we need to grab the data. Right. I think the whole data science field, one of the big challenges is about data. You know how to clean data, how to prep process. So we are a findout to skip some steps here. I'm just download this book from the written bird website. It's a book about agriculture. Yeah. The beginners doing another use case with any general resource data set. So here I just changed the context to a good. Right. So it's a huge book about a picture, telephone. And I have here the whole book. Also, I already got the data. Now let's do the chunk. Let's do the chunk and then insert this embedding the chunk into our vector database. So again, pretty simple way to do. Change using the chain with the her Christopher character text leader. Right. So we just define the chunk size. We can put develop here is the characters not the word or tokens. How usually you see large length models. And we can define how so I overlap. So they are put the chain returns here, but also we can. Copy or replicate the last sentence, the last few words. Just make sure you have our overlap and you can like. Post information here to retrieve that. So after that pretty simple to do. Just can say the her true story here doing the change and then I passed the role text what's role text my whole book here. Right. Have my whole book doing chunk. And I'm bringing here some chance to just check, you know, the three to six position. Once sorry, I'm a little bit under the weather, but I'm definitely trying to present here. But sometimes I can.", "start_char_idx": 8885, "end_char_idx": 12973, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ef945fdf-828d-4f48-8741-3fb64f8f5910": {"__data__": {"id_": "ef945fdf-828d-4f48-8741-3fb64f8f5910", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "349bab13-3696-48e5-8eab-ede27cef7c8c", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "51cd74e10bd2d9c5b219f44a5c0823118592d3794b47e45796c2efc2415513cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4a7806b1-85e8-4832-876f-05eb1d78f92d", "node_type": "1", "metadata": {}, "hash": "207384938a08b4b9d77d19bcecc3d3127886e45559a0e391f2f2535247fcc6e5", "class_name": "RelatedNodeInfo"}}, "text": "Right. So we just define the chunk size. We can put develop here is the characters not the word or tokens. How usually you see large length models. And we can define how so I overlap. So they are put the chain returns here, but also we can. Copy or replicate the last sentence, the last few words. Just make sure you have our overlap and you can like. Post information here to retrieve that. So after that pretty simple to do. Just can say the her true story here doing the change and then I passed the role text what's role text my whole book here. Right. Have my whole book doing chunk. And I'm bringing here some chance to just check, you know, the three to six position. Once sorry, I'm a little bit under the weather, but I'm definitely trying to present here. But sometimes I can. All right, you can see the chunks. Also have the chunks. You just create a window state of frame with this is an optional step. Right, you can use like any other. Library. I start or just put the whole thing, but this is the way I find a file to organize, you know, put a chunk table. Actually, this is an index table, you know, when you have a metadata, the chunks have the values and have ideas. I am trying to tell us. Develop what it's about. Think about in words from that. I'm not going to explain it. All right. This is there are many ways to do that. This is just the easiest one and pretty useful. How is it works? All right. So I have three functions to function here. The first one, the metadata is just doing something similar to a hash, you know, creating some ideas. So for make sure they are unique, unique, you know, have the embedding values here. And then the text, the original one. All right. And this table will you find after here on our vector database database. Right, that didn't say it. Let's move forward. Now we are upset and the three of some fine call. Just make again, make sure we have fine con here into machine. I'm using call lab. So you look all. Even if you use like the free version or the paid one, you need to. You should have a API key here. And that's important because we need to connect to the record database with our code. We are in different machines. Everything we already know. I'm using my API key here. I am using the my database. I have this one. I've read for this presentation. And just sending up the environment variables. Right. Make sure you did this connected. I really did mention why designation calls here using open and I. API in a opening I API has this limit of the mission. And you're also the opening I am getting. Right. So where we have something there. How so I have a really inserted previously. Let me see if you give some more information about this. I don't know how deep can I go, but if I. I did not go deep enough we can. No, not this. But let's do. Let's move on to connection with database. Chanks are we gone and betting are really gone. So let's prepare our data set here to import. A percent. Right. So again, I'm just here doing the chat size and convert our records to. This is that already executed. That's why I already have some information that I created a base. So I have already reported that. Here I'm going to use this functions. I'm showing. I don't know if you have any delay and the chair screen, but I'm showing up now. So functions to retrieve the three-wheel information. Right. Why? Because I'm going to use it to connect my large, my opening. I model and then do the questions with these chunks and retrieval information. So here I am just in part live libraries again. Why I'm doing again and again calls we can run independently. This part of the code so each section here have the low data. We have create a split chunks, absurd and complexions. We can have this code in different notebooks and you can run then independently. From each part. I'm going to use the previous one. Also I start the new section. I can. I can. I can. Thank you again. All right.", "start_char_idx": 12187, "end_char_idx": 16133, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4a7806b1-85e8-4832-876f-05eb1d78f92d": {"__data__": {"id_": "4a7806b1-85e8-4832-876f-05eb1d78f92d", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef945fdf-828d-4f48-8741-3fb64f8f5910", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "370a4314db4fa314b6ca05a597ceafe4aaa82c5a3ae9cd72cd2709c9894b92fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f828e89b-515e-43bc-beea-86204ebc775d", "node_type": "1", "metadata": {}, "hash": "0c7f5a13fbad595fba1110b3e1b7d4364a03c11fd19168a3c7bb3f85a9ce75bc", "class_name": "RelatedNodeInfo"}}, "text": "Here I'm going to use this functions. I'm showing. I don't know if you have any delay and the chair screen, but I'm showing up now. So functions to retrieve the three-wheel information. Right. Why? Because I'm going to use it to connect my large, my opening. I model and then do the questions with these chunks and retrieval information. So here I am just in part live libraries again. Why I'm doing again and again calls we can run independently. This part of the code so each section here have the low data. We have create a split chunks, absurd and complexions. We can have this code in different notebooks and you can run then independently. From each part. I'm going to use the previous one. Also I start the new section. I can. I can. I can. Thank you again. All right. Oh, something important here. Maybe all but the do I have an important environment here. Normally I have a private file with these environment. As usual. I have separate environment. I have a separate environment. I have a separate environment and the variables to. But here also have an notebook just a port again. There's a pretty simple one and I'm just put together here. All right. Let me check if I am out of time. I need to present the acknowledge red. Yeah. All right. Here just some functions to clean up data. I got the chunks. I can split them. Okay. I have the K first chunks. Then I can use the first one and then I just put some packs here to split that. All right. And we are reaching some important thing here. One of the most important in large and large models that is from engineer. Why calls the from engineer will be responsible for a proper arm. And not so good answer. Right. For instance, in this case, I am. Tell the large knowledge model you are. Caching answer bought. But be sure you are just answer based on the vector database on the information you had. Not if you don't know. Don't make anything. Don't don't. Don't you there is any other garbage just to say I don't know. So the from engineers are pretty important set on when you are using large language model with frag or just large and the models from engineer is a crucial stat to get a proper answer. You we can see here like let's use the first first red response right. So the first one I'm saying okay, you don't know you say I don't know. All right, if you don't have information in the chunk in the vector database or the information is not provided. So let's try the first one I can ask like what. Future something. What is the. What is the monster right. So say I don't know why I have a lot of I don't know cause I mean just bring here if you want to see how it works the function here the completions how I am splitting I just bring you just make it easy. But the answer is that one. Okay, so I don't. Okay, so what is the best. Culture technique. Probably you bring some answer calls you talk about the future right. All right, that's something the best. The technique depends on specific nature. Okay, at least it knows something about the future. They say okay depends on many factors depends on the ground depends on the flies are depends on the water depends on many. Many factors. But you see if I ask anything out of context it you see I don't know. Right, you can try you can play around it later let move forward and connect the next way to do right. I had this image here just to explain how and that and an index and how to put chunks into. Direct database but let's keep it for now. The second way to do right that I've been work one it's used at the knowledge grave acknowledge graph database behind the chatbot behind. So behind the. The large language model. So how it works. That was that was some approach that I found that again many ways to do that we can have many models that have only one model work on it. We can have like much attribute search here you can have many ways this was one of the simplest one and use it was well. So how does it work first user can from here do some questions then second is that we have two models here. The first model is responsible for generate the site query. So query.", "start_char_idx": 15358, "end_char_idx": 19459, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f828e89b-515e-43bc-beea-86204ebc775d": {"__data__": {"id_": "f828e89b-515e-43bc-beea-86204ebc775d", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4a7806b1-85e8-4832-876f-05eb1d78f92d", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "507db1be128be7b3e69b9d228722c1decc11ede81d0097c0b40deeabdfff7e9e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9d7450a4-6b0d-4238-a706-a8555c96e132", "node_type": "1", "metadata": {}, "hash": "e282990177df92aeab82b7ae8a8d2dd9559acfdb6c176ed8f9956ff78ba54afe", "class_name": "RelatedNodeInfo"}}, "text": "I had this image here just to explain how and that and an index and how to put chunks into. Direct database but let's keep it for now. The second way to do right that I've been work one it's used at the knowledge grave acknowledge graph database behind the chatbot behind. So behind the. The large language model. So how it works. That was that was some approach that I found that again many ways to do that we can have many models that have only one model work on it. We can have like much attribute search here you can have many ways this was one of the simplest one and use it was well. So how does it work first user can from here do some questions then second is that we have two models here. The first model is responsible for generate the site query. So query. You don't know it's a kind of SQL you know SQL query to SQL database. I query is a query for new project database. New for days are acknowledge graph. The graph database. In case so I have two models the first one to do the site query and the second one to respond to the user. Right. So after we have the site query let's suppose I'm asking about the future again then OK let's make a site query that is querying about the future then the new for your return in this case information different in terms. And the after database and then we've got but again from here it works the same way like from here that fight. It's pretty the same then step six and seven here because once I have the question I have some information I can work on the project engineering to say if you know this information answer based on that piece of information if you don't know if you don't have it just say I don't know. Right and I would show if I have time I would show a third option that is a hybrid one using vector database plus knowledge graph but I did not have time to finish it but just we can discuss it later. So let's see how it works. And please let me know if I'm out of time. OK I'm speaking a lot of steps here cause again many data management is a pretty hard test so have a lot of preprocessing steps will have for build this knowledge graph I had to do is web scrappy on the engine result. Besides I had to pull some some dump files dump from the SQL database also had a lot of PDF to split and for the information here but the point is I have a knowledge graph with some information about gas about restaurants I did not have time to change the whole context here but that's OK cause all of I have here is public information you can find at mgmresort. And the general resource website so no problem about that. The focus for these use case is restaurants let's see if I can find the restaurant here hotel let's hit it. I will hotel I think I have more data. You can see like in your hotel I can tell like the menu or the options I can say but it's pretty hard to build a site query using just you know for scratch. That's why we are using a large amount of modern top of it just come back to the image. In the first case my best experience was using chat pit for for site queries and chat pit 3.5 to answer house it's cheap and the answers are pretty acceptable right and that's not the same case to the first model to generate site queries I had to work a lot more on 3.5. So that's why I use chat pit 4 here API and here 3.5 to the street and I can't get my text and the query was as well. So I can ask about something okay what restaurant options you have at higher hotel. Again it's a fork we have could have some high hallucination here and again you can go later how to improve that. How to do that the blog the previous. At the beginning I was working on this interface and this okay okay my API key probably is not working. Well there's still a half time I can change the I key maybe using the same I was just because this one I was working yesterday is there a different API keys. I can change it pretty quickly. Oh and something maybe important probably for the here I'm use doctors and containers to insunstate these applications here I have containers for a new project I have containers for the item code with model I can show you here. Okay here in the training I have let me show you. I have some instance of site query but on the production version I just put some. Graph schema you know all the connections all the ads all the weights and the ads also for this specific.", "start_char_idx": 18692, "end_char_idx": 23048, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9d7450a4-6b0d-4238-a706-a8555c96e132": {"__data__": {"id_": "9d7450a4-6b0d-4238-a706-a8555c96e132", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f828e89b-515e-43bc-beea-86204ebc775d", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "797cae516614ce76445df195de23e2aa6e71c74aae1464d074b24448f8feb078", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "60cd25fe-1b89-42e6-9cbc-6559480f1a48", "node_type": "1", "metadata": {}, "hash": "8d6be009ee250dcfd2661211f16311f97108f8e25b9402a913887b765443135b", "class_name": "RelatedNodeInfo"}}, "text": "Again it's a fork we have could have some high hallucination here and again you can go later how to improve that. How to do that the blog the previous. At the beginning I was working on this interface and this okay okay my API key probably is not working. Well there's still a half time I can change the I key maybe using the same I was just because this one I was working yesterday is there a different API keys. I can change it pretty quickly. Oh and something maybe important probably for the here I'm use doctors and containers to insunstate these applications here I have containers for a new project I have containers for the item code with model I can show you here. Okay here in the training I have let me show you. I have some instance of site query but on the production version I just put some. Graph schema you know all the connections all the ads all the weights and the ads also for this specific. But I have I have to work in embedding so for at least for the restaurants I already have the embed information here I really to build up at the database on this application. But that's my application. Okay so let me change the API key here and I can have time we can start questions you can I can answer later. I can demonstrate later. I think you had been good on time but if you want to take few minutes to do this go ahead. I can show you it working but we can start with questions and in the meantime I can change the API key here and show you later. Because as I was doing sorry I was focused on the first rag and I say oh that's what's working I don't need to worry about but actually I had to. I'm actually getting a lot of my questions answered by watching you go through and do this. So can I try to change the API key here or I'm hoping for questions right now to. Yeah actually you're answering my question right now by going through and changing the API key and letting us see the insights of what it is that you're working on so I would say go ahead and change it but if you guys if and or or jelly want to want to start answering different questions that's fine too. I agree with you Mike go ahead leave a change unless Angela you have questions you want to or comments you want to make. I know I think that's some good for now yeah okay we didn't come back and was was away from some of the other stuff. So so go ahead and change the API we will we'll hang here. So remember where I had this one. On the spot probably I have not divided into the environment file and others so. If I know myself. Do you have it defined in a dot file somewhere no no this was just a. Again a pretty simple application was demonstrate so I don't have it. I do. I hear have the question here again I have a photo. I was using catch pta but I was doing also some experiments with the amount of but I had. High hallucination with the Yamato model. Yeah. I see that you're getting it from the environment. So you may want to do an L. S. A. Just give you have a dot in V. So. I'm going to print the V and put that through that. I keep. So. Next week. Thank you thank you my. Thank you very much. I need to find where I'm defining. So. Sorry for that. Okay. Okay. I should deal with the fact. I'm going to take a couple of minutes. We can start out in the meantime. Okay. I'm going to use IDEs myself. So the question that I have for example I see that we're using doctor. Yeah. And you're using doctor compose. Are you. Is get hug. Is get a tool that you use for social management or do you use get hug or bit bucket. Or do you use those kinds of. Two links in order to manage your. The code that we're developing. Both. I was both. This is a good answer. But so because we do have a private. Version. I mean we're running get hug enterprise in the cloud. So actually if you go back there. Can we take a look at one of your projects and what I'm looking for. Is do you have as you're you're up there at the top of one of the projects. You have. Pick one. Are you using get help actions for. For any purpose or is that something that you don't be so.", "start_char_idx": 22137, "end_char_idx": 26190, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "60cd25fe-1b89-42e6-9cbc-6559480f1a48": {"__data__": {"id_": "60cd25fe-1b89-42e6-9cbc-6559480f1a48", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d7450a4-6b0d-4238-a706-a8555c96e132", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "390f5dfb2d2802011327f6182f70ad1900d5bf2691f0e660ccd7025a651e03d1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4e2c1416-b0c9-4383-aea6-df4854243788", "node_type": "1", "metadata": {}, "hash": "8677bdd83d8f8162e420a7ebc3c21f6c1d6ca0ed09d9c68f603846873dcb2dbf", "class_name": "RelatedNodeInfo"}}, "text": "Yeah. And you're using doctor compose. Are you. Is get hug. Is get a tool that you use for social management or do you use get hug or bit bucket. Or do you use those kinds of. Two links in order to manage your. The code that we're developing. Both. I was both. This is a good answer. But so because we do have a private. Version. I mean we're running get hug enterprise in the cloud. So actually if you go back there. Can we take a look at one of your projects and what I'm looking for. Is do you have as you're you're up there at the top of one of the projects. You have. Pick one. Are you using get help actions for. For any purpose or is that something that you don't be so. If you go to one of your repositories that is. And I don't know what. Try. Chat. If you can go to that. And just look at the files at the top. So I don't see. Any workflows there. No, I don't have. Using my personal. Okay. So do you have workflows in any of those? I do have, but I didn't. I also know. Okay. So we can't. That we can't see right. Yeah. All right. So fair enough. So you are familiar with workflows you have use them. Haveoop executors or do you use the executors that are available via. I have done it. Maving and some. We using jinks. You know that was by myself. I'm. And I actually did it. Normally at the end time, I was. I was normally at the end time. I was. I was. And, and don't. Don't be concerned about the questions I ask. I'm not \u0628\u0639\u062f to find out that. You don't need to be able to do any of these things. I'm trying to find out. Where. What do you have? Yeah. And you don't. So. them to my experience and most of the AWS or we deployed it artifactually. Do you deploy your doctor images or the golden one then locally on them in your chat box that you're building for work? I have deployed to ETS, but most of the time I use by myself using E-Sue, no using Seren far, but I had this pipeline because I had some DevOps experience and also machine learning office. I believe I'm totally able to do the pipeline to, you know, into a from VT Hub to alpha mate person. Alright, and then so clearly you're using Python and you're not just stuck in a notebook. I was happy to see that you're actually building that PY files and orchestrating them together into an application. So you showed us a collab notebook. I'm wondering are other do you have experience with other notebook environments like SageMaker or Donna, Domino or RingGiepper locally or in other some other platform? Okay, you're clear I had I use it all the time, but I'll SageMaker of course and I'm very good to see you. Okay, cool. Alright, so let's see, what other telling questions are there? Because it was when I said that it was interesting watching you go through and look at your files and stuff. It was because most of the questions that I would ask would be related to that. And I've already seen what you're doing there. So how big of a team is it that you work with? Are you working on your own? Are you working with five people, 50 people? How, you know, how is your relationship with the other pieces that you're working on? Are the other people that are working on the same thing? Well, I'm Amy Jim Resorts. My direct boss was the VP. So I was a pretty small team, nine people, three engineers. I was the data science one. But before that, and still for me, I had a pretty big team like we are in party people working the data team. Also my, especially my team, we have like 15 people only work with time series analysis, light chain, customer even sorry and get the garment brand stuff. What kind of project management did you use? Did you have canned band boards to use some other mechanism for tracking, planning and tracking what it is that you're doing?", "start_char_idx": 25513, "end_char_idx": 29253, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4e2c1416-b0c9-4383-aea6-df4854243788": {"__data__": {"id_": "4e2c1416-b0c9-4383-aea6-df4854243788", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "60cd25fe-1b89-42e6-9cbc-6559480f1a48", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b13ccb5320b4851c0178e7e4b4dda433909974e39d6ba168fbb55e629961bf0f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ee6278ee-5f6d-4b4b-8714-bb6bac19a186", "node_type": "1", "metadata": {}, "hash": "a152cad038f870079a51c1fd6832807acf47a3f4b9bd9ead07bf93fb3c8b46a1", "class_name": "RelatedNodeInfo"}}, "text": "Are you working on your own? Are you working with five people, 50 people? How, you know, how is your relationship with the other pieces that you're working on? Are the other people that are working on the same thing? Well, I'm Amy Jim Resorts. My direct boss was the VP. So I was a pretty small team, nine people, three engineers. I was the data science one. But before that, and still for me, I had a pretty big team like we are in party people working the data team. Also my, especially my team, we have like 15 people only work with time series analysis, light chain, customer even sorry and get the garment brand stuff. What kind of project management did you use? Did you have canned band boards to use some other mechanism for tracking, planning and tracking what it is that you're doing? It's so more to use a spreadsheet, you know, how did you know deep planning and tracking that teachers calls? I can sit both, both case. I mean, MGM Resorts and Nester Perina was, you know, totally different. So at the MGM Resorts, we are just gira with canned band. So we have chickies, okay, daily meeting, what do you do tomorrow? Today, what have gone yesterday? Personally, I like to use a formal door technique because, you know, I just do many stuff at the same time. So, okay, 25 minutes for this one, okay, 50 minutes. I haven't heard of the alarm bill. And up at the Sriperina, we had the, we used only Microsoft tools. So they have the chartifying and some spreadsheets in there. So instant use like geratic through have a spreadsheet with which runs name and then the tasks in the second column. Okay, that's, yeah, we use something that's closer to zero than spreadsheets. Okay, so the makeup of the team, you mentioned that you had so many engineers, do you have experience cleaning your own data, finding and cleaning your own data, or is that something that, that comes to you? No, I totally caused that. I didn't do it right. I was the only data scientist. I was responsible for gravity data and demonstrate that, make sure, you know, okay, you have this data and then you have these insights. We can use it. We cannot use that piece of data. All right, so, yeah, you answer most of my questions as you're wondering for your code there. So, and so I'll hand it over to, yes, I can hand it back to you, Joe, you should run this. I can see some you show that, and I'm pretty sure Angela can probably quiz you on more specifics of the chatbot that you're showing. So thanks a lot. I appreciate it. Thank you, Mike. I think I'm just going to share this one. Angela, you have any questions? Yeah, I think you mentioned something about like a hybrid rag with using a knowledge graph. Yeah, I made sure that. Yeah, if there is a theme time, I'd love to just hear some more about that, but I also know, you know, we have to get to like the other parts of the interview. I'll leave that up to. I can see it. Yeah, I just reserved this morning. I'll reveal that for you guys. I'm on learning. Can you see my screen? Yes. Okay, so this second approach I will think about. So why? I think that's not a pretty interesting thing to do. Because we can build more complex links between, you know, cause we have a guest. This guy has a pet and he loved to see. He is a vegetarian person. He would like to. No, go to the spa. Go to Gene. A very active person. So we have many things linked to this guy. And just a vector database was not enough for that. But also, the not geographic is not enough. Cause sometimes the assistant had some spanning either, you know, like instant type MGM type and MGM or something like that. So we were trying to use vector database for cosin similarity. So instant. Okay, the. Decide the query could not find the properly answer the properly. No, the query was empty. So let's try different. Let's try to similarity search. Doing some words close to them and change the query. That was a approach we are working just cause the largely model.", "start_char_idx": 28459, "end_char_idx": 32427, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ee6278ee-5f6d-4b4b-8714-bb6bac19a186": {"__data__": {"id_": "ee6278ee-5f6d-4b4b-8714-bb6bac19a186", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4e2c1416-b0c9-4383-aea6-df4854243788", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "e67c65148904469e56da913c1ac1f324a147151b8a5b3c46351bc5693389f7fe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d822043d-66a1-48d8-948f-c4d6938bce37", "node_type": "1", "metadata": {}, "hash": "d19f593fdd6a18510856f2aeca5d503fc4f52edc965ee1db7698da06d82e0224", "class_name": "RelatedNodeInfo"}}, "text": "This guy has a pet and he loved to see. He is a vegetarian person. He would like to. No, go to the spa. Go to Gene. A very active person. So we have many things linked to this guy. And just a vector database was not enough for that. But also, the not geographic is not enough. Cause sometimes the assistant had some spanning either, you know, like instant type MGM type and MGM or something like that. So we were trying to use vector database for cosin similarity. So instant. Okay, the. Decide the query could not find the properly answer the properly. No, the query was empty. So let's try different. Let's try to similarity search. Doing some words close to them and change the query. That was a approach we are working just cause the largely model. Pretty high hallucinations. I had it. Well, so no worries. If not, I'm curious if you have a sense of how this compares to like doing. The hybrid search where you're doing like both a vector and semantic search. But no, we're just curious. Okay. And then the second one I was. I think I can show you. The first race on again. I want to see if you can show this. I'm going to see if you can see. Okay. I know. Let's see. It's going to start. I'm going to start to find the restaurant's calls. I'm dying. Cousin here. I can show you how I have some embedding. Cousin was listing also the information here, but. I think that's not updated. But. Okay. Beyond the information itself, I also have another. Teacher here like embedding. So instance search for words. I was searching embedding once. And also new for J has it's on embedding way to do. We can embedding the whole schema. You can embed in entities. We can embed in edges. So there again, many ways to do that. We can search in the graph and then use that vector database. Aside are we can use the embedding information from the. Not graph. From each entity or connection. I'm just trying to find here the embedding portion. But that looks like I read out of date. I don't know if you answer your question. Angela. Oh, yeah, thanks. Yeah, I was just curious to hear more about the. You said the use of the knowledge graph. So you so in your test, you found that this performed better. Yeah. I didn't. We are using in production. I can tell you we are using the. You know, we are using the, you know, the. This is the, you know, the. And it's, the, they're using the. There's a major. So I think that this is not new project. And also a side application with costumes to be. Costs to be its, the. Azure vector database. They have. Okay, cool. Thanks. And then. I just want to ask a question for me. Um, I'm here. Are there any difficulties with like updating this knowledge graph? When you bring in new documents? It is. Like I was telling I was I had to do a lot of web scrapping a lot of Documents played so have already some automation process for that But it is if you need to update here you need to do a side query like for update and that's pretty fun That's it. Okay. Thank you Thank you, Angela Hi I wanted to follow up when Angela's really quick so if I could Had to do with you said that there was a pipeline that you could update Your your basically the knowledge base, right? Is that incremental or do you have to start from the beginning each time? You need to show it now No, no, don't don't show it the question is is your is that pipeline set up to incrementally add information? Or do you have to add information and then load everything and basically build from scratch again? Oh, no, no, no, they do us build tool and start and then update information Okay, it's that kind of click wouldn't okay?", "start_char_idx": 31675, "end_char_idx": 35298, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d822043d-66a1-48d8-948f-c4d6938bce37": {"__data__": {"id_": "d822043d-66a1-48d8-948f-c4d6938bce37", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ee6278ee-5f6d-4b4b-8714-bb6bac19a186", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "ee1c6041c9ba54a2e98e152e7335afd12f9b16bc8f38bb97e8f30dcbfa506783", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e510cb65-3a5d-40dd-b7a2-b42982e79b19", "node_type": "1", "metadata": {}, "hash": "a8ae6d895762b69a60045ffda6aaa862eee4ab108ffd003d55bb5ea15f1ef923", "class_name": "RelatedNodeInfo"}}, "text": "Okay. Thank you Thank you, Angela Hi I wanted to follow up when Angela's really quick so if I could Had to do with you said that there was a pipeline that you could update Your your basically the knowledge base, right? Is that incremental or do you have to start from the beginning each time? You need to show it now No, no, don't don't show it the question is is your is that pipeline set up to incrementally add information? Or do you have to add information and then load everything and basically build from scratch again? Oh, no, no, no, they do us build tool and start and then update information Okay, it's that kind of click wouldn't okay? Okay, run pipeline and you can yeah run through the alright But you don't have to we run how many days to tell load it up the first time right oh no, absolutely Okay, all right, thanks Go ahead some yet Hi, sorry, I joined late so I'm from engineering background. So I'll just ask you the infrastructure related questions You know you mentioned that you have written a lot of data models, right? So I was just curious about the CI city process I've also seen that you worked on AWS DCP and Azure So did you ever get a chance to deploy your data models in Azure cloud or how did you go about doing that? Well, at the MGM we had a lot of problems with major So at the beginning I was doing I had a specific VM to myself and then I was doing in that old school You know like share a script doctors and try to just make sure it runs at Azure site But after a lot of meetings discussions and campaigns we finally got access to the Azure machine line pipeline So yeah Beginning I was almost leaving the company. I had the protein to work with So yeah, you're mute Sorry, how did you implement it? I mean how did you push your do you do deploy them as a package? Or did you deploy them as function apps or how did you go about deploying in Azure? Oh? No, this is way I found out time was function Okay got it and how different how different are these deployments from AWS and GCP? They are different platforms of course On my point of view they are pretty similar, you know, I mean the big picture like we have this step this step we have Almost both step in both platforms, but different path So they are different, but I can tell you the big picture if I got a new Cloud platform nowadays I can say okay give me some minutes to understand how to do the steps and I can replicate it Thank you Oh, thank you Sony I have few few questions Very good. I did this a general questions not technical questions. I've had a giveaway break from So you're still working at mgm results, right? No, I finished my project in December Okay, so we're working now Well, hopefully I expect to join by your in the next couple of weeks, but Okay Let's And So before that you worked at Amdogs and before that Nestle you have worked for short period of time. Are these like are you going in a consenting? I'm going from one company or the company or is it like new jobs you're taking up Everytime oh no cause normally I work Consoting so probably perfect. So I had this project this stuff To finish and sometimes they don't have budget to proceed with the project and they just finish But all of them are projects not I did you had any full-time position Okay I mean in my resume you can see that they were not full-time position Oh Yeah, mainly the last one cause they are pretty excited with the results and they say okay Let's build a bigger application now not not just to the call center, but the whole mgm So I was working the virtual concierge But then you don't know you know about this, but we had a cyber attack affect in june july last year I was I can't see this and then they changed they completely changed the piax to the company Then my boss just came with a said face a man.", "start_char_idx": 34652, "end_char_idx": 38462, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e510cb65-3a5d-40dd-b7a2-b42982e79b19": {"__data__": {"id_": "e510cb65-3a5d-40dd-b7a2-b42982e79b19", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d822043d-66a1-48d8-948f-c4d6938bce37", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "0d1f8e495c8b92721882657590c045cc83398dedfe5200eafbb3d6d97c60b3f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2319a23b-d482-4196-9f5e-624250ca0c8c", "node_type": "1", "metadata": {}, "hash": "2b9f55a713f3243035a0dd43ae6d9934fa5531c668d5e361d9a6c12a2e1092ad", "class_name": "RelatedNodeInfo"}}, "text": "I'm going from one company or the company or is it like new jobs you're taking up Everytime oh no cause normally I work Consoting so probably perfect. So I had this project this stuff To finish and sometimes they don't have budget to proceed with the project and they just finish But all of them are projects not I did you had any full-time position Okay I mean in my resume you can see that they were not full-time position Oh Yeah, mainly the last one cause they are pretty excited with the results and they say okay Let's build a bigger application now not not just to the call center, but the whole mgm So I was working the virtual concierge But then you don't know you know about this, but we had a cyber attack affect in june july last year I was I can't see this and then they changed they completely changed the piax to the company Then my boss just came with a said face a man. Sorry, but we don't have budget for next year That's why I left my last project Okay, that makes total sense that makes it Any other question from from Anybody else here's some yeah mic and Angela Uh if if no, we'll do a small test this coding test Sure, it'll be so simple for you Leo But we do this for everybody and and and So we're going to do that conversantly Uh So Angela mic Give me a thumbs up and I'll go for it Um, I'm good Okay Get some good Okay, so uh the test is very simple uh you pick With five numbers and you find the largest number without using any of the functions built-in functions He is just for loops while loops or any of the loops and and external statements and and just figure out the maximum and you have to write the code while sharing the screen It doesn't really have to be an IDE if you can set up IDE and do it like let's say jippie do not book It's fine. It's not you just share a text file and just to type it out Now you can pick any language you want Anything you're comfortable with if you want to just write it in English. We are fine with that also Okay, so code Interesting Not when I go and my last time you just showed code Okay, it means here So So this mega list of five numbers See Okay, five numbers Uh, they are sorted and not sorted how I'm sorted just let's say five 100 thousand and six If there's a lot and it's much easier right Obviously it's not sorted at one more number at one more number. You should be five like the add Okay, add one more number say two okay, sure Two are one. Yeah perfect. I don't know. I do like that. I saw you add a negative number in there So we need one of them. Yeah, yeah, it's a good idea add a negative number Yeah, I was about to say can we add minus two You just go for it add minus two uh to Leo okay minus two Minus two. Yeah. Yeah, just just that's perfect Can you see my screen? Yeah, can you yeah, we're able to see everything so go go even doing good. Okay good. Nice. So The biggest one right Yeah, the biggest one uh and if it can also tell the index of the biggest one that is even better But if you just find the biggest one fastest way that's fine Okay, if you return only the beast one I could just have max function no one on Yes, for the we cannot use max functions any of the functions for loop Okay, so to return to the beast number and the index I'm gonna secure a foreign C here Right so I cannot put like far E equals zero All times like you know, but that's for E my index I sorry Language problem here for I in a range what range the length of these numbers Pretty similar to See look right cause I have three to eight each index and I can check it okay If Normally I could use some function but One and in that's So we've her third I'm sure they are I don't need any validation My biggest one This position I do the index It's bigger than my biggest one I need to save it Okay His equal number Each position and I know say let's I don't think this is special one. In special words, I think this is. Yeah, we could solve the charting one line, but there we go. This is good. Can you copy paste the what you wrote into the comments, the comments? Compat. On the chat. Yeah, in the chat. The because I am who I am, I'm going to suggest that you use biggest equals none to initialize worth.", "start_char_idx": 37576, "end_char_idx": 41763, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2319a23b-d482-4196-9f5e-624250ca0c8c": {"__data__": {"id_": "2319a23b-d482-4196-9f5e-624250ca0c8c", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e510cb65-3a5d-40dd-b7a2-b42982e79b19", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "1257bd5965a1e1ba16a1e0a4eacd67f9df8a17d075db78f4d3ca4b947212d84f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aaaaa1fa-96e5-420e-bba2-b393db5fb1e2", "node_type": "1", "metadata": {}, "hash": "6c57401d7032234f6680774bcedb494c1b230b73f28e10ca9d96970886d87f95", "class_name": "RelatedNodeInfo"}}, "text": "In special words, I think this is. Yeah, we could solve the charting one line, but there we go. This is good. Can you copy paste the what you wrote into the comments, the comments? Compat. On the chat. Yeah, in the chat. The because I am who I am, I'm going to suggest that you use biggest equals none to initialize worth. And you don't have to do it here, but just in general, because somebody's going to come up with a negative bigger number. Yeah, I don't remember Python calls my first language, C and the second and Java, but we have some functions in there like the infinity and infinity something and minus and to make sure that works too. Yeah, just something that's that's not part of what you're looking for. So that you tell. Totally agree. That's not the best approach to pull if I say this is the smallest one. And I thought you can get infinity from Numpy. Oh, but yeah. And we got NAM right. That's. Yes, this is the old school way to do it. It could use like a dictionary, do it more complex, this is the. This is good. This is perfect. Nice. Yeah. Yeah. So, so I agree with Mike that maybe infinity or something like that could have been used, but this is Python is not your native language. So this makes sense. Like is what we used to do in Pascal and. Like. So yeah, this is fine. So thanks for this. Any. Any other questions from Somia Mike and Angela. Yeah. Thank you. Yeah, we need to give Leo some time. I mean, Jody, you haven't asked any question, but we also want to make sure we leave some time for Leo to ask us some questions. Yes, yes, I'm done with my question. This is something I wanted to do that you guys kind of covered most of the things I wanted to cover. And yeah, this is good. So Leo, go ahead. If you have some questions for us, this is a good time. Yeah, I have a couple of questions if you have time. Okay, the first one. We will be my team just in case I join. Who will be teaching like this? We are talking here would be teaching I would work with. But most probably it'll be Geary and Geary. It's going to be your primary person and I think Angela. But we all are kind of. We all kind of connect with each other quite easily, but I think it Angela and and and Geary Mike. Do you have any thought about that? Do you have any visibility about that? Yeah, I think you're right. I know that people try to pull me in. But I am working. Different project right now and you're just keeps asking me questions and wants me to ask you guys questions. So I'd love to play in Geary's sandbox. I mean that that's a given, but I have other responsibilities. And I can answer that question for you. So Geary has a team with Angela and few more developers from a data science team. And it also has an engine in team from where I belong to. We are all working on something called an advisor which I'd been free with the application. And that's what we are feeling a person for. We're looking for a data scientist. Yeah, interesting. I'm glad to know that. And wow, that that's. Lead me to my next question about the project. Can you share about use case? What expect at the first weeks of job? I don't know, maybe you can tell it. I can just talk about business you business from a business level and maybe Angela can talk from a data science perspective. So it's this is all about you know we have a huge knowledge base of a lot of documents beta PDFs. You know our images are you know textual documents are JSON objects. So we are trying to build a chatbot in which could actually answer the questions from the data sources that we are actually trying to consolidate and then host in our application. From a data science maybe Angela can talk about you know how we are planning to implement that. Angela please go ahead. Yeah, so I think we're. You know one of the things that I was brought into work on is like evaluating the model performance. I think we're continuing to like think of how to improve the like yeah the models.", "start_char_idx": 41441, "end_char_idx": 45402, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aaaaa1fa-96e5-420e-bba2-b393db5fb1e2": {"__data__": {"id_": "aaaaa1fa-96e5-420e-bba2-b393db5fb1e2", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2319a23b-d482-4196-9f5e-624250ca0c8c", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "49ae09c49aee4ef5a3d4eec3789268394574dab894c5287bb65c2186899e91d3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "515f688d-285e-4c4f-8ebe-0101e4359e91", "node_type": "1", "metadata": {}, "hash": "2c4fad3f1712144a56879fa398c997f89e5c4c27b85a06c91cd029c7626000ca", "class_name": "RelatedNodeInfo"}}, "text": "What expect at the first weeks of job? I don't know, maybe you can tell it. I can just talk about business you business from a business level and maybe Angela can talk from a data science perspective. So it's this is all about you know we have a huge knowledge base of a lot of documents beta PDFs. You know our images are you know textual documents are JSON objects. So we are trying to build a chatbot in which could actually answer the questions from the data sources that we are actually trying to consolidate and then host in our application. From a data science maybe Angela can talk about you know how we are planning to implement that. Angela please go ahead. Yeah, so I think we're. You know one of the things that I was brought into work on is like evaluating the model performance. I think we're continuing to like think of how to improve the like yeah the models. Sorry. To improve the model like whether that means experimenting with different retriever strategies or you know of course when we're like chunking and indexing the documents. I think we're finding that there's some issues that arise from that. So it's a lot of like so I find the work like pretty pretty interesting. I think you really probably have the best visibility into like what kind of stuff you might be expected to take on but at least not my end was the kinds of things I'm focusing on. Thanks. Thanks for it to me. I totally agree. I am pretty excited about large and large models as a sort of the beginning for I mean I'm a computer science by my major is computer science. So for computer science people who I believe like not learning large into model was a big context change and good and bad steps are coming. I just like make sure I'm giving up it. Well, so okay, you're even overview about the project. Initial steps. Yeah, that's I'm wondering about the next steps actually what should I expect about next more interviews or. So the process. Just I think the next step is I think it will be taught to you and and from there. Giri or somebody from which I will reach out to you and that that's kind of general next step Angela Mike or some if you have any more details about that part please. I just got pulled in the last minute. I don't have all I know is like yeah Leo is being into your for you know of this positions in our project. Yeah, go ahead Angela. I'm sorry I was just going to ask it are you working with Kelly Mitchell. Not right now but I'm a bit familiar with it. Are you sure I was like the recruiting firm the staffing firm I was just curious if the staffing firm that is. Oh sorry I think about the technology. But yeah yeah I'm working because I was trying to remember calls the last the less company was a different one but for this one yeah. Okay I think you really get back to you yeah. Okay so I'm just going to answer yeah yeah. Yeah I feel at least was Kelly Mitchell they gave me a phone call and told me what was happening but yeah it's. Definitely very depending on your own stuff. So give me a different meeting he'll get back to you the end of the day or something like always up to we can always update. Probably. Yeah sounds good to end up. That's a good summary is mostly communication will be through the staffing company that. You're working with and you're going to reach out to you and probably they'll follow up with us but the official communication that's done is going to be through the staffing company. Yeah I don't know if maybe you're working with Lexi who's really great but yeah they just kept me posted on the entire process so. If you can do anything in this way just let know. Yeah sure sure I think that if there are no questions from the team and if there are no questions from Leo. Leo you have any questions anymore questions for us or now that's all I want to sign. We still have few minutes allocated for this so if you have more questions please do so or else we will bring this interview to an end. It's up to you. And I'm done. Thank you. Okay can I see thumbs up from everybody else to before you kind of. Plus good good perfect perfect.", "start_char_idx": 44527, "end_char_idx": 48622, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "515f688d-285e-4c4f-8ebe-0101e4359e91": {"__data__": {"id_": "515f688d-285e-4c4f-8ebe-0101e4359e91", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aaaaa1fa-96e5-420e-bba2-b393db5fb1e2", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "172102b6dc14bc5478f16e54716a50f1f071cc3fde5e5e2919e48a2c9af86100", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6884e192-d11c-4083-9bb2-8197cec674c0", "node_type": "1", "metadata": {}, "hash": "d4b409fea1b623e5247de5bbd81c87a469a0a794aebe77300a026beee76ee476", "class_name": "RelatedNodeInfo"}}, "text": "You're working with and you're going to reach out to you and probably they'll follow up with us but the official communication that's done is going to be through the staffing company. Yeah I don't know if maybe you're working with Lexi who's really great but yeah they just kept me posted on the entire process so. If you can do anything in this way just let know. Yeah sure sure I think that if there are no questions from the team and if there are no questions from Leo. Leo you have any questions anymore questions for us or now that's all I want to sign. We still have few minutes allocated for this so if you have more questions please do so or else we will bring this interview to an end. It's up to you. And I'm done. Thank you. Okay can I see thumbs up from everybody else to before you kind of. Plus good good perfect perfect. Okay thank you so much for attending and and Leo it was a it was a pleasure to see you go through your stuff and it is a. This first time I've been in interview with in something it PPT there is actually kind of code being shown that is very nice and and you did very well in your coding tests. Thank you very much. To be honest I was pretty nervous at the beginning because no buyer is a company I have tried to line before and of course I got not success and now I got it. I got it for to take in and I was pretty nervous but you guys make me totally comfortable so I really appreciate it. Yeah thank you so much for coming in and doing this detailed presentation and with that I will also thank Angela, Somia and Mike for participating and with that I'll close the. Thank you so much. Thank you all the best. Thank you. Bye bye. I think I think I think you might be getting an offer soon. That's not bad. I love the fact that the PhD in I don't know what is it the information retrieval or whatever was so terrified of asking a question about it because. Oh about Twitter yeah. The Asian lady. Angela she was terrified of asking you any any more because because it would show the rest of the group that she didn't know as much as you. You should just join right this month. Yes yes so. Yeah that's a successful interview. I was a little terrified because you were putting too many things at the same time but but the good news is that you have the old guy who love the you know the all of the Linux stuff. Yeah and all of that stuff and that was that was great but yeah and now that was that was pretty cool. Yeah so Mauricio you should be getting something man like yesterday. I think the one thing we have to be careful with in the future is I think the first time we spoke I thought we didn't we we meet with we met with joy joy tea. And I think you did mention that you were still working at MGM so so we got to be careful with with that the policies usually is that you're still there but you have finished your contract and you're just working on documentation and stuff like that. That's the usual thing to say because it's it's really weird people are shitty and if you're if you don't have a job there it's harder for them to give you one that if you're working with somebody else it's crazy you know what it looks like it's like when ladies. You're married. Oh when you're married. I know. I know. Interesting. Yeah it's like well you know why is he single what's wrong with it. Same thing same thing you're right if if you're at the position you you are you know okay oh we're we're poaching him we're we're getting him we're head hunting him from from that. I really liked I really liked the knowledge graph visualization which is not necessary right you don't need to have another out another out that is that is just. It's impressive. So many connections. Yeah other connections and other things and and I can immediately tell you why I think that knowledge graph is less. That's capable of an vector databases because the connections have to be made right by you by somebody at some point they have to be built and and basically the the vector database you build on the spot with a button in two minutes. Yeah four lines. Yeah four lines and and I think that's the that's the big advantage and that's why I think slowly knowledge graphs are going to go away and even though everybody's trying everybody's trying to to keep the focus right.", "start_char_idx": 47787, "end_char_idx": 52080, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6884e192-d11c-4083-9bb2-8197cec674c0": {"__data__": {"id_": "6884e192-d11c-4083-9bb2-8197cec674c0", "embedding": null, "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d3521eae-158d-4899-908d-b76c2e23d824", "node_type": "4", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "b32ddac7db55e3cade9f9627ffe18eed5c0e8ca9938e81a74d88765fd51852f3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "515f688d-285e-4c4f-8ebe-0101e4359e91", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "8ea4d2036830eff56f784a6f0f766e3823fba7335c185470823ef78dca479482", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3b816b2d-c0e3-406d-aec4-1277060569d2", "node_type": "1", "metadata": {}, "hash": "4f149e25d1d07a3d7f6351fc466e54cac232428ddab07b1c825d736c2ca395ce", "class_name": "RelatedNodeInfo"}}, "text": "I really liked I really liked the knowledge graph visualization which is not necessary right you don't need to have another out another out that is that is just. It's impressive. So many connections. Yeah other connections and other things and and I can immediately tell you why I think that knowledge graph is less. That's capable of an vector databases because the connections have to be made right by you by somebody at some point they have to be built and and basically the the vector database you build on the spot with a button in two minutes. Yeah four lines. Yeah four lines and and I think that's the that's the big advantage and that's why I think slowly knowledge graphs are going to go away and even though everybody's trying everybody's trying to to keep the focus right. So so Neo4j has a vector database like thing that they can connect you and this other but you know. Another thing that's that's interesting is that that little notebook that you have there. With some things that are not super necessary I like to put it into a pandas data frame because I think in pandas and if I don't have if my if my data is not in a pandas data frame, my don't understand the data. But but those steps are basically the same throughout you have to get the data in somehow well there's a PDF or something you have to split it and then you have to you have to upload it and then and then query it but yeah no that was cool. I'm sure I'm late to something because this has taken a long time. I'm hearing the hat. Yeah, I don't know what it is. It's the least one I had so far. I think I think it was meant to be shorter but I think they were enjoying it. Yeah, me too to be honest. I think they were like wow look it answers questions and Angela's like that's what we're trying to build right there that one that thing we need that. I wanted you to have them ask questions about the agriculture thing but yeah that was pretty good. All right, I'm going to shut up big thumbs up from me Mauricio. I would be very surprised if you don't get a call tonight. Like right now. I can hear your Mauricio. I can at least. Sorry sorry for that guys I was muted. I'm writing actually right now to the vendor. BFX message and she's asking me how they did when I'm going to put all this information but actually I have bond with this specific vendor and she's always aware so she will let me know ASAP. And as soon as I have everything I will let you know guys but everything was awesome. Yeah, no I think I think this is there's no doubt in my mind. So I think interesting I never heard before they they were concerned about the vendor. Oh which one is it? Right well I think it's Angela right Angela had her like her company and then she thought that you were with them. So immediately that tells me that she's like trying to establish like a relationship with you in that sense. So that leads me to think that she also believes that you're getting an offer. Oh that's good. I really like being. I really like the where you're working with hopefully in Bayer. That was good. A little risky but. Okay. Yeah it's like it's like like if you meet up again a lady in the bar and you're like what are you doing later? What are you doing tomorrow and it's like hopefully breakfast with you. Oh my. Look at the hand. These guys. All right. Paul, this is talking to somebody. Yeah actually I was having a word with Arturo. I was having a word with Arturo. And he was asking about the interview and then just let him know that everything.", "start_char_idx": 51296, "end_char_idx": 54815, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3b816b2d-c0e3-406d-aec4-1277060569d2": {"__data__": {"id_": "3b816b2d-c0e3-406d-aec4-1277060569d2", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0a11490-68e9-4b07-bef5-27c31af27966", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "201eb0e77e152c65a2f5938f019514eb7a658ded7fd7816c4acc0b3f2f642324", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6884e192-d11c-4083-9bb2-8197cec674c0", "node_type": "1", "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "5a23bcbcac5e7de52bc4c50af609c52b47e4cb7c1d8b7b6bf2673904a173a60a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "30c0a70d-19b1-43cb-b9b0-441ae2ad8a25", "node_type": "1", "metadata": {}, "hash": "98827689e9668bcb2bcda5337278a4b310047816bf986dec566dc86fb6ef2d10", "class_name": "RelatedNodeInfo"}}, "text": "1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5% 1.5%, 1.5% 1.5%. 1.5% 1.5%. Merely, lemme see, the most tedious cleaning job I've done has been healthcare data to clean it. So that has been the most tedious, but in terms of feature engineering, feature, and everything, I had this project that I worked with Jeffrey Finer. It was so difficult in terms of joining data from various sources and trying to leverage the different features, create new features because it was so sketchy and stuff like that. That was also a challenging one that time because... Gotcha. Yeah. So it looks like you've worked in multiple fields too, right? So healthcare, finance, and which other domains have you worked with? Yeah, mostly the both of them have healthcare and finance. That has been... Gotcha. Okay, so let's come to the large language models, right? So that's the current trend right now and that's where GNI and large language models. So what's your experience in this domain? What have you worked on so far? This is... I think so far this has been one of my most at my add domains, especially as a domain that is very pretty new and everybody was learning when I go to a big forest to build a textualization UI. We use frameworks that we pretty new like LANG chain. We use foundational models like Flanck T5 and stuff like that. Which model? Yeah, we use Flanck T5 from Hogan phase. Okay, got you. Yeah, and all the computational challenges we had to select the right machine, T4 machine, Philia machines and stuff like that. The issues. Yeah, so our overall job and also working with the QA department to be able to collect label data set in this project because we needed data set that were human labeled. And that's what actually took us a lot of time because these department had to be able to do it and save it for us. And every time the QA, a particular clinical node that came in like a nurse sense in their notes because these guys have hundreds of clinical notes coming weekly and they have to kill the notes, QA, the notes and pay this clinicians and also build these notes that coming from nurses, doctors and other clinic clinicians. We had to work with them, try to work with them to get this label that I said humanly labels like from their own perspective. And when they gave it to us, we had to clean it. We use a seismic and notebook and precisely they used the save this data on S3 using cloud formation and they have a whole architecture that we could have access to it, in our department and we had to remove using beautiful soup. We had to remove some HTML if they were present and using rejects, remove non-textured data that were present using NLP, NLTK library to remove all of these stopwares, non like data from it. The cleaning process was really very difficult putting it right and then now we had to use the models that we used using Hanging face embedding. We used Hanging face embedding.", "start_char_idx": 1, "end_char_idx": 3201, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "30c0a70d-19b1-43cb-b9b0-441ae2ad8a25": {"__data__": {"id_": "30c0a70d-19b1-43cb-b9b0-441ae2ad8a25", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0a11490-68e9-4b07-bef5-27c31af27966", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "201eb0e77e152c65a2f5938f019514eb7a658ded7fd7816c4acc0b3f2f642324", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3b816b2d-c0e3-406d-aec4-1277060569d2", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "8a5c78f4562d36e8420ea1819c23241abe5c85d5b02c4ca334f6e0d92be16669", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a328c706-20f5-4c35-99e8-efef138fe040", "node_type": "1", "metadata": {}, "hash": "83d4b8d7cf9a4c9b9ca156a810e57d9c744483f28bd8359119f3a08fec7bbd32", "class_name": "RelatedNodeInfo"}}, "text": "We had to work with them, try to work with them to get this label that I said humanly labels like from their own perspective. And when they gave it to us, we had to clean it. We use a seismic and notebook and precisely they used the save this data on S3 using cloud formation and they have a whole architecture that we could have access to it, in our department and we had to remove using beautiful soup. We had to remove some HTML if they were present and using rejects, remove non-textured data that were present using NLP, NLTK library to remove all of these stopwares, non like data from it. The cleaning process was really very difficult putting it right and then now we had to use the models that we used using Hanging face embedding. We used Hanging face embedding. Not now that while we were doing some POCs using these new technologies like even OpenAI came in open and embedding was way better and faster. So when we did them embedding, then we then now fine tune our model and then we also had a lot of challenges. You know, he passed off like that security and everything we had to make sure everything was right. What kind of practice were you enforcing before hand to make ensure safety, security, things like this? Yeah, you know, everything that works in ABIC is in accordance to HIPAA, like right from the handling of the data, the level of the QA department, the respect or HIPAA regulation, and ensure personal identifiable information we're hitting from like diagnoses we use codes ICD10 and stuff like that. And all of the most essential information we try to capture semantics of the most important information that we could get from the clinical notes that were submitted by the NERSD to make sure the NERSD actually did the right thing. And to make sure the NERSD actually went and saw the patient because sometimes NERSD can bring notes that don't match up to the standards and stuff like that. So all of these ethics, even at the level of ethics and everything we respected and yeah. So when they push it down to S3, you know, there we only have access to a single key security logins that are going to be to our department. And so it's generated once when we want to assess it in terms of privacy. So the whole architecture was there using automated using cloud formation and stuff and then. So how is it compared to the so you I know you're working with the healthcare data right now with the NERSD notes and out. But before that when you are working with financial projects, what kind of measures are you taking? Yeah, with Jeffery finance, one of the things that we do at the because it's a large department is the equity research department. We used to we work with derivatives that is we were modeling the volatility right so we stock data is available for the company. So we usually get the OHLC that is open high low and closing of the stock from which these are these are pretty open source data like you can get it from your finance. You can get it from any stock data this and they were not too sensitive, but security is always very essential in terms of who has access to the data at what time. And there were no buyers in terms of how we approached the data and they were finished. So when we have this data, we calculate what we call. The realized volatility using gaming class volatility is a kind of function, a magic function that takes us parameter the open high. Close and start of the of the stock. Yeah, so we calculate this volatility and we then model it is a time series data volatility and time because volatility is price changing over time so change of price with time. Then now we use a REMA we can now get what we call if forecasted volatility or predicted volatility which helps the company to mitigate risk whenever they want to make some kind of investment some kind of trades and stuff like that that has to be done at the level of the equity research department. Those were the kind of things we were doing the we were more than this kind of data and stuff like that. Let's switch back to language models so you mentioned Lama right you said Lama not Lama. Langshane. Langshane. Oh yeah, Langshane. So what do you what is Langshane and what's it used for and how much how much are you from there with it Langshane and Lama index? I mean Langshane I'm very familiar with it right now because it's pretty what I've been working with so Langshane is a framework that helps you to change.", "start_char_idx": 2429, "end_char_idx": 6874, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a328c706-20f5-4c35-99e8-efef138fe040": {"__data__": {"id_": "a328c706-20f5-4c35-99e8-efef138fe040", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0a11490-68e9-4b07-bef5-27c31af27966", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "201eb0e77e152c65a2f5938f019514eb7a658ded7fd7816c4acc0b3f2f642324", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "30c0a70d-19b1-43cb-b9b0-441ae2ad8a25", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "e763720621c48a82524c9c14426263aafe76a839dec60d53f8b4c479465cc8e5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c1f389d1-2523-4f14-ba4e-de2bbb19a7dd", "node_type": "1", "metadata": {}, "hash": "0b71bd3e357c7f294eafe63d46ea5f323ef34fea0a34e9e45ef00379f768e142", "class_name": "RelatedNodeInfo"}}, "text": "Then now we use a REMA we can now get what we call if forecasted volatility or predicted volatility which helps the company to mitigate risk whenever they want to make some kind of investment some kind of trades and stuff like that that has to be done at the level of the equity research department. Those were the kind of things we were doing the we were more than this kind of data and stuff like that. Let's switch back to language models so you mentioned Lama right you said Lama not Lama. Langshane. Langshane. Oh yeah, Langshane. So what do you what is Langshane and what's it used for and how much how much are you from there with it Langshane and Lama index? I mean Langshane I'm very familiar with it right now because it's pretty what I've been working with so Langshane is a framework that helps you to change. LLM with prompts and template so and it makes connections with several different LLM's like you can connect it with it has connectivity with different foundational models from different sources like you have bedrock like we just mentioned bedrock. It has an API that you can connect with Langshane you have as your opponent you have a vertex AI in the GCP you have a whole gain phase you have a opponent itself so this framework you can get access to this different foundational models depending on the project you are working with so why we were working with flanks if I is is the less a general purpose model and encoder decoder model so using this we connected it and we also use the hogging phase embedded in Langshane because from Langshane dot LLM's you can import these models from these frameworks and using Langshane embeddings you can import hogging phase or maybe open AI embeddings and stuff like that so this framework also helps you to connect to different databases you can make your your LLM more intelligent like that's why they are used to make a model more customized you can either use a supervised approach which is fine tuning or you can use what we call retrieval or minted generation that is rack so in the in the rack that we used because rack is mostly using in the framework we wanted to build something like a chat board and stuff like that that we have some proprietary documents we chop them down into chunks and then chunks size and then we embed them because you have to convert them to numerical values yep and then also the problem we have two we have two stuff that we are doing so the rack is mostly used when we want to have access to proprietary documents like a chat board but the textualization UI is supervised approach that was done there using label data set to fine tune the model so yeah okay so what kind of bench so what kind of benchmarks are you using are you planning to use things like that to evaluate your model's efficiency yeah so the best benchmark that we used was human evaluation or human evaluators does the best I mean it's one of the most appreciated now in the market even though we used the stuff like blue, blue, rouge but those are also good but the human approach was because when we were done the QA department or reviewed the result the outcome that came from the evaluation and the squad eat and this on it the Rouge score was also good but sometimes it can be because if we talk about these Rouge metrics like in like N grams it can measure the similarity between the results from the the summarize result from the model to those from the human perspective because you still have to compare them before it gives the percentage of how good the model is or not but sometimes the similarity or the same words that matches might not actually bring out the best sense in what we are looking for in the summary so that's why human eye has to go there and try to see if we can do it and try to see if the model is actually making sense so we we used all of these metrics in terms of how we were trained that's good so you have pretty much familiar with python then since you used language and so it's python your main program language yeah python is my main language followed by scala and yeah scala as well okay gosh then it comes to lambda implementation so do you know what do you understand do you have any experience dealing with AWS lambda?", "start_char_idx": 6053, "end_char_idx": 10285, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c1f389d1-2523-4f14-ba4e-de2bbb19a7dd": {"__data__": {"id_": "c1f389d1-2523-4f14-ba4e-de2bbb19a7dd", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0a11490-68e9-4b07-bef5-27c31af27966", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "201eb0e77e152c65a2f5938f019514eb7a658ded7fd7816c4acc0b3f2f642324", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a328c706-20f5-4c35-99e8-efef138fe040", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "6513d7ae09b29a387682356f86eb7465f0a27dd482ae58054f47f4482a1f8ec4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c532364-1169-4cb1-95a0-250c43940657", "node_type": "1", "metadata": {}, "hash": "348cb508ad34c6c1176d9f50b217123125135302b5d317e69518c3a6cb80bf91", "class_name": "RelatedNodeInfo"}}, "text": "yes yeah it's gonna explain what it is yeah so lambda is used to orchestrate let's see we are building a code so lambda you can it has issues for automation you cannot to meet the whole process it's a code it's a code as a service so it's a fully managed code as a service that is used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used to be used foraly applications 3, you import Boto 3, and then when you use Boto 3, you can view a Boto client with Betrock, for example, Betrock API, if you have selected the model. So, it betrock run time to be precise, maybe I might have you. So, we build a Bot, betrock run time. And from which, if we are using, for example, AWS Gateway, we can prompt it at the Gateway and then on Lambda. So Lambda, we can write all the functions and from the client, we can define the prompt that from the prompt using API Gateway, whenever the user has write something at the prompt, when we customize the prompt, it would trigger the Lambda function, which would send a message to the LLM either in Betrock, we can use maybe AI21 or maybe co-hair depending on the task that we are working on or Titan. So, it would trigger an API call to the model and the model would perform the task. Let's say we are performing image. So, the Lambda ought to miss the whole process for you and it helps you to define the whole task. And there is an extensive documentation in Lambda, AWS that depending on the task, the run time, the client that you want to create, maybe connecting with S3, you have to create another client connecting with Betrock, connecting with SageMaker, all of them. So Lambda can give you a whole automated process that can trigger various tasks and make your work easy to do. Yeah. That's right. So, let's see. So, what are the benefits and limitations do you see from the Lambda, AWS Lambda point of view? What kind of value do you see? It's good and very fast. What do I see? It's good. I mean, it's good in terms of the fact that it can make the process real-time seamless. If I use that term, it can make it. And the inconvenience that I can see, Lambda has, I think if, let's say we are working out of AWS, let's say we are working in, we have a dead party like snowflake. I don't know how compatible it is with all dead party vendors. I think it might be limited in terms of compatibility. And also execution time, Lambda doesn't have some kind of distributed kind of computing that maybe can be that fast. Because it's serverless. Because it's serverless and no management is that, is it? Yeah. Yeah. Yeah. So, for a chart based application, for another, if you are using a chart based interface and application, do you think that's a good idea to utilize Lambda or no? It depends. After what extent? Yeah. That's a good one to what extent. Because it depends on the amount of users that are accessing your application that would depend because at the level of API is, let's say we have an application that we have one, the users or less, we might go for it. Or if it's maybe a batch kind of process that we collect and whenever this body fits in the real-time deployment environment that the users are really high, we might maybe go for something different. It depends on the workload. Yeah. That's good. Let's close it as specifically with AWS Lambda and things like that with one question. How would you ensure the security in terms of especially when dealing with Lambda functions that are interacting with sensitive information in ML use cases?", "start_char_idx": 10286, "end_char_idx": 14337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9c532364-1169-4cb1-95a0-250c43940657": {"__data__": {"id_": "9c532364-1169-4cb1-95a0-250c43940657", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0a11490-68e9-4b07-bef5-27c31af27966", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "201eb0e77e152c65a2f5938f019514eb7a658ded7fd7816c4acc0b3f2f642324", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1f389d1-2523-4f14-ba4e-de2bbb19a7dd", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "134403d9093335740011a98ae4608b47fea3e95c0577f26acced89ed49c19253", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f7d35226-315e-4002-bb1f-13dec45cc83c", "node_type": "1", "metadata": {}, "hash": "1b6ad0a1573106712c54b31383f5abc72c044f856e0b718c545404419353c3d6", "class_name": "RelatedNodeInfo"}}, "text": "It depends. After what extent? Yeah. That's a good one to what extent. Because it depends on the amount of users that are accessing your application that would depend because at the level of API is, let's say we have an application that we have one, the users or less, we might go for it. Or if it's maybe a batch kind of process that we collect and whenever this body fits in the real-time deployment environment that the users are really high, we might maybe go for something different. It depends on the workload. Yeah. That's good. Let's close it as specifically with AWS Lambda and things like that with one question. How would you ensure the security in terms of especially when dealing with Lambda functions that are interacting with sensitive information in ML use cases? So, AWS is a fully managed platform, as we said. The IAM rules are very important. It has policies and everything. So, when you are configuring the IAM in Lambda, Lambda when you go to configuration security, you would put the policies and you would specify the security, the how you want, who can access it and when can it be access and everything. You can define the policy based on the rules. So, let's say I have a main role. I can give it full access if you if you because in in in a typical production environment, every department has their their roles and so you can block access to data engineers and give access just to data science in the roles that you assign on the Lambda and whenever they make that call that. The IAM is very important and also in terms of network security, you can also do that. You can maybe use eventual private cloud and stuff like that and there is also possibility for encryption if it's in terms of data and other. Yeah. So, do you have experience dealing with the AWS Lambda for Lambda service in fine tuning models and all that is a different. You're using that in your current scenario basically. Yeah, we built a POC as I mentioned that we use AWS gateway, Lambda and bedrock. These are pretty new stores, especially bedrock, pretty new. Yeah, so it was a POC and based on it, we were able to use it. So, that's why I did it. Gotcha. So, you're familiar with GitHub? Yeah, that's not bad. That's a basic. We didn't breathe and forget. Yeah, I mean, yeah, well, if you use it is you would have some some pre-knowledge for vision control as to if you commit you, yeah, so like that. Yeah, but as much as they learn about Git, we keep forgetting whatever we learned yesterday. You got to keep on looking for it. So, coming to the vector databases, are you guys using vector databases or knowledge drafts, anything like that in your current POC? No. Do you have any experience here? Yeah, I walk vector databases. Yeah, we did as I mentioned before when we have to do with proprietary documents as I mentioned, yeah, we have to push it with vector database after embedding. After embedding. Yeah, and then we index it. Vector database like Pinecon. So, like that, that the one we use face, chroma, you have orders. Yeah, so when you index it, it uses what we call similarity search or, yeah, you also use semantic search from the database that is index and then, yeah, it's good for building chat boards. I mean, in this new age that we are, everybody is looking forward to incorporate chat boards in their businesses because the cost of calls and everything, why not just go for a chat board that you will just have one AI that is giving you all the results rather than recuting 50 people to be taking random calls from people, yeah. Right, right, that wave as it is going. Yeah, so everyone wants to be part of it. Yeah, new technologies, but we are keeping up with it because it's changing the world right now. Yeah. And the next, so what kind of deep learning framework set you familiar with what you have, what frameworks we have experienced dealing with in terms of, do you have experience in deep learning models and all? No, I do. So I've worked with RNN and LSTN, LSTN when I was working with Jeffries. As I mentioned that we're working with some time series data. Yeah, right, when stores get too complicated, so I'm familiar with Keras, by touch. And I mean, TensorFlow now is also incorporated with Keras. So yeah, one final question.", "start_char_idx": 13558, "end_char_idx": 17823, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f7d35226-315e-4002-bb1f-13dec45cc83c": {"__data__": {"id_": "f7d35226-315e-4002-bb1f-13dec45cc83c", "embedding": null, "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0a11490-68e9-4b07-bef5-27c31af27966", "node_type": "4", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "201eb0e77e152c65a2f5938f019514eb7a658ded7fd7816c4acc0b3f2f642324", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c532364-1169-4cb1-95a0-250c43940657", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "c30584d977571a57917741bd23c169dbecebc96b082ce50749b270e8aac54e53", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73520d45-75e0-4df5-99c8-978dac8f7c3d", "node_type": "1", "metadata": {}, "hash": "637a3b2c465b286024116cdffe6bb61bb47a60703191839977060acc3aff055f", "class_name": "RelatedNodeInfo"}}, "text": "Right, right, that wave as it is going. Yeah, so everyone wants to be part of it. Yeah, new technologies, but we are keeping up with it because it's changing the world right now. Yeah. And the next, so what kind of deep learning framework set you familiar with what you have, what frameworks we have experienced dealing with in terms of, do you have experience in deep learning models and all? No, I do. So I've worked with RNN and LSTN, LSTN when I was working with Jeffries. As I mentioned that we're working with some time series data. Yeah, right, when stores get too complicated, so I'm familiar with Keras, by touch. And I mean, TensorFlow now is also incorporated with Keras. So yeah, one final question. And you'll close that up. What is the what does it mean bias and variance trade off to you and how do you handle that? Yes. Can you repeat that please one more time? Bias and variance in machine learning, general principles, fundamentals of machine learning, bias variance trade off and how do you think we can handle that? Yeah. So bias basically is measures how closely the average predictions of the models matches to the true value. So and variance we talk about variability of the model predictions across maybe different data sets, so we start talking about maybe the distribution of the model. Right. So how will you handle that in practice when there is a there is either too much bias, too much variance, how will you handle that? So the overall objective in machine learning is to have it as low as possible like low but right. Yeah, but in an ideal scenario, it's you can never achieve that. Yeah, yeah. Especially since you're going to be fine tuning models, you fine tuning models are all they want. So how do you maintain that in the models that you're fine tuning? Yeah. So several techniques have been used in tradition, I mentioned learning like we can use regular regularization technique. Yeah. Yeah. You can use your cross validation and stuff like that. Yeah. As simple modeling like in models like decision tree that have high, we can use some assemble models that random for it instead of boosting models that can. Yeah. I mean, at the low level, we can use the future engineering kind of stores and yeah, that's good. Yeah. Well, that's all the questions. That's all the time we have. Yeah. Just like you have a lot of experience. So I wish you good luck with the next steps if they decide to move forward. Yeah. All right. Thank you. I think they'll let you know. Yeah. Thank you for your time and you'll hear from Suda. Yeah. Thank you. Thank you. Thank you. Good luck. Good luck. Thank you, too. Yeah. Bye. Bye. Okay. Okay. Lauren. Good job. Is it Suda? He said we are in Suda. Okay. I think he was good. Yeah. That's what I feel. Yes. Let's ask Ignacio. He was from the call, I guess. Yeah. Yeah. I'm right here. Yeah. So he said we'll hear back from Suda. I don't know when, but yeah, he's the one who takes care of it. Yeah. I mean, at the beginning, it was going to be a video screen call with the manager, but they really, they really like your profile. So they decided to go for a technical call. So it means that they're really into you and I believe that they never went well. So yeah, let's move forward with the second position. For second round, hopefully it's going to be a final, but I'll ask before I let you know if this is going to be a final. Anyway, I'm going to send a thank you email right now to those. Okay. All right. Thanks. Thanks. I'm appreciate that guys. Yeah. Now good job. Yeah. Yeah. Good job. Bye. Bye. Thank you. Thank you.", "start_char_idx": 17112, "end_char_idx": 20707, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73520d45-75e0-4df5-99c8-978dac8f7c3d": {"__data__": {"id_": "73520d45-75e0-4df5-99c8-978dac8f7c3d", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f7d35226-315e-4002-bb1f-13dec45cc83c", "node_type": "1", "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "764727c41adbbdb6b85a801244f2ec25688d5114758fe35e1a5a6cbdcdc93a30", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b3465798-fdf5-453a-9ad7-59078f90ef24", "node_type": "1", "metadata": {}, "hash": "122fdbc267716cd99d6b8ee3f16fc97b2cf49a021342e6161a2e004996597c85", "class_name": "RelatedNodeInfo"}}, "text": "Where are you based, Lauren? Right now, I'm in DC. DC? Oh, you're in DC, okay. That's where you live or you are there because of your work. That's where I live. Oh, okay. I guess it's nine o'clock, so let's get started. You know, so probably one or two persons may join in. I'm present at even Radoo, right? You know, I'm based in Dallas. I'm kind of interviewing on behalf of Cerebra for the contract position with Vanguard. Right? So I'm not associated with Vanguard, but I'm kind of helping screen the candidates and the position for Vanguard. Okay. Okay. So is this like the final round or is does it? No, there will be this is the initial round, if you will, right? You know, there will be interview from Vanguard. Okay. Okay. So I'm sure you would have seen the requirements. So, before we get started, we'll just wanted to hear from you, let's yourself water your interest, what motivates you? Yeah, my name is Loudin. I'm a senior diversenities. Yeah, right now my area of interest is LLMs and Jenny. I mean, it's taking over the world right now and everybody is really focused. So I'm really in active research in that area trying to dig more and try to get more. My most recent project with Abik, we're actually working on generative AI LLMs. We help them to build a text summarization UI. And this helped the company with the quality assurance department, which had manual jobs being done at the moment. They had to screen clinical notes manually. So we helped them to facilitate this process using LLMs. So in my prior projects, I was working with Jeffrey Finans with the equity research department. We were mostly focused with time series and using some derivatives and stock data for the company. We used Arima, LSTM and some other manmatica functions to be able to capture market risk. I've also worked with supply chain management where we had to do some predictive analysis. I am using random forest models and its exhibits here we use its tables. And yeah, so globally I've worked in both deployment, ML labs and also some data engineering jobs. I really have a wide experience across various areas. I think that looking at the current job description, which ties exactly with my area of research, I think I'm going to be of great value to this project and giving my best to make sure everything works well. Thank you. So you know, this specific requirement on pollution requires experiencing large language models. And you said you are currently doing research and helping Abek to do the text summarization and other things. So that's good. What kind of models that you have used are you using for Abek? In Abek, back we used Flanck T5 from Hoganface. And then Koda, the Koda model. So we part of the job, which was really tedious. It was really tough. It was first to have labelled data sets from the company QA department, which was human labelled. That was what took us a lot of time because we had to fine tune the model, fine tuning that is customizing. And now we have the concept of micro or small language models that you have to use some supervised approach. So we did that and we deployed the model using stream lid for batch inferencing. So they can just put in the text and then get a summary. And yeah, so it was pretty difficult task, especially since the technology, the programmatic assets of the model and everything. But the body was still in the face of developing and understanding everything with lime chain. Things were just happening. So we had to be able to integrate everything and use it for the advantage of the business and looking at what we were able to achieve using what we put in place. The company, QA department had to invest less in terms of the difficulties they had with human resource and they could be able to do the job 10 times faster than what they were doing prior to all of those complications. And they, I mean, they are impressed and everything went well, but my contract just ended. So that's why I am now open in the market and try to look for the next opportunity still in this light of of Gen AI, which I saw this one and it's really interesting. So you picked up a plantify. Okay, so what made through the process right from you know the problem definition, right?", "start_char_idx": 1, "end_char_idx": 4236, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b3465798-fdf5-453a-9ad7-59078f90ef24": {"__data__": {"id_": "b3465798-fdf5-453a-9ad7-59078f90ef24", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73520d45-75e0-4df5-99c8-978dac8f7c3d", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "8ff1d2ef4620854c25f221e21881e753fde856ae4aa1243ce29c9330811e0440", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ed7e79d-79d2-4535-82c9-9c9d255c10f8", "node_type": "1", "metadata": {}, "hash": "f008b284ce7c5b755180942168768980d95f353a697da0f5743117b769a0795a", "class_name": "RelatedNodeInfo"}}, "text": "But the body was still in the face of developing and understanding everything with lime chain. Things were just happening. So we had to be able to integrate everything and use it for the advantage of the business and looking at what we were able to achieve using what we put in place. The company, QA department had to invest less in terms of the difficulties they had with human resource and they could be able to do the job 10 times faster than what they were doing prior to all of those complications. And they, I mean, they are impressed and everything went well, but my contract just ended. So that's why I am now open in the market and try to look for the next opportunity still in this light of of Gen AI, which I saw this one and it's really interesting. So you picked up a plantify. Okay, so what made through the process right from you know the problem definition, right? So you, you, this is a lot of manual effort goes into you know summarizing the clinical reports and other things. That's the problem statement. So from there, how did you arrive at the solution? What kind of methodology that you used? How did you pick up a model? What kind of tools and frameworks that you picked up and how did you go about doing that? And the process of from there to actually generating the solution, buck me through the steps. Yeah, so when I got to a big what they were doing with that when the clinical notes because they have nurses, doctors and clinicians in the field. We do send clinical notes on daily basis and so when this notes coming, we have some clinicians in the office. We call them Q a is the Q a department quality assurance department. We have to review these notes and then Q a it validated it before the notes can be paid. That is a can be built and the clinicians can be paid. So now what we did was that this work was done manually. They had to go through thousands of pages. So what we did first of all we use. We were working with the quality assurance department because that was the first part to get a label data set. And so pre-train models already exist in Hogan phase open AI. The reason why we choose Hogan phase is it's open source nature and it was really cost effective rather than using GPT 3.5 which existed at that time. And Hogan phase also has Hogan phase embedded which is free. I mean even though it's a little bit slow than GPT, then open AI embedded takes embedded embedded. So we choose Hogan phase which is flanked to 5. I mean at that time you know beginning of 2022 like that time Hogan phase was really still very good. Not now that GPT has gave a programmatic access and it's really pretty more efficient and stuff. So that is why we choose flanked C5 which was a very good general proposed model and Koda Dakota and it was really good for text summarization. At that time we had other options but that was the one that was really was really better and at that time also RAC was not yet a standard like retrieval of maintained generation. So it wasn't really a standard and many papers had not come out so the most efficient approach at that time was fine tuning like model fine tuning. That was what most of the research papers published at that time we're talking about and it was what everybody was looking at at that time. So we choose the flanked C5 model from Hogan phase we use Sashmaker in this project that was the cloud platform that we use because we could have access to a GPU machine that the T4 machine in Sashmaker and you know flanked C5 is trained on about 11 billion parameters if I got it correct. So we were able to to to fine tune the model on Sashmaker and it was a little bit cost effective than other than we had other models that had more trainingable parameters than than flank C5 like we had far gone. Yeah we had far gone far gone is trained on more parameters than than so it was more difficult to to fine tune that one but the result if you look at flank C5 when we when we fine tuned it it was pretty good and based on all the research people that we published for text summarization we we either could use. So flank C5 or we could use palm there is this Google model palm Facebook has lama I think lama to lama had came out that time so no palm was not yet out at that time it was yeah it was lama it was far gone so but the best bet was just bet at that time. The bet was mostly for classification and this kind of problem because it was mostly an encoder based kind of model.", "start_char_idx": 3355, "end_char_idx": 7816, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ed7e79d-79d2-4535-82c9-9c9d255c10f8": {"__data__": {"id_": "0ed7e79d-79d2-4535-82c9-9c9d255c10f8", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b3465798-fdf5-453a-9ad7-59078f90ef24", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "5df63e76d8df2574b143a290ee2888b6cc83a054646d89a70e7e230490d13742", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1d0e9dee-e671-4e2f-b85e-7532a209338e", "node_type": "1", "metadata": {}, "hash": "2ffa3d03ed46315ebf17724e8a291071fedeef46b79296f270771e4541bc42dc", "class_name": "RelatedNodeInfo"}}, "text": "Yeah we had far gone far gone is trained on more parameters than than so it was more difficult to to fine tune that one but the result if you look at flank C5 when we when we fine tuned it it was pretty good and based on all the research people that we published for text summarization we we either could use. So flank C5 or we could use palm there is this Google model palm Facebook has lama I think lama to lama had came out that time so no palm was not yet out at that time it was yeah it was lama it was far gone so but the best bet was just bet at that time. The bet was mostly for classification and this kind of problem because it was mostly an encoder based kind of model. So that is why among all the models that we had at our disposal at that time flank C5 was one of veterans on so many other parameters as I mentioned and so we went for it and then from Hogan phase we imported the model and then we went for it. And then we had to use months to have level data set so we we're working in collaboration with the quality assurance department team and so they had to give us the data from a human perspective because whenever they get the text the summarized it manually based on what they needed the essential things they needed for them to validate that one. The clinician actually saw the patient that was very important to the notes that the clinician produce that is the diagnosis the procedures that the clinician used to take care of the patient and to see the patient were right and we they had something called plan of care so we had to see a good plan of care and everything was good. So the gave us these summaries based on what the way concerned with in the the notes and from the road notes so we had the road note and the summary the road note and the summary and then we now loaded this data into session we can notebook. We clean the data we removed non textual data using rejects we remove if there were any HTML using beautiful so we removed using energy key library we cleaned the text we remove stop words remove everything and then tokenize it and then perform all the NLP tax then we use the Hogan phase and we can use the text. We removed the text and then we removed it and then fine tune the model in all the framework we used was extremely and lunch and lunch is the framework we use and from lunch and we could import all of these things and then make the API. The API was done using the stream lead so we could design a kind of UI and then the UI was then accessible by the the human evaluators because the methods we use for evaluation was the QA team that is domain experts they had to put in a road text and the results that were generated. We also used the rules and other evaluation methods in this project so when when we were done it was much appreciated the results were good and the so the problem at that time so now is to improve the model and try to upgrade it and maybe. You said you at the time you did hard drag so you decided to go fine tune it right so then varies the embedding coming into place and how is the language fitting into this. Yeah, lunch and helps you to make your model more intelligent so when lunch and it's a framework so when we are using stream lead and lunch and it helps us to add other intelligence in the model like. Because the overall objective of. Fintuning the model is to cost customize it so lunch and has a number of tools that can be incorporated like split us we you know some of these kind of things and. And load us and everything so these are frameworks that is the right right so you're splitting the text you're embedding it and you're loading it that is part of right pipeline yeah if you're not using. If you're just fine tuning yeah why would you use that yeah the process of fine tuning didn't that part the part of fine tuning where we had the level we loaded it using seismic we did everything didn't have. The right part the fine tuning itself was to it supervised approach that was done to make the model more intelligent but it's not just for rack the the launching is not just for for the right part it was to. It was to help us in the LL ops part of the model like incorporate other stores because in lunch and we also have what we call agents so we have other things that make the model more intelligent the prompting prompt engineering change so it makes the model that we can write the right from because. One of the most important part in this process is prompt engineering so prompting and getting it right was really better with this framework than just doing it like normally with without the framework so we had to. Make change and make it really right and the prompt passing the system from the user from and everything it was yeah.", "start_char_idx": 7136, "end_char_idx": 11881, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1d0e9dee-e671-4e2f-b85e-7532a209338e": {"__data__": {"id_": "1d0e9dee-e671-4e2f-b85e-7532a209338e", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ed7e79d-79d2-4535-82c9-9c9d255c10f8", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "21f73a7fa97590d62ef98b0620dca0b0bdc6b333a231b6c312e9d182d332308a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "be2efb2e-a841-4f8b-8237-700c352b16cd", "node_type": "1", "metadata": {}, "hash": "0e827ac692c65080686e907bb07fbd8c2066b54f2fbfee41dd12183a887b964e", "class_name": "RelatedNodeInfo"}}, "text": "The right part the fine tuning itself was to it supervised approach that was done to make the model more intelligent but it's not just for rack the the launching is not just for for the right part it was to. It was to help us in the LL ops part of the model like incorporate other stores because in lunch and we also have what we call agents so we have other things that make the model more intelligent the prompting prompt engineering change so it makes the model that we can write the right from because. One of the most important part in this process is prompt engineering so prompting and getting it right was really better with this framework than just doing it like normally with without the framework so we had to. Make change and make it really right and the prompt passing the system from the user from and everything it was yeah. How big was the data set for fine tuning and how many days you took for fine tuning the data says was really big because we. We would in order for us to have that right it took so it took us a lot of time it took us months and it was like a hundred K and. Yeah it took us since the machine was good decision because we use a theft parametri efficient fine tuning so it was the number of trainable parameters were less so it took us to cause how many days. Like to be to for the yeah something like that yeah so you said you used a L.T.K. for a lot of you know data cleansing light yeah yes we did so you're pretty good at an L.T.K. yeah I can say that. So natural language processing as well yeah natural language process what what is the difference between an L.P. and NLU NLP is natural language processing NLU natural language understanding yeah. What is the difference today we I mean understanding processing the what are the components of NLU NLP. So basically the components of NLP you have to when you have your data you have to clean the data the cleaning part of the data then which you remove stop words you remove non textual data you remove H.T.T.P. HTML links and stuff like that and then after that. You tokenize tokenize tokenization is vital and then after that you can perform limitization or stemming and then after that we do vectorization or embedding after the vectorization then we can now perform classification task or all the steps. And all the steps that you mentioned there are part of language processing right you know the three components of NLP or language understanding language generation and language processing what you said was part of language processing that is where NLP comes into play right. Language understanding is is nothing but that the energy part of it but all the three pieces are part of NLP language understanding generation and processing. Okay so you know you talked about stemming and limitation when do you use the stemming and when do you use limitation. Stemming you you capture the base word let's see we have root we talk about the root words which sometimes my nomics sense I mean even if it's not a dick a word that exists it will still just get the word example what can I use let's see. But the limitation finds a root word that has meaning a meaningful base word like running wrong running running wrong and maybe so it would have it would take wrong but stemming I'm trying to look for an example stemming. Stemming it can be a it can be three different whether the base word doesn't have a meaning but it will see ticket and then limitation also if you have some kind of way like good better best some different it would still give you a base word that is that takes care of all of these. Differenties like run run it will give you a base word like wrong but stemming will not stemming would stemming just try to capture it in a base word which even if it's not a meaningful word it captures it because it's a base word and so. Basically you're talking about cutting words versus cutting words with context right yeah perfect cutting word versus cutting word we call it. Yeah which one is more accurate. Limitization I prefer I mean it but but what is important what is important to note is that stemming is really easy and less compute and faster but limitation is more effective because it's so it depends on the project that you are doing if it's just like a simple project you would want to. Think about the competition and stuff yeah. How many types of text summarizations are there and can you talk about those. How many types of text summarization so there are two types. We have the two types we have this charity we have extractive yeah we have extractive and abstractive yeah so extractive it just extracts from basically extractive.", "start_char_idx": 11042, "end_char_idx": 15692, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "be2efb2e-a841-4f8b-8237-700c352b16cd": {"__data__": {"id_": "be2efb2e-a841-4f8b-8237-700c352b16cd", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1d0e9dee-e671-4e2f-b85e-7532a209338e", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "f62806f1d6329ffe7e4aaaf2fdcee9d22ecb5d87f634268a8f7492d24ec09e32", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cee31820-8605-471f-a1b3-753750992fd0", "node_type": "1", "metadata": {}, "hash": "72797fd294c0e679c26e5e475e82c771d175445ec3d59087b3a72b6a33aa86d8", "class_name": "RelatedNodeInfo"}}, "text": "Basically you're talking about cutting words versus cutting words with context right yeah perfect cutting word versus cutting word we call it. Yeah which one is more accurate. Limitization I prefer I mean it but but what is important what is important to note is that stemming is really easy and less compute and faster but limitation is more effective because it's so it depends on the project that you are doing if it's just like a simple project you would want to. Think about the competition and stuff yeah. How many types of text summarizations are there and can you talk about those. How many types of text summarization so there are two types. We have the two types we have this charity we have extractive yeah we have extractive and abstractive yeah so extractive it just extracts from basically extractive. It's from the text and gives you a summary extractive is more generative it brings it takes it from the text and creates you something that is better and more presentable so yeah extract from yeah so that does the difference between the. So which one you used for your project yeah so we used abstractive that is where LLM's come into picture because that when when we do the prompting and everything that's why frameworks like I'm saying that important because you try to make it more generative that's why we call it generative AI extractive is not don't need to be in AI is what has been happening prior to. To to generate a but abstractive makes it more humanly if I may use that term because it it understands it and brings it in the form that irrespective of how you change the things is able to capture the semantics that is why the transformer architecture. It's captures what we talk about safe attention li captures the semantics of of the words the context one meaning not just not just the because to me two words can can be used in two different sentences but in different context so that that context while meaning of. That word in a sentence was vital and that's what brought the success of the transformer of the transformer architecture that we are using today and yeah. Have you used gun. No, I've generated an adverse in the network. Generative address on network. I think I've seen that like deep fake. Some things. I think I've seen. You're not used. Okay, that's all right. You have knowledge about it. Yeah, I've read an article on it but I've not implemented it so. I've talked about deep fake and the place images to networks something I can't really is being quite some time. Sometimes we just read research papers and try to capture some stuff. So I think at that time you were talking about two networks competing against each other. So I don't know if you can just give me a little bit of head so maybe I might I might refresh what I what I got in the gun. What is being quite some time that I read that paper. That's okay. So I want to be the neural network so. What is the drawback of LSTM and why is the transformer architecture better than that? LSTM still uses sequence sequence. So even though LSTM solves part of the problem of vanishing gradient but it's still so fast from it. Even though it's LSTM which transformer architecture doesn't and talking about the semantics that we just mentioned. And the contextual to capture the contextual meaning of of talking in a word in a sentence, the contextual meaning of of a word in a sentence. LSTM doesn't capture that which the transformer architecture due to the safe attention layer is able to capture that LSTM doesn't capture in terms of. So LSTM will just generate the text based on maybe they are if they occur in a sentence like how are you and if it's maybe supposed to translate it is going to attribute how and that based on the how they occur and how they so we will just know that if it's this is that if it's this is that based on how it is string. But transformer architecture doesn't only do that kind of capture the attention layer when we do the position encoding and everything that passes through the attention layer and it assigns attention scores and everything. And so based on that it would now generate representations during that phase which are probabilities and then based on that we would so it captures the context that's just the one of the great great difference and then transformer has both encoder and decoder. So the LSTM for LSTM to really be like transformer is attention in is the attention layer like with the idea is is very difficult because you have to maybe forget get and all of those things are the recursive nature. It doesn't really solve everything. So are you heard about this egos models. Ego models.", "start_char_idx": 14877, "end_char_idx": 19526, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cee31820-8605-471f-a1b3-753750992fd0": {"__data__": {"id_": "cee31820-8605-471f-a1b3-753750992fd0", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "be2efb2e-a841-4f8b-8237-700c352b16cd", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "854eb03f7640b502406b3f97ff5bad812ca50794618c85b9b988dad62a54bd84", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d1182f7f-3c0b-43fc-b277-bb303c2d8ed5", "node_type": "1", "metadata": {}, "hash": "dda310940b2942ff4aa86fc09c063c26462b31929c9505b71f9eac4b5e7883e8", "class_name": "RelatedNodeInfo"}}, "text": "But transformer architecture doesn't only do that kind of capture the attention layer when we do the position encoding and everything that passes through the attention layer and it assigns attention scores and everything. And so based on that it would now generate representations during that phase which are probabilities and then based on that we would so it captures the context that's just the one of the great great difference and then transformer has both encoder and decoder. So the LSTM for LSTM to really be like transformer is attention in is the attention layer like with the idea is is very difficult because you have to maybe forget get and all of those things are the recursive nature. It doesn't really solve everything. So are you heard about this egos models. Ego models. And I'm right you know but it is based on our and it doesn't use transformer architecture. Very recently the release it. It's as good as the amount to but it is based on our and. So what what did they use in. To capture the context of the. Based on the sequence to sequence nature of our NN and. I mean I will look into into it. You take a look at that right it's very interesting. So you don't necessarily need. You know transformer architecture but. They crack it with the order and so anyway. This is this is a fast changing domain that the list. They that you don't study something or you don't. You are you are you are you are you lost information like every day people are doing active research and. I mean it's really interesting but I would read I would read the paper on that and. You said ego right if I got it right. Yeah let me see if it is the eagle or. No not. I forgot I let you know you know before this call. So if it is far content in fact no lets be like you always say. I think, while you're looking that up, right, loud and this is straight away and here. So I just want to quickly ask you a couple of questions. I think you brought up a point about these micro-allel lamps. Right. So can you talk about micro-allel lamps? Why would you use micro-allel lamps? And what's the power of using a micro-allel lamp versus a regular large-scale? Yeah. So there are several advantages. One is that the micro-allel lamp is customized. So it's smaller than the large language model. And so you benefit in terms of computation, in terms of you get exactly the kind of response that you need. Because most big-allel lamps are general purpose. Like they were trained on large-corporals. So they are prone to hallucination. There is a concept called hallucination, where if the model was less than GPT-3, it was trained to 2021 or 2021, you had GPT-3.5. If you ask GPT-3.5 about Lama II or something concerning RAC, it would say, I don't know about that. So it's limited. So we need some kind of additional data to customize it to our context. So we have computational concerns with large-language models, which are solved with micro ones. And they are more efficient than for specific tasks than the large-language model. So, and the micro models can be trained faster, and even locally than the large-language models. Yeah. So, what do you say, Thael, that micro-allel lamps, if trained properly would not hallucinate? The overall objective is that even if it does, it would do it less. So that is why all these customized elements or micro-allel lamps is because we want to reduce that hallucination. But to do that for a large one is more cost-effective, and to do that for a large one is more expensive, it's more time-consuming and all-deliberate for a smaller one is cheaper and faster. Yep. What are the applications of micro-allel lamps? Where do you see them fitting in? Basically, we see them in chat boards. If you have an institution, for example, and you, let's say, a bank is different from a healthcare company, so it would be more better if you use maybe a kind of bank kind of documents in a micro-allel lamp in a chat board or stuff, rather than using a general purpose, like, chargifity, which is to use it in your... So it's more proprietary kind of applications. Have you heard of micro-services architecture? Yeah, micro-serve, yes. So can you correlate the micro-allel lamps and how they fit into overall schema?", "start_char_idx": 18738, "end_char_idx": 22970, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d1182f7f-3c0b-43fc-b277-bb303c2d8ed5": {"__data__": {"id_": "d1182f7f-3c0b-43fc-b277-bb303c2d8ed5", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cee31820-8605-471f-a1b3-753750992fd0", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "dd870ac4b6cf5c4799523045b9c138abbfec0a79ca6e92d4ef43f93eaf2952d3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bfcf4e11-d0bb-4da6-b073-73dc5c2531fc", "node_type": "1", "metadata": {}, "hash": "66189c3c5f011f15cb79530e7d8380d21115a79eb3104057a4922c0b58494d4b", "class_name": "RelatedNodeInfo"}}, "text": "But to do that for a large one is more cost-effective, and to do that for a large one is more expensive, it's more time-consuming and all-deliberate for a smaller one is cheaper and faster. Yep. What are the applications of micro-allel lamps? Where do you see them fitting in? Basically, we see them in chat boards. If you have an institution, for example, and you, let's say, a bank is different from a healthcare company, so it would be more better if you use maybe a kind of bank kind of documents in a micro-allel lamp in a chat board or stuff, rather than using a general purpose, like, chargifity, which is to use it in your... So it's more proprietary kind of applications. Have you heard of micro-services architecture? Yeah, micro-serve, yes. So can you correlate the micro-allel lamps and how they fit into overall schema? There will be some orchestrator wave. Yeah, I'm just giving you some hints. Yeah, so micro-services is... A typical DevOps environment is every micro-service produced a given outcome, but on the higher level, each outcome joins together to give the final result. So let's say micro-serve is one, produces a bottle, micro-serve is two cleansed water, and the higher level, we put the water inside the bottle before we sell it. Let's just take as an example. So, yeah, that's a similar scenario, even on micro-allel lamps, like, it's more reduced to a given task at a given time. Like, for example, you can do something just for a chat board or maybe summarization, or maybe just a specific task, and it produces more beta. It's easier for you to customize a model that was built just for text summarization, for a summarization task, than to customize a general purpose model for a summarization task. But now you can have various tasks in your company, summarization, question and answering, text generation, and all other things, image and everything, so you would customize. Like, for example, Dali can be more used in a particular context, and that is different from... So choosing the right kind of model too is very important, depending on the task that you want to do. So, if I were to ask you, so you talked about Langchain before, or other frameworks. You have to somehow correlate between using micro-allel lamps in a Langchain kind of framework. How would you do that? Excuse me. So, it's an interesting question. So, basically, if we have some proprietary documents, right, let's see, they are PDFs and other stuff, so... What we do is we make sure... In Langchain, we have the right micro-allel lamps, that's the first thing. So, when we have the right micro-allel lamps, we have other proprietary documents, we would use a spita. Langchain, we can use a spita like a recursive text spita. We speed them down into chunks. When we do that, Langchain, we also can use a vector store after we do the embedding, we proceed to a vector store. Let me just stop here. If you're chunking, there is a risk of losing context. How do you tie these different purposes to the other? If I'm chunking, there is a risk of losing context, the overall context. The chunking is because every model has limitations in terms of tokens. So, in the chunk, we specify both the chunk size and the overlap. So, the overlap helps us to capture... We need to specify the overlap. It helps us not to lose context. Did I respond to your question, right? There is a balance. There is a balance that you have to play around, so that you don't lose the context. But I'll take that answer. We can also group by topics. Just moving along. Have you worked with vector databases? Yes. I've worked with Pinecon. That was where I was heading to when we embed. We do index. We can create an index. Based on that, we can load the chunks in the vector store. We use what we call... While creating the index, we would specify the dimension. If we are going to use dot product or cosine similarity, yeah, so when all you clear and distance, and when we do that, then when we finish the indexing, we use what we call similarity search. So whenever there is a query, based on maybe when we are prompting also, we pass the message.", "start_char_idx": 22138, "end_char_idx": 26267, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bfcf4e11-d0bb-4da6-b073-73dc5c2531fc": {"__data__": {"id_": "bfcf4e11-d0bb-4da6-b073-73dc5c2531fc", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1182f7f-3c0b-43fc-b277-bb303c2d8ed5", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "14a626875557170b9e11386e96c7b8a57e19b59d197f42bdd0c95bbf1a36ffa8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2807c55a-565f-477c-9d9b-833d0b3bdefb", "node_type": "1", "metadata": {}, "hash": "cacdf413c5abdace149964f9f20b7305c9c5b69f18bfdc01208ce654feabbf50", "class_name": "RelatedNodeInfo"}}, "text": "Did I respond to your question, right? There is a balance. There is a balance that you have to play around, so that you don't lose the context. But I'll take that answer. We can also group by topics. Just moving along. Have you worked with vector databases? Yes. I've worked with Pinecon. That was where I was heading to when we embed. We do index. We can create an index. Based on that, we can load the chunks in the vector store. We use what we call... While creating the index, we would specify the dimension. If we are going to use dot product or cosine similarity, yeah, so when all you clear and distance, and when we do that, then when we finish the indexing, we use what we call similarity search. So whenever there is a query, based on maybe when we are prompting also, we pass the message. During the prompting, we pass the message. This can be system, human and AI. AI message. Based on the human message that is passed as a query on the prompt, that we would provide, it will be able to do a cosine similarity, and then using the micro-LLM that we choose, we will be able to generate the response to the user at the front end. Is there any other search mechanism that you are aware of, other than vector databases? Yeah, we have semantic search. No, no, in terms of not... If we thought using vector database, there are any other... So when we take search, again, there are vector databases. Anything other... Graph? Any other... Yes, go ahead. Knowledge graphs? Yeah. Knowledge graphs. Yeah. So have you worked with any of the knowledge that we have to? Or... A bit, I've worked a bit, but not too much, just a bit. I've played around with Neo4G. Yeah, okay. What's the triplet in Knowledge Graph? Can you repeat that? Triplet. Yeah. Triplet. Not to show... That's okay. That's all right. So, you know, any other way you can use micro-elements, leveraging blockchain framework? Have you heard about agents? Hello again. Have you worked with using agents? Yeah. So, agents... Each agent can be triggered and can be, you know, focused to do some particular task that can be done through the micro-elements. So, you have all these micro-elements working as agents, and then they will be agent orchestrated on the top. But... Have you worked with the agents? Yeah. I've worked with agents, but not in the context that you are saying right now, but the agents were just to make the LLM more intelligent in terms of we needed something like a Python interpreter, a database, and other things to be incorporated to reuse agents in Lungchain, but not like the high level that you are trying to... But it's possible because the agents are... Yeah, they are what makes it more powerful. They make the... Basically, the agents use the tools. Yeah, they use like a different... Other things are the tools. The agents use the tool to perform some tasks. For tasks. In place of a tool, you have a micro-elements. Okay. That's where I was going to... Okay. Yeah. It makes sense. It makes sense. So, what are all the techniques that you would use to increase the accuracy of the LLM output? The techniques to increase well... First of all, prompt... Prompting engineering is... ...is very important. We have to... ...set the... ...gifts like... ...a few short inferences... ...during the prompting. The... ...speaker... ...if... And there is a new technique that we are working on right now, which is... ...ranking... ...it's the... ...retrived chunks... ...which is very important right now in a vector store. So, those... Those are stores that are... ...improved, really improved. And it's... ...can keep just the top... ...maybe... ...to a top three or top four or five chunks rather than... ...just choosing it randomly instead of giving... ...given it... ...you can select five out of maybe 15. Also... ...the... We already mentioned fine tuning. Fine tuning also makes it more customizable. So, it's also very important. So, the data set that we use to fine tune has to be good.", "start_char_idx": 25468, "end_char_idx": 29449, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2807c55a-565f-477c-9d9b-833d0b3bdefb": {"__data__": {"id_": "2807c55a-565f-477c-9d9b-833d0b3bdefb", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bfcf4e11-d0bb-4da6-b073-73dc5c2531fc", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "fab434848a39f21f8e3ffc6f4d8f367f6219c7151b1b554ae09e6cdf88f640d2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "032f3e2d-60cf-40cc-b9f8-71668940c15a", "node_type": "1", "metadata": {}, "hash": "fa775c17af95a9e7f1bb5e642a2df8bc5d5de0177204f2e1a29813bf262a4f23", "class_name": "RelatedNodeInfo"}}, "text": "We have to... ...set the... ...gifts like... ...a few short inferences... ...during the prompting. The... ...speaker... ...if... And there is a new technique that we are working on right now, which is... ...ranking... ...it's the... ...retrived chunks... ...which is very important right now in a vector store. So, those... Those are stores that are... ...improved, really improved. And it's... ...can keep just the top... ...maybe... ...to a top three or top four or five chunks rather than... ...just choosing it randomly instead of giving... ...given it... ...you can select five out of maybe 15. Also... ...the... We already mentioned fine tuning. Fine tuning also makes it more customizable. So, it's also very important. So, the data set that we use to fine tune has to be good. We can use reinforcement learning... ...that is... ...feedbacks from... ...maybe... ...or... ...aligning it with certain policies or human feedback and stuff like that... ...model alignment. Yeah. So... ...can you talk about our... ...relationship... ...a bit more detail. How is that... ...reinforcement learning that you will feedback... ...inplement it? How do you implement that? Yeah. So, basically we have... ...we have rewards in reinforcement learning... ...we have... ...a reward... ...a reward model... ...and we have... ...a reinforcement learning model like... ...PPO.PPO is one of those that are mostly... ...used. So... ...whenever... ...the... ...whenever we finish the fine tuning... ...we... ...can... ...make it to... ...when it produces good results... ...whenever it makes an inference. Let's say it does the job on the model... ...and it produces good results... ...it gives rewards. So we use the reward... ...the reward model. They are several different rewards. Do you train the... ...analyms that is producing the output... ...of do you train a reward model? We train the... ...the reward model because... ...so the reward model is based on human feedback. So when the feedback is positive... ...it gives a reward. When it's not it gives... ...a penalty based on what the LLM... ...has produced as a result. Because the LLM is the one... ...which generates the response. And so... ...the reward model... ...uses this... ...LLM model as a reward function... ...to optimize... ...the policy... ...to reinforce... ...to reinforce... ...meaning. So we train... ...you train the model... ...basically. Yeah, you're using two models. Yes. And the reward model... ...is it usually... ...a better model than the LLM... ...that is producing output... ...or is it... ...of... ...inferior to the LLM? I mean, they... ...reward model... ...is... ...the LLM is more intelligent than the... ...than the... ...well, the reward model would be better if I... ...if I say so. So, which means basically if I have to go around... ...our LLM... ...you have to do... ...inforcement learning... ...it is much more costly for me. Yeah. Right. Say that again please. It is more expensive for me to go... ...to use our LLM... ...because I have to use a better model... ...and I have to use two models... ...to train the two models again. Yeah. Yeah. How do we overcome this challenge? Is there any other way? So... ...we could... I think we could just fine tune. Maybe... ...if we have some regulations... ...or some things that we want our model to align with... ...we could continue... ...and correct the response... ...and based on the feedbacks we find... ...we... ...you are right. You are going on the right direction. So, what is that called? Retrain. It is... ...DPO... ...direct differential optimization. Where you kind of take away the reward model... ...and using the feedback... ...you put regulation as you said... ...and try to train the LLM itself. But then... ...whether it is RLHF... ...whether it is DPO... ...whether it is fine tuning... ...what is that common thing that we need? We need... ...what is the common... Yeah. What do we need? We need feedback. We need lots of feedback.", "start_char_idx": 28665, "end_char_idx": 32652, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "032f3e2d-60cf-40cc-b9f8-71668940c15a": {"__data__": {"id_": "032f3e2d-60cf-40cc-b9f8-71668940c15a", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2807c55a-565f-477c-9d9b-833d0b3bdefb", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "f6159a8f94470b98a705a4caac16bcb989df56233b60080ab801ff105d5f39d1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "95703399-98e7-4c86-bac9-a7971b5ce475", "node_type": "1", "metadata": {}, "hash": "2461f79256248950f45aedfd03640352ed20c1aba75746a73186a1af1e0294c5", "class_name": "RelatedNodeInfo"}}, "text": "Maybe... ...if we have some regulations... ...or some things that we want our model to align with... ...we could continue... ...and correct the response... ...and based on the feedbacks we find... ...we... ...you are right. You are going on the right direction. So, what is that called? Retrain. It is... ...DPO... ...direct differential optimization. Where you kind of take away the reward model... ...and using the feedback... ...you put regulation as you said... ...and try to train the LLM itself. But then... ...whether it is RLHF... ...whether it is DPO... ...whether it is fine tuning... ...what is that common thing that we need? We need... ...what is the common... Yeah. What do we need? We need feedback. We need lots of feedback. We need lots of feedback. Right? You know, so... ...if we have to get to that point... ...how much time we will take to get the feedback? Depends on... ...that is how... ...so... ...if I am able to generate the feedback... ...and collect that enough data set... ...where the question context answers... ...and the feedback in terms of whether it is positive or not... ...it takes months or a year for us to collect the feedback. By then... ...there is a new LLM. That's... ...you know... ...teaks are changed so fast. So, why... ...why would I invest in that? So, how do I address this challenge? You got to have a better way of doing things. So, how do we do that? Now, think about this. You don't have to answer out of now. But I am just putting your point. Yeah, that's a good point to note. I mean, I am going to work on that. We learn everyday. I think we are almost at the top of the hour. So, I think we got a good conversation going on. By the way, that model I said is EGLE77B7.5B. The RNN model. Oh! Was the name please? EGLE. EGLE7.5B. Okay. Thank you so much. I learned a lot from you today. Same here. Every interaction, we kind of learned something new. It was a good time spending time with you, Lauren. So, probably we'll get back to you in an AR2 on the next steps. Or whether we are able to take you to the Van Vard interview on app. Like you know, so I'll keep you posted. Either it's would have been posted on the election or I'll inform you either way. All right. Thank you. Next way of time, you have a wonderful day. You too. Thank you, Lauren. Bye-bye. Take care. Oh, my goodness. These guys are good. They know things. They know a lot of things. They are so powerful. Like, yes. They have been working. They are not internal for where God there. You just hear of screening process. Yeah. This is just the, they are. So, this is a very interesting field. So, you know where you got yourself in trouble, right? You know it, right? Lanching. Wow. Yeah. That's why I'm going by the same way. You were doing great. You were like, there was no, no rag yet. There was, there was just this. We were, you were perfect. And then it's like, yeah. And we, we, we started throwing things. Yeah. Who knows? We'll see. So, what's interesting is, again, that there's not a lot of people using it. And I also noticed when you get nervous, you speak a lot. So, so, so it's okay to talk. But it's also, let me put it this way. Every time they ask a question when you answer correctly, it's 100 times more powerful than you, you volunteering something. So, so it's good to, to. They were very nice to let you speak and, and gave you rope to hang yourself, you know, they're like, like, keep on going. Yeah, let's hear about this Lanchane in 2020.", "start_char_idx": 31912, "end_char_idx": 35404, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "95703399-98e7-4c86-bac9-a7971b5ce475": {"__data__": {"id_": "95703399-98e7-4c86-bac9-a7971b5ce475", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "032f3e2d-60cf-40cc-b9f8-71668940c15a", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "54d5ed20f16e2708874efec00236ec6c2c938ad421cb5bab51450a7fd6d6f64b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cd622ea0-9589-454f-baea-b419c1d91ae1", "node_type": "1", "metadata": {}, "hash": "e5e59f3913c2760688379f8a785a8eddc9b42de181e0e9c694b2a8d4aa147ef6", "class_name": "RelatedNodeInfo"}}, "text": "There was, there was just this. We were, you were perfect. And then it's like, yeah. And we, we, we started throwing things. Yeah. Who knows? We'll see. So, what's interesting is, again, that there's not a lot of people using it. And I also noticed when you get nervous, you speak a lot. So, so, so it's okay to talk. But it's also, let me put it this way. Every time they ask a question when you answer correctly, it's 100 times more powerful than you, you volunteering something. So, so it's good to, to. They were very nice to let you speak and, and gave you rope to hang yourself, you know, they're like, like, keep on going. Yeah, let's hear about this Lanchane in 2020. But I think, I don't know, I think, I think, I think you kind of worked yourself out of the, of the problem. They have to be aware that, you know, everything is new. Everything is new. Me and Shaz and we've been working on LLMs for years and years and years. And everything we know is old. This is why this, I mean, we build this very nice bird classifiers, like, like two years ago. They're now obsolete. This question about NLU and NLP, it's a semantic question. It used to be very different and I'll tell you the big differences. NLU was more about understanding the language. So, for example, clustering and stuff like that. Nowadays, it doesn't matter. We don't even need to limitize or stem or do any of that stuff. Basically, the preprocessors for all the large language models do it by themselves in a better way than we could possibly do. So, nowadays, you don't stem, you don't limitize. You may be denoise because there could be links, there could be stuff like that. But even a basic and better, like, universal census encoder can handle anything you throw at it. In a better way than you could. And the true phase that the large language models, the encoders of these large language models, need to have capital letters. They need to have a preposition because you're trying to capture the meaning. So, just like a person, you know, a lot of language is things that make it easier for you to understand something. And the old-fashioned NLP models, where you remove stop words, you remove everything, you are just trying to classify these words. You're just trying to make a unique numerical identifier for this particular group of words and then kind of relate it. But a large language model trained on billions of words and stuff like that. It doesn't really care. You don't need to stem, you don't need to limitize, you don't even need to tokenize. It will have a preprocessing step that will limitize and tokenize everything. It used to be that for LLM, for NLP, you spent half of your time basically cleaning up your test. It's not anymore. You don't care about that. You mostly care about what he said. Is this chunk, does it contain enough context? So, for example, if you write a recipe to give you an idea, and the recipe is in a page with 20, I don't know. Let's say 200 words. Just because you need to split them into, let's say, 20 word chunks, it doesn't mean that you will be able to know that that's the recipe for a souffl\u00e9 or whatever. You know, add an egg. So you lose the whole thing. So a lot of the work that is ahead of us as a discipline is to learn how to preserve that context. And it all happens in the splitting. It all happens in the splitting. It all happens at that moment where you do it. We had an idea for something called the hierarchical splitter, where you try to preserve the field or the topic. But this is all, all, like I said, is all new. And the interesting thing is that a lot of these rack systems are pretty good. But it's a combination of factors. All right, Lauren. We got to run. I don't know. I don't know how it went, but I can tell you is that it is. It was a very challenging interview. It was very good, very interesting. And we learned a lot of things.", "start_char_idx": 34729, "end_char_idx": 38623, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cd622ea0-9589-454f-baea-b419c1d91ae1": {"__data__": {"id_": "cd622ea0-9589-454f-baea-b419c1d91ae1", "embedding": null, "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f821ba1-e534-4918-ad05-b49a04e66534", "node_type": "4", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "25ec10a93aa2696fbc4cbee011a51b5339a68d9474a7d28531085c646ccb3a6a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "95703399-98e7-4c86-bac9-a7971b5ce475", "node_type": "1", "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}, "hash": "77211d774e50c80fb8a33b9452f67af030c92ab04e0f7472f1f9473747200eaa", "class_name": "RelatedNodeInfo"}}, "text": "You know, add an egg. So you lose the whole thing. So a lot of the work that is ahead of us as a discipline is to learn how to preserve that context. And it all happens in the splitting. It all happens in the splitting. It all happens at that moment where you do it. We had an idea for something called the hierarchical splitter, where you try to preserve the field or the topic. But this is all, all, like I said, is all new. And the interesting thing is that a lot of these rack systems are pretty good. But it's a combination of factors. All right, Lauren. We got to run. I don't know. I don't know how it went, but I can tell you is that it is. It was a very challenging interview. It was very good, very interesting. And we learned a lot of things. We do a lot of interesting information. So, you know, the idea that I had, which apparently is a thing, you'll find out that any idea that you have an interview is most likely already been written up by somebody else, somewhere else. And the thing is that whenever you have a proper response and the human gives you good feedback from that, oh, yeah, you gave me good information. You immediately trigger a retrain. So the cool thing about LLN, particularly for example, the OpenAI stuff, all that you need to do to retrain is you just give it a question answer pair. So, you know, in a situation where you can get, you can generate a response to a question like, oh, what's that information useful to you? And based on that response, if it was yes, it was very useful. Thank you. You immediately retrain it. So what you would do, be doing is almost like transfer learning, where you're adding. So, you know, you're adding samples that you know are okay. So the more you talk, so in theory, the model will improve, right? The in theory, the model will get better, but he's absolutely right. It can take a year. Yeah. Yeah. They were very knowledgeable. Those two guys were very knowledgeable in this field. Like, what's up, Shazam? Yeah. Like, you know, every time I run them, retraining it every time, if it is computationally extensive, can we not set something like a threshold and like you know, say, if we get this amount to actually peter or deeply retrain it with the correct response? Well, so the biggest difference is, and if you go to the OpenAI retraining or fine tuning page, it's very easy. You just, just like you do a completion, you just give it a single observation. And so the interesting thing about that is that you can be doing it all the time. All the freaking time. The other interesting thing about it, it's. The observation, it's yeah. Yeah. So as long as the feedback is high enough, so that would be the threshold I would put it's like if the feedback is high enough, then you retain the only problem is this. People could be wrong. Just because I'm happy with this wrong response doesn't mean that it is useful for other users. Oh, shoot. Okay. I got to run. I'll be right back. Thank you. Thank you. Thank you. Bye.", "start_char_idx": 37870, "end_char_idx": 40869, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"c433fffb-ab0b-4f64-afb2-b5f065255c4f": {"node_ids": ["05374a5a-b27a-4363-b1a1-a998366cba84", "fa9daee1-81cd-4f22-b73c-da31a58636d0", "ba971bd8-7529-4bea-bcb9-e6102dd09fb0", "1d4ed061-3fe1-4e2b-9597-cb82ae4199f3", "18ffbc8e-1924-4670-a809-2d4b430e7c1f", "59f2c73b-cb66-447f-9ba8-a11381e83fcb"], "metadata": {"file_path": "Video-20240202_212830-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240202_212830-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 4299381, "creation_date": "2024-02-27", "last_modified_date": "2024-02-28", "last_accessed_date": null}}, "d3521eae-158d-4899-908d-b76c2e23d824": {"node_ids": ["4b93328c-f438-435b-b791-1a77d7474f9f", "140039e2-6389-4239-8c9a-a47e43509eeb", "e76b746e-de81-4a0d-8055-288367541a6f", "349bab13-3696-48e5-8eab-ede27cef7c8c", "ef945fdf-828d-4f48-8741-3fb64f8f5910", "4a7806b1-85e8-4832-876f-05eb1d78f92d", "f828e89b-515e-43bc-beea-86204ebc775d", "9d7450a4-6b0d-4238-a706-a8555c96e132", "60cd25fe-1b89-42e6-9cbc-6559480f1a48", "4e2c1416-b0c9-4383-aea6-df4854243788", "ee6278ee-5f6d-4b4b-8714-bb6bac19a186", "d822043d-66a1-48d8-948f-c4d6938bce37", "e510cb65-3a5d-40dd-b7a2-b42982e79b19", "2319a23b-d482-4196-9f5e-624250ca0c8c", "aaaaa1fa-96e5-420e-bba2-b393db5fb1e2", "515f688d-285e-4c4f-8ebe-0101e4359e91", "6884e192-d11c-4083-9bb2-8197cec674c0"], "metadata": {"file_path": "Video-20240206_165750-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240206_165750-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 15753105, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}}, "a0a11490-68e9-4b07-bef5-27c31af27966": {"node_ids": ["3b816b2d-c0e3-406d-aec4-1277060569d2", "30c0a70d-19b1-43cb-b9b0-441ae2ad8a25", "a328c706-20f5-4c35-99e8-efef138fe040", "c1f389d1-2523-4f14-ba4e-de2bbb19a7dd", "9c532364-1169-4cb1-95a0-250c43940657", "f7d35226-315e-4002-bb1f-13dec45cc83c"], "metadata": {"file_path": "Video-20240208_213412-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240208_213412-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 6373953, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}}, "3f821ba1-e534-4918-ad05-b49a04e66534": {"node_ids": ["73520d45-75e0-4df5-99c8-978dac8f7c3d", "b3465798-fdf5-453a-9ad7-59078f90ef24", "0ed7e79d-79d2-4535-82c9-9c9d255c10f8", "1d0e9dee-e671-4e2f-b85e-7532a209338e", "be2efb2e-a841-4f8b-8237-700c352b16cd", "cee31820-8605-471f-a1b3-753750992fd0", "d1182f7f-3c0b-43fc-b277-bb303c2d8ed5", "bfcf4e11-d0bb-4da6-b073-73dc5c2531fc", "2807c55a-565f-477c-9d9b-833d0b3bdefb", "032f3e2d-60cf-40cc-b9f8-71668940c15a", "95703399-98e7-4c86-bac9-a7971b5ce475", "cd622ea0-9589-454f-baea-b419c1d91ae1"], "metadata": {"file_path": "Video-20240215_160826-Meeting Recording.mp3", "file_name": "c:/Users/Ali Kone/OneDrive/ALKHAF/projects/genai_q_a/Video-20240215_160826-Meeting Recording.mp3", "file_type": "audio/mpeg", "file_size": 12194829, "creation_date": "2024-02-27", "last_modified_date": "2024-02-27", "last_accessed_date": null}}}}